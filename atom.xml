<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sean&#39;s Notes</title>
  
  <subtitle>Stay hungry, stay foolish.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://seanlook.com/"/>
  <updated>2018-03-22T13:32:49.000Z</updated>
  <id>http://seanlook.com/</id>
  
  <author>
    <name>seanlook</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MySQL复制与数据一致性 分享</title>
    <link href="http://seanlook.com/2018/03/22/mysql-ppt-replication-and-consistency/"/>
    <id>http://seanlook.com/2018/03/22/mysql-ppt-replication-and-consistency/</id>
    <published>2018-03-22T13:32:49.000Z</published>
    <updated>2018-03-22T13:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>这是针对公司内部的一个分享，主题是去年10月份就想好的，中间因为一些项目，也包括自己的拖延症，ppt一直没准备好。</p><p>在临近快要辞职的时候，还是想兑现一下承诺，加班加点完成了。</p><p>分享的内容包括：</p><ol><li><p>binlog介绍<br>我们有不少项目依赖于binlog同步数据，所以对binlog的格式以及内部结构进行了简单介绍</p></li><li><p>innodb事务的提交过程<br>主要是两阶段提交的一些概念和原理，与下面的组提交原理一起，方便后面对崩溃恢复机制的理解</p></li><li><p>组提交<br>着重介绍组提交的概念，以及它的实现。为下面的并行复制做铺垫</p></li><li><p>介绍MySQL复制流程<br>种类包括异步复制、半同步复制、增强半同步复制和并行复制，顺便结束了复制延迟常见的原因</p></li><li><p>基于上面的原理，介绍主库、从库分别在异常宕机的情况下，如何保证数据一致的</p></li><li><p>高可用类型<br>这部分由于时间的关系，没有准备，并且本身也是一个很大课题，所以干脆就去掉了</p></li></ol><p>演示稿中穿插了一些思考题，感兴趣的朋友不妨思考思考。</p><div class="row">    <embed src="http://7q5fot.com1.z0.glb.clouddn.com/mysql-replication-and-consistency.pdf" width="100%" height="550" type="application/pdf"></div><hr><p>原文连接地址：<a href="http://seanlook.com/2018/03/22/mysql-ppt-replication-and-consistency/">http://seanlook.com/2018/03/22/mysql-ppt-replication-and-consistency/</a></p><hr><!--<iframe src="https://www.slideshare.net/slideshow/embed_code/key/3HLJJcJmM9KLGT" width="900" height="512" frameborder="0" allowfullscreen></iframe><p>–&gt;</p>-->]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这是针对公司内部的一个分享，主题是去年10月份就想好的，中间因为一些项目，也包括自己的拖延症，ppt一直没准备好。&lt;/p&gt;
&lt;p&gt;在临近快要辞职的时候，还是想兑现一下承诺，加班加点完成了。&lt;/p&gt;
&lt;p&gt;分享的内容包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;binlog介绍&lt;b
      
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="分享" scheme="http://seanlook.com/tags/%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>MySQL分页优化</title>
    <link href="http://seanlook.com/2018/03/21/mysql-pagination-no-offset/"/>
    <id>http://seanlook.com/2018/03/21/mysql-pagination-no-offset/</id>
    <published>2018-03-21T08:32:49.000Z</published>
    <updated>2018-03-21T08:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>关于数据库分页查询的话题，网上谈论的很多，但开发人员在使用上还是习惯以往的思路。</p><p>比如我们有个电话记录表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t_tel_record` (</span><br><span class="line">  `f_id` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;流水号&apos;,</span><br><span class="line">  `f_qiye_id` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;企业&apos;,</span><br><span class="line">  `f_callno` varchar(20) DEFAULT NULL COMMENT &apos;主叫号码&apos;,</span><br><span class="line">  `f_calltono` varchar(30) DEFAULT NULL COMMENT &apos;被叫号码&apos;,</span><br><span class="line">  `f_Starttime` datetime NOT NULL COMMENT &apos;开始时间&apos;,</span><br><span class="line">  `f_Endtime` datetime DEFAULT NULL COMMENT &apos;结束时间&apos;,</span><br><span class="line">  `f_Calltime` mediumint(8) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;通话时间&apos;,</span><br><span class="line">  `f_user_id` bigint(20) NOT NULL COMMENT &apos;员工用户&apos;,</span><br><span class="line">  `f_path` varchar(200) DEFAULT NULL COMMENT &apos;语音文件路径&apos;,</span><br><span class="line">  `f_crm_id` bigint(20) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;客户库id&apos;,</span><br><span class="line">  `f_call_type` tinyint(4) unsigned NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;0:未知，1:为呼入类型，2:呼出类型&apos;,</span><br><span class="line">  PRIMARY KEY (`f_id`),</span><br><span class="line">  KEY `idx_endtime_userid` (`f_Endtime`,`f_user_id`,`f_qiye_id`),</span><br><span class="line">  KEY `idx_crmid` (`f_crm_id`),</span><br><span class="line">  KEY `idx_qiye_user_calltime` (`f_qiye_id`,`f_Starttime`),</span><br><span class="line">  KEY `idx_calltono` (`f_calltono`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">查询第1页的数据：</span><br><span class="line"> SELECT * FROM t_tel_record</span><br><span class="line"> WHERE f_qiye_id=xxx</span><br><span class="line"> ORDER BY f_Starttime DESC</span><br><span class="line"> LIMIT 0,100</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">当数据量很大，需要查询第10000页的数据：</span><br><span class="line"> SELECT * FROM t_tel_record</span><br><span class="line"> WHERE f_qiye_id=xxx</span><br><span class="line"> ORDER BY f_Starttime DESC</span><br><span class="line"> LIMIT 999900,100  -- 或者 OFFSET 999900 LIMIT 100</span><br></pre></td></tr></table></figure><p>MySQL的 limit m,n 工作原理就是先读取符合where条件的前面m+n条记录，然后抛弃前m条，返回后面n条，所以m越大，偏移量越大，性能就越差。这也是大部分ORM框架生成的分页sql。</p><p>还有数据不准确的问题产生。</p><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/15223856466570.jpg" alt=""></p><p>要优化这类sql大抵有三种方法：</p><ol><li>利用索引来排序</li><li>利用覆盖索引避免回表</li><li>想办法去掉大offset</li></ol><h2 id="利用索引来排序"><a href="#利用索引来排序" class="headerlink" title="利用索引来排序"></a>利用索引来排序</h2><p>这是写sql的基础的优化手段，利用二级索引的有序性，避免filesort。考虑索引 <code>KEY a_b_c (a, b, c)</code> :</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ORDER may get resolved using Index</span><br><span class="line">    – ORDER BY a</span><br><span class="line">    – ORDER BY a,b</span><br><span class="line">    – ORDER BY a, b, c</span><br><span class="line">    – ORDER BY a DESC, b DESC, c DESC</span><br><span class="line">     </span><br><span class="line">WHERE and ORDER both resolved using index:</span><br><span class="line">    – WHERE a = const ORDER BY b, c</span><br><span class="line">    – WHERE a = const AND b = const ORDER BY c</span><br><span class="line">    – WHERE a = const ORDER BY b, c</span><br><span class="line">    – WHERE a = const AND b &gt; const ORDER BY b, c</span><br><span class="line"> </span><br><span class="line">ORDER will not get resolved uisng index (file sort)</span><br><span class="line">    – ORDER BY a ASC, b DESC, c DESC /* mixed sort direction */</span><br><span class="line">    – WHERE g = const ORDER BY b, c /* a prefix is missing */</span><br><span class="line">    – WHERE a = const ORDER BY c /* b is missing */</span><br><span class="line">    – WHERE a = const ORDER BY a, d /* d is not part of index */</span><br></pre></td></tr></table></figure><p>当然不是说利用索引排序性能就一定好，由于MySQL优化器的局限性，也会出现选择选择糟糕的index scan执行计划，见 <a href="http://seanlook.com/2017/10/26/mysql-bad-plan-order_by-limit/">MySQL order by limit 走错索引(range-&gt;indexscan)</a> ，using filesort也有可能比 index scan 要快。</p><a id="more"></a><h2 id="利用覆盖索引避免回表"><a href="#利用覆盖索引避免回表" class="headerlink" title="利用覆盖索引避免回表"></a>利用覆盖索引避免回表</h2><p>我们先来理解一下回表的概念：</p><ol><li>MySQL是一个B+Tree结构的聚集索引组织表</li><li>每一行记录都有个rowid，要么是主键，要么是非空唯一索引，要么是内部分配的ROWID</li><li>二级索引是在表的一个或多个字段联合起来，创建的用于快速检索数据行的“字典”，这个有序的字典结构也是B+Tree</li><li>每个二级索引元组的结构后面，都会自带存储相应行记录的rowid，以便定位数据物理位置</li><li>如果一个查询采用的索引上，包含了 select 之后所需要返回的列，那么MySQL可直接从索引上返回数据；如果select 要返回的字段只要有一行没在索引中，则需要根据索引对应的rowid，进行回表获取数据。这部分数据有可能在内存，也有可能在磁盘。</li></ol><p>当然实际情况要比上面的复杂，比如MySQL内部有ICP和MRR、BKA优化访问的手段，覆盖索引也就不需要使用了。</p><p>如果你的分页SQL where条件和select返回列刚好都在同一个索引上，那在这一部分讲的方法没什么好优化的了。由此也应该可以得到启发，<strong> select只返回需要的行，不要返回多余的行，禁止select * </strong>，这些开发规范都是有依据的。</p><p>利用Covering index优化分页的方法，先用一个子查询把符合条件主键id集合查出来，然后与原表join取出其它列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM</span><br><span class="line"> t_tel_record t1</span><br><span class="line">INNER JOIN (</span><br><span class="line"> SELECT f_id</span><br><span class="line"> FROM t_tel_record</span><br><span class="line"> WHERE f_qiye_id = xxx</span><br><span class="line"> ORDER BY f_id DESC</span><br><span class="line"> LIMIT 999900, 100</span><br><span class="line">) t2 ON t1.f_id = t2.f_id</span><br></pre></td></tr></table></figure><p>子查询部分利用覆盖索引只返回主键(rowid)，但不是每次都有好运气，原where条件放到子查询就能很快，毕竟它还是需要过滤999900条数据。</p><p>上面的sql还出现了它的一个变种：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">min_id = SELECT f_id</span><br><span class="line">FROM t_tel_record</span><br><span class="line">WHERE f_qiye_id = xxx</span><br><span class="line">ORDER BY f_id DESC</span><br><span class="line">LIMIT 999900, 1</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">SELECT * FROM</span><br><span class="line">  t_tel_record t1</span><br><span class="line">WHERE f_qiye_id = xxx</span><br><span class="line">AND f_id &lt; &#123;min_id&#125; + 1</span><br><span class="line">ORDER BY f_id DESC</span><br><span class="line">LIMIT 100</span><br></pre></td></tr></table></figure><p>第一条语句利用覆盖索引获取到该页最小id(如果是升序就是最大id)</p><p>第二条语句利用主键和其它过滤条件，获取该页数据。</p><p>上面两种方式都有一定的优化效果，具体还是要看业务本身的复杂度。</p><h2 id="无offset翻页"><a href="#无offset翻页" class="headerlink" title="无offset翻页"></a>无offset翻页</h2><p>上面的变种已经提供了一个很好的思路：</p><ul><li>程序端或者客户端，保留当前页的最小id、最大id（id是主键），这并不是什么难事</li><li>降序情况下，每次提取下一页的数据时，f_id &lt; min_id order by f_id desc limit 100;  上一页 f_id &gt; max_id order by f_id desc limit 100</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">第一页：（降序）</span><br><span class="line">SELECT * FROM t_tel_record t1</span><br><span class="line">WHERE f_qiye_id = xxx</span><br><span class="line">ORDER BY f_id DESC LIMIT 100</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">获取结果集最大最小id：一般是第一条和最后一条，或者 max_id=max(f_id), min_id=min(f_id)</span><br><span class="line">下一页（如果有）：</span><br><span class="line">SELECT * FROM t_tel_record t1</span><br><span class="line">WHERE f_qiye_id = xxx</span><br><span class="line">AND f_id &lt; &#123;min_id&#125;  -- min_id变量</span><br><span class="line">ORDER BY f_id DESC LIMIT 100</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">上一页（如果有）：</span><br><span class="line">SELECT * FROM t_tel_record t1</span><br><span class="line">WHERE f_qiye_id = xxx</span><br><span class="line">AND f_id &gt; &#123;max_id&#125;  -- max_id变量</span><br><span class="line">ORDER BY f_id DESC LIMIT 100</span><br></pre></td></tr></table></figure><p>没有第几页之说，更不存在【跳转x页】这种深度分页，只有【上一页】【下一页】，所以用户体验上有差别。这种分页方式，使用f_id过滤数据，而f_id是主键，速度是很快的，性能不会随着页数的增大而变慢。</p><h2 id="反转分页"><a href="#反转分页" class="headerlink" title="反转分页"></a>反转分页</h2><p>降序分页的时候，如果用户直接点击最后一页，或者上面的第10000页实际就是倒数第2页，那就没有必要取这么大的offset，转换成升序，性能就与正向前几页效率一样高了。</p><p>如下图所示，很容易理解。</p><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/15223859031285.jpg" alt=""></p><p>在几万页的情况下翻到最后一页，用户不太关心最后一页是100条还是99条：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">最后一页：（降序）</span><br><span class="line">SELECT * FROM (</span><br><span class="line">  SELECT * FROM t_tel_record t1</span><br><span class="line">  WHERE f_qiye_id = xxx</span><br><span class="line">  ORDER BY f_id ASC LIMIT 100) AS t</span><br><span class="line">ORDER BY f_id DESC</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">倒数第二页：(以此类推)</span><br><span class="line">SELECT * FROM (</span><br><span class="line">  SELECT * FROM t_tel_record t1</span><br><span class="line">  WHERE f_qiye_id = xxx</span><br><span class="line">  ORDER BY f_id ASC LIMIT 100, 100) AS t</span><br><span class="line">ORDER BY f_id DESC</span><br></pre></td></tr></table></figure><p>分页不存在大一统的绝对优化方法，有时候需要产品层面来回避技术难题，比如前5页显示页号，便于跳页，实现上用offset；大于5页只能上下翻页，实现上用无offset方法；最后几页使用反转翻页实现：</p><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/15223859322454.jpg" alt=""></p><p>包括前面所有优化方法，都没有提供 记录总数 这样的显示，大数据量count对MySQL来说实在不擅长。即使是Google搜索引擎也只提供 <strong>约xx条结果</strong> 。</p><p>抛开数据量谈实现，也就太天真的。</p><h2 id="不精确分页"><a href="#不精确分页" class="headerlink" title="不精确分页"></a>不精确分页</h2><p>其实再想想 order by  xxx limit m,n 场景：</p><ol><li>展示列表或搜索结果</li><li>内部统计或者导出业务</li></ol><p>第2种场景，比如扫描一组数据或者全部数据，业务批量导出数据，并不是严格的分页，换句话讲，开发的目的是将数据分批取出，每批的数据量是不是一样并不重要，甚至顺序也不重要，而在批量取数据的实现反而引入了两个可能限制性能的条件。</p><p>比如有个扫描全表统计数据的功能，范围、等值条件比较复杂，无法很好的使用索引（比如范围搜索可能会使索引其它列失效）。下面直接按 f_Starttime 每5分钟切片，可以较好的利用(f_qiye_id,f_Starttime)索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM t_tel_record</span><br><span class="line">WHERE f_Starttime &gt;= &apos;2018-03-16 08:00:01&apos; AND f_Starttime &lt; &apos;2018-03-16 08:05:01&apos;</span><br><span class="line">ORDER BY f_Starttime DESC</span><br></pre></td></tr></table></figure><h1 id="分页优化陷阱"><a href="#分页优化陷阱" class="headerlink" title="分页优化陷阱"></a>分页优化陷阱</h1><h2 id="order-by-id-与-order-by-f-Starttime"><a href="#order-by-id-与-order-by-f-Starttime" class="headerlink" title="order by id 与 order by f_Starttime"></a>order by id 与 order by f_Starttime</h2><p>按照主键与按照二级索引排序，它们对优化器的影响是非常大的。</p><ol><li>在order by 主键时，MySQL优化器很“喜欢”直接用主键，而放弃where条件可能具有更好过滤效果（但有filesort）的执行计划。</li><li>在order by 二级索引的某个字段时，MySQL优化器表现比较正常，虽然遇到where条件的范围索引容易失去索引排序，但好歹有可能采用覆盖索引。</li></ol><p>正因为第1点的影响，所有再某些分页sql优化时，可考虑 order by id 改成具有接近排序效果的其它字段，比如id是自增，时间字段也是增长。</p><h2 id="第一页和最后一页非常慢"><a href="#第一页和最后一页非常慢" class="headerlink" title="第一页和最后一页非常慢"></a>第一页和最后一页非常慢</h2><p>考虑下面两个sql: （都采用上面的 f_id &gt; max_id 的优化方法）</p><p>sql1:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- f_Starttime上没有可用索引</span><br><span class="line">SELECT f_qiye_id,f_id,f_money,f_type,f_callno,f_calltono,f_Starttime,f_Endtime, f_Calltime,f_status, f_num,f_result,f_time,f_user_id,f_is400,f_crm_log,f_code, f_path,f_crm_id,f_telbox_id,f_mp3_len, f_in_out_type, f_call_type FROM d_ec_telecom7.t_tel_record_201710</span><br><span class="line">WHERE f_id &gt; 0</span><br><span class="line">  and (f_Starttime&gt;=&apos;2017-10-25 00:00:00&apos; and f_Starttime&lt;=&apos;2017-10-26 00:00:00&apos;) ORDER BY f_id ASC LIMIT 1000</span><br></pre></td></tr></table></figure><p>sql2:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT f_log_id,f_crm_id,f_user_id,f_qiye_id,f_creat_time,f_send_time,f_end_time,f_do_type, f_static_time,f_go_web,f_type,f_contact_num,f_share,f_record_type,f_provice,f_city,f_is_addclient, f_is_customer,f_ontime_flag,f_msg_type,f_id,f_style,f_operate_type,f_from,f_sendmsg FROM d_ec_contact.t_crm_contact_at201708</span><br><span class="line">WHERE f_log_id &gt; 3815923707</span><br><span class="line">  and (f_creat_time&gt;=&apos;2017-08-01 00:00:00&apos; and f_creat_time&lt;=&apos;2017-08-02 00:00:00&apos;) ORDER BY f_log_id ASC LIMIT 1000</span><br></pre></td></tr></table></figure><p>都是导出性质的sql，开发反应每当扫描开始的第一页（如sql1）和最后一页（如sql2），都变的贼慢，然而中间页的数据拉取都在几十毫秒级别。</p><p>我们分析一下sql1慢的原因</p><ul><li>f_Starttime上没有索引，执行计划如下：</li><li>f_id是个全局id，单调递增。应该说与f_Starttime是保持相同的趋势增长的，因为正是这样决定了中间页都较快</li><li>仔细观察f_Starttime条件，是从10月份表中获取 10.25 日全天数据。执行计划几乎就是根据主键全表扫描，因为f_id&gt;0的条件需要扫描10.1，10.2，… 10.24，之后终于在10.25的第一个f_id找到，通过where条件过滤。可想而知有多慢</li><li>第一页取出后，拿f_id的最大值，去取第二页，因为f_id与f_Starttime是保持相同趋势增长，所以扫过的所有记录都满足where条件，很快返回（另外主键扫描是顺序IO，取1000是很快的）</li><li>最后一页也是同样，当最后一页不满1000条时，f_id已经超出f_Starttime范围右边了，后面虽然已经没有满足f_Starttime条件的记录，但根据主键还是要一扫到底。<br>（要判断行数是否小于1000，如果不判断还会拿最后一页的最大值去查询，返回结果0，无谓的耗时）</li></ul><p>优化第一页和优化最后一页的方法其实是类似的。第一页在f_Starttime无索引的情况下，无论如何都是很难提高效率的，除非你用专门的一段代码去猜f_id的起始值。我们这个例子还特殊点，f_id的组成是 timestamp + incr_1 ，根据f_Starttime范围直接就得到 f_id 的近似值作为下界。</p><p>同理，最后一页根据f_Starttime得到最大值，转换为 timestamp × 1000000000 + 99999 作为上界。</p><p>sql2慢的原因有点不一样：</p><ul><li>f_creat_time上是有一个索引 (f_creat_time,f_operate_type) 的，看一下它的执行计划：</li><li>像本文前面说的，一个范围条件，再 order by 主键，优化器选择了主键扫描，而非范围扫描再filesort （一天数据量约320万）</li></ul><p>优化办法：</p><ul><li>比如去7月份表查个最大值</li><li>…use index(idx_creattime) … order by f_creat_time ASC</li></ul><p>关于分页优化，具体问题具体分析。</p><p><strong> 参考 </strong></p><ul><li><a href="https://mariadb.com/kb/en/library/pagination-optimization/" target="_blank" rel="noopener">https://mariadb.com/kb/en/library/pagination-optimization/</a></li><li><a href="http://www.cnblogs.com/wy123/p/7003157.html" target="_blank" rel="noopener">http://www.cnblogs.com/wy123/p/7003157.html</a></li><li><a href="https://blog.jamespan.me/2015/01/22/trick-of-paging-query" target="_blank" rel="noopener">https://blog.jamespan.me/2015/01/22/trick-of-paging-query</a></li></ul><hr><p>本文链接地址：<a href="http://seanlook.com/2018/03/21/mysql-pagination-no-offset/">http://seanlook.com/2018/03/21/mysql-pagination-no-offset/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于数据库分页查询的话题，网上谈论的很多，但开发人员在使用上还是习惯以往的思路。&lt;/p&gt;
&lt;p&gt;比如我们有个电话记录表：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;CREATE TABLE `t_tel_record` (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_id` bigint(20) unsigned NOT NULL DEFAULT &amp;apos;0&amp;apos; COMMENT &amp;apos;流水号&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_qiye_id` bigint(20) NOT NULL DEFAULT &amp;apos;0&amp;apos; COMMENT &amp;apos;企业&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_callno` varchar(20) DEFAULT NULL COMMENT &amp;apos;主叫号码&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_calltono` varchar(30) DEFAULT NULL COMMENT &amp;apos;被叫号码&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_Starttime` datetime NOT NULL COMMENT &amp;apos;开始时间&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_Endtime` datetime DEFAULT NULL COMMENT &amp;apos;结束时间&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_Calltime` mediumint(8) unsigned NOT NULL DEFAULT &amp;apos;0&amp;apos; COMMENT &amp;apos;通话时间&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_user_id` bigint(20) NOT NULL COMMENT &amp;apos;员工用户&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_path` varchar(200) DEFAULT NULL COMMENT &amp;apos;语音文件路径&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_crm_id` bigint(20) NOT NULL DEFAULT &amp;apos;0&amp;apos; COMMENT &amp;apos;客户库id&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_call_type` tinyint(4) unsigned NOT NULL DEFAULT &amp;apos;0&amp;apos; COMMENT &amp;apos;0:未知，1:为呼入类型，2:呼出类型&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  PRIMARY KEY (`f_id`),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  KEY `idx_endtime_userid` (`f_Endtime`,`f_user_id`,`f_qiye_id`),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  KEY `idx_crmid` (`f_crm_id`),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  KEY `idx_qiye_user_calltime` (`f_qiye_id`,`f_Starttime`),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  KEY `idx_calltono` (`f_calltono`)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;查询第1页的数据：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; SELECT * FROM t_tel_record&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; WHERE f_qiye_id=xxx&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; ORDER BY f_Starttime DESC&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; LIMIT 0,100&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;当数据量很大，需要查询第10000页的数据：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; SELECT * FROM t_tel_record&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; WHERE f_qiye_id=xxx&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; ORDER BY f_Starttime DESC&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; LIMIT 999900,100  -- 或者 OFFSET 999900 LIMIT 100&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;MySQL的 limit m,n 工作原理就是先读取符合where条件的前面m+n条记录，然后抛弃前m条，返回后面n条，所以m越大，偏移量越大，性能就越差。这也是大部分ORM框架生成的分页sql。&lt;/p&gt;
&lt;p&gt;还有数据不准确的问题产生。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/15223856466570.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;要优化这类sql大抵有三种方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;利用索引来排序&lt;/li&gt;
&lt;li&gt;利用覆盖索引避免回表&lt;/li&gt;
&lt;li&gt;想办法去掉大offset&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;利用索引来排序&quot;&gt;&lt;a href=&quot;#利用索引来排序&quot; class=&quot;headerlink&quot; title=&quot;利用索引来排序&quot;&gt;&lt;/a&gt;利用索引来排序&lt;/h2&gt;&lt;p&gt;这是写sql的基础的优化手段，利用二级索引的有序性，避免filesort。考虑索引 &lt;code&gt;KEY a_b_c (a, b, c)&lt;/code&gt; :&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ORDER may get resolved using Index&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – ORDER BY a&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – ORDER BY a,b&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – ORDER BY a, b, c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – ORDER BY a DESC, b DESC, c DESC&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;WHERE and ORDER both resolved using index:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – WHERE a = const ORDER BY b, c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – WHERE a = const AND b = const ORDER BY c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – WHERE a = const ORDER BY b, c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – WHERE a = const AND b &amp;gt; const ORDER BY b, c&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ORDER will not get resolved uisng index (file sort)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – ORDER BY a ASC, b DESC, c DESC /* mixed sort direction */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – WHERE g = const ORDER BY b, c /* a prefix is missing */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – WHERE a = const ORDER BY c /* b is missing */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    – WHERE a = const ORDER BY a, d /* d is not part of index */&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当然不是说利用索引排序性能就一定好，由于MySQL优化器的局限性，也会出现选择选择糟糕的index scan执行计划，见 &lt;a href=&quot;http://seanlook.com/2017/10/26/mysql-bad-plan-order_by-limit/&quot;&gt;MySQL order by limit 走错索引(range-&amp;gt;indexscan)&lt;/a&gt; ，using filesort也有可能比 index scan 要快。&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="分页" scheme="http://seanlook.com/tags/%E5%88%86%E9%A1%B5/"/>
    
  </entry>
  
  <entry>
    <title>MySQL主从复制idempotent模式以及同步错误处理预案</title>
    <link href="http://seanlook.com/2018/03/11/mysql-replication-error-and-idempotent/"/>
    <id>http://seanlook.com/2018/03/11/mysql-replication-error-and-idempotent/</id>
    <published>2018-03-11T08:32:49.000Z</published>
    <updated>2018-03-11T08:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-slave-exec-mode-参数作用"><a href="#1-slave-exec-mode-参数作用" class="headerlink" title="1. slave_exec_mode 参数作用"></a>1. slave_exec_mode 参数作用</h1><p><code>slave_exec_mode</code> 可以在主从复制中遇到 duplicate-key 和 no-key-found 错误时，自动覆盖或者略过binlog里面这个row_event，避免报错停止复制。</p><p>这个参数原本是解决像 NDB Cluster 多节点写入冲突的情况，也可以在普通主从、双主、环形复制等情况下解决冲突，保持幂等性。幂等性怎么定义，感兴趣的可以阅读<a href="http://http://blog.wl0.org/2016/05/the-differences-between-idempotent-and-my-suggested-auto-repair-mode/" target="_blank" rel="noopener">The differences between IDEMPOTENT and AUTO-REPAIR mode</a>）。</p><p><code>set global slave_exec_mode=IDEMPOTENT</code> （可以动态修改）使从库运行在 幂等模式，对1062，1032等不同的错误类型，有不同的处理：</p><ol><li>write_row event 遇到主键冲突或唯一索引冲突，这一行被覆写(delete + insert)。<br>delete时候不是full value match，仅需要主键或唯一索引找到记录则删除</li><li>delete_row event 遇到记录不存在，忽略这一行</li><li>update_row event 修改唯一索引导致的冲突，忽略这一行</li></ol><p>注意：  </p><ul><li>idempotent 模式都是对有疑问的<strong>行</strong>进行replace或ignore，不影响其它row。</li><li>idempotent 模式要求表上必须要有主键</li><li>binlog必须是 FULL RBR 模式</li></ul><h1 id="2-slave-skip-errors"><a href="#2-slave-skip-errors" class="headerlink" title="2. slave-skip-errors"></a>2. slave-skip-errors</h1><p>这个参数不能在线修改，只能加到配置文件里面或者启动的时候带上<code>--slave-skip-errors=1032,1062</code>。除非你真的理解它skip掉了什么，否则不建议使用。</p><p>讲一个我所遇到的坑。在我们的一个分库项目中，需要把一个database里面的数据拆成32份，于是做了个主从，把从库里面不需要的那份删除，但复制过来肯定会报 HA_ERR_KEY_NOT_FOUND 错误，于是这也是所期望的，就设置了<code>--slave-skip-errors=1032</code>。</p><p>但接下来就出现 1062:HA_ERR_FOUND_DUPP_KEY 错误！从库只会删数据，不会写入和更新，怎么会出现重复数据？读者不妨试想一下为什么。</p><p>这里做个说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">① insert into t values (1, &apos;a&apos;), (2, &apos;b&apos;), (3, &apos;c&apos;);</span><br><span class="line"></span><br><span class="line">② begin;</span><br><span class="line">③ delete from t where id=1;</span><br><span class="line">④ delete from t where id in (1, 2, 3);</span><br><span class="line">⑤ insert into t where (3, &apos;c&apos;), (4, &apos;d&apos;), (5, &apos;e&apos;);</span><br><span class="line">⑥ update t set ... id=1;</span><br><span class="line">⑦ commit;</span><br></pre></td></tr></table></figure><ul><li>事务包括显式事务和隐式事务(transaction)，语句①落在binlog里面也会有begin和end</li><li>一个事物可以包含多个语句(statement)</li><li>一个语句可以影响多行(row)，但属于一个event</li><li>一个语句在binlog里面有多个event (row log event, table map event, xid event…)</li><li>event在binlog里面以 event group 组合起来<br>事务引擎如 InnoDB，event group 就一个事务；非事务引擎如 MyISAM，event group就是一条语句</li></ul><a id="more"></a><p><strong>slave-skip-errors 参数作用的是 statement，上面的slave_exec_mode作用的是row</strong><br>比如上面那段sql在RBR复制到从库时发现④的 id=2 不存在：</p><ul><li><code>slave_exec_mode</code>: ④里面的 id=2 略过，id=1,3 正常删除，事务里其它sql(row event)都正常重放</li><li><p><code>slave-skip-errors=1032</code>: 从库也会一直从 begin 执行到 end ，但④里面的 id=3 会跳过（跳过的是这个statement，而 id=1 会依然删除，不是原子操作），事务里其它sql正常重放。  </p><p>这就导致了我上面那个问题，id=3应该是被删除的但被跳过，下面在插入 id=3 的记录就 1062 了。如果再把 1062 也加入到 skip-errors，那么数据肯定会出现的丢失，是不可取的。</p></li></ul><p>相关验证可以看后文。</p><h1 id="3-sql-slave-skip-counter"><a href="#3-sql-slave-skip-counter" class="headerlink" title="3. sql_slave_skip_counter"></a>3. sql_slave_skip_counter</h1><p>MySQL主从复制出现异常的时候，如不及时处理，延迟的时间会越来越长，所以有时候哪怕允许极少量的数据不一致，也要让数据继续同步，往往会用到 <code>sql_slave_skip_counter</code> 参数来跳过异常事件。<br>用法:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show slave status\G -- 1062可以看到是哪条记录重复</span><br><span class="line"></span><br><span class="line">mysql&gt; slave stop;</span><br><span class="line">mysql&gt; set GLOBAL SQL_SLAVE_SKIP_COUNTER=1;</span><br><span class="line">mysql&gt; slave start;</span><br></pre></td></tr></table></figure><ul><li>sql_slave_skip_counter=1<br>跳过一个 event group。前面讲到对InnoDB而言，就是<strong>跳过一个事务</strong>。<br>如果当前 binlog postion 落在 event group 中间，那么就一直跳到这个事务末尾。   </li><li>sql_slave_skip_counter=N (N&gt;1)<br>跳过 N 个 event。对不同的binlog版本会加入不同的event类型。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/slave_error_binlog_events.png" alt="slave_error_binlog_events"><br>比如上图在 pos 199 出现error，如果设置 <code>set global sql_slave_skip_counter=3</code>，那么就会以此跳过 199,264,332，每跳过一个 Skip_Counter 减去1，减到 Skip_Counter=1 的时候，如果pos还在<strong>事务</strong>中间，那么那么就一直跳到该事务末尾。<br>(同样，在事务中出现异常之前的修改，不会回滚)</li></ul><h1 id="4-GTID复制异常处理"><a href="#4-GTID复制异常处理" class="headerlink" title="4. GTID复制异常处理"></a>4. GTID复制异常处理</h1><p>主从开启了GTID（<code>select @@gtid_mode</code>），就不能再用 sql_slave_skip_counter 来跳过错误，需要注册一个空gtid event来代替原本执行报错的event。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show slave status\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">               Slave_IO_State: Waiting for master to send event</span><br><span class="line">                  Master_Host: 10.153.173.149</span><br><span class="line">                  Master_User: replicator</span><br><span class="line">                  Master_Port: 3027</span><br><span class="line">                Connect_Retry: 60</span><br><span class="line">              Master_Log_File: mysql-bin.014670</span><br><span class="line">          Read_Master_Log_Pos: 181716556</span><br><span class="line">               Relay_Log_File: slave-relay.028871</span><br><span class="line">                Relay_Log_Pos: 166693104</span><br><span class="line">        Relay_Master_Log_File: mysql-bin.014670</span><br><span class="line">             Slave_IO_Running: Yes</span><br><span class="line">            Slave_SQL_Running: No</span><br><span class="line">              Replicate_Do_DB: </span><br><span class="line">          Replicate_Ignore_DB: </span><br><span class="line">           Replicate_Do_Table: </span><br><span class="line">       Replicate_Ignore_Table: </span><br><span class="line">      Replicate_Wild_Do_Table: </span><br><span class="line">  Replicate_Wild_Ignore_Table: </span><br><span class="line">                   Last_Errno: 1032</span><br><span class="line">                   Last_Error: Could not execute Update_rows event on table mysql.user; Can&apos;t find record in &apos;user&apos;, Error_code: 1032; handler error HA_ERR_KEY_NOT_FOUND; the event&apos;s master log mysql-bin.014670, end_log_pos 166693925</span><br><span class="line">                 Skip_Counter: 0</span><br><span class="line">          Exec_Master_Log_Pos: 166692941</span><br><span class="line">              Relay_Log_Space: 688</span><br><span class="line">              Until_Condition: None</span><br><span class="line">               Until_Log_File: </span><br><span class="line">                Until_Log_Pos: 0</span><br><span class="line">           Master_SSL_Allowed: No</span><br><span class="line">           Master_SSL_CA_File: </span><br><span class="line">           Master_SSL_CA_Path: </span><br><span class="line">              Master_SSL_Cert: </span><br><span class="line">            Master_SSL_Cipher: </span><br><span class="line">               Master_SSL_Key: </span><br><span class="line">        Seconds_Behind_Master: NULL</span><br><span class="line">Master_SSL_Verify_Server_Cert: No</span><br><span class="line">                Last_IO_Errno: 0</span><br><span class="line">                Last_IO_Error: </span><br><span class="line">               Last_SQL_Errno: 1032</span><br><span class="line">               Last_SQL_Error: Could not execute Update_rows event on table mysql.user; Can&apos;t find record in &apos;user&apos;, Error_code: 1032; handler error HA_ERR_KEY_NOT_FOUND; the event&apos;s master log mysql-bin.014670, end_log_pos 166693925 </span><br><span class="line">  Replicate_Ignore_Server_Ids: </span><br><span class="line">             Master_Server_Id: 1088575531</span><br><span class="line">                  Master_UUID: 108f89d5-d74f-11e7-942f-7cd30ac4755e</span><br><span class="line">             Master_Info_File: mysql.slave_master_info</span><br><span class="line">                    SQL_Delay: 0</span><br><span class="line">          SQL_Remaining_Delay: NULL</span><br><span class="line">      Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it</span><br><span class="line">           Master_Retry_Count: 86400</span><br><span class="line">                  Master_Bind: </span><br><span class="line">      Last_IO_Error_Timestamp: </span><br><span class="line">     Last_SQL_Error_Timestamp: </span><br><span class="line">               Master_SSL_Crl: </span><br><span class="line">           Master_SSL_Crlpath: </span><br><span class="line">           Retrieved_Gtid_Set: 108f89d5-d74f-11e7-942f-7cd30ac4755e:8077-122925776</span><br><span class="line">            Executed_Gtid_Set: 108f89d5-d74f-11e7-942f-7cd30ac4755e:1-122925773,</span><br><span class="line">8b101f33-f327-11e7-89c3-7cd30ac333bc:1-1425,</span><br><span class="line">fba62795-d74e-11e7-942e-7cd30ac4e7fc:1-630905526</span><br><span class="line">                Auto_Position: 0</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure><p>跳过处理：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; stop slave;</span><br><span class="line">mysql&gt; set gtid_next=&apos;108f89d5-d74f-11e7-942f-7cd30ac4755e:122925774&apos;;</span><br><span class="line">mysql&gt; begin; commit;  -- empty trx</span><br><span class="line">mysql&gt; set gtid_next=&apos;AUTOMATIC&apos;;  -- auto position</span><br><span class="line">mysql&gt; start slave;</span><br></pre></td></tr></table></figure></p><p>上面 gtid_next 的值 <code>108f89d5-d74f-11e7-942f-7cd30ac4755e:122925774</code> 是个会话级变量。  </p><ul><li>uuid是 <code>Retrieved_Gtid_Set</code> 的uuid，一般是 <code>Master_UUID</code> 的值，但如果是级联复制(master -&gt; slavel1 -&gt; slave2)，那么要找到出错事务最原先在哪执行的  </li><li>trx_id(或叫position)是 master 上正常执行的最大id + 1，即<code>Executed_Gtid_Set</code>里面master uuid执行过的最大值 122925773 + 1</li></ul><h1 id="5-pt-slave-restart"><a href="#5-pt-slave-restart" class="headerlink" title="5. pt-slave-restart"></a>5. pt-slave-restart</h1><p>pt-slave-restart 可以快速方便的恢复主从复制错误，并且支持普通 file:postion 和 GTID 模式。</p><p>修复的原理就是运行上面的 <code>sql_slave_skip_counter</code> 和 <code>gtid_next</code>，只是它可以自动的帮DBA识别错误码，或者匹配error_msg，stop/start slave，并且默认情况下它是一直运行 检测+修复。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pt-slave-restart --user=dbuser --password=xxxx --socket=/var/lib/mysql/mysql.sock --error-numbers=1032,1677,1051</span><br></pre></td></tr></table></figure></p><p>几点说明一下：</p><ul><li><code>--sleep</code><br>pt-slave-restart 循环检查 <code>show slave status</code> 的间隔时间。如果发现有异常，下次sleep time将减半，因为它假设当前有异常，那么下一个event很有可能也异常。</li><li><code>--master_uuid</code><br>级联复制下指定了 master_uuid 才能知道事件原始来自于哪里，好让<code>pt-slave-restart</code>知道在哪个 max_trx_id 上面 + 1。</li><li><p>在gtid模式下，pt-slave-restart 不能用在多线程复制下（即 <code>slave_parallel_workers&gt;0</code>），因为它不知道这个GTID错误是从库哪个sql线程产生的。</p></li><li><p>以上所有处理错误的方法，在跳过后，都需要进行数据一致性修复(pt-table-sync)，或者重做从库。</p></li></ul><h1 id="6-手动处理复制错误并修复"><a href="#6-手动处理复制错误并修复" class="headerlink" title="6. 手动处理复制错误并修复"></a>6. 手动处理复制错误并修复</h1><p>这种处理思路是写程序实现，遇到1032错误，在主库Binlog里面解析出before image，在从库插入，再stop/start slave；遇到1062错误，在从库删除这条数据（可以根据主库binlog after image取数据，也可以根据duplicate key中提示的重复记录），再stop/start/slave。</p><p>不需要skip操作，也不需要后续修复数据（只是不会因为有跳过event而产生不一致），如果从主库拿binl log或者从库拿relay log有困难，也可使用 <code>pymysql-replication</code> 来伪装成从库拿到出错的 binlog postion 的内容，解析再用。</p><p>当然为保险起见，已经出现不一致的还是要 pt-table-checksum 跑一下。</p><h2 id="7-附-测试-slave-skip-errors-slave-exec-mode"><a href="#7-附-测试-slave-skip-errors-slave-exec-mode" class="headerlink" title="7. 附: 测试 slave_skip_errors, slave_exec_mode"></a>7. 附: 测试 slave_skip_errors, slave_exec_mode</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t_repl_test` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `name` varchar(30) DEFAULT NULL,</span><br><span class="line">  `age` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  UNIQUE KEY `uk_name` (`name`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4</span><br><span class="line"></span><br><span class="line">insert into t_repl_test values(1,&apos;a&apos;,10), (2,&apos;b&apos;,20), (3,&apos;c&apos;,30), (4,&apos;d&apos;,40),(5,&apos;e&apos;,50);</span><br><span class="line"></span><br><span class="line"># 初始化测试数据</span><br><span class="line"># master:</span><br><span class="line">delete from t_repl_test where id=2;</span><br><span class="line"></span><br><span class="line"># slave:</span><br><span class="line">delete from t_repl_test where id=3; insert into t_repl_test values(2,&apos;b&apos;,20);</span><br></pre></td></tr></table></figure><p>每次测试前，数据都初始化成下面的：</p><table><br><tr><td>master</td><td>slave</td></tr><br><tr><br><td><pre><br>mysql&gt; select <em> from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  1 | a    |   10 |<br>|  3 | c    |   30 |<br>|  4 | d    |   40 |<br>|  5 | e    |   50 |<br>+—-+——+——+<br></em></pre></td><br><td><pre><br>mysql&gt; select  from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  1 | a    |   10 |<br>|  2 | b    |   20 |<br>|  4 | d    |   40 |<br>|  5 | e    |   50 |<br>+—-+——+——+<br></pre></td></tr><br></table><h3 id="7-1-delete-测试"><a href="#7-1-delete-测试" class="headerlink" title="7.1 delete 测试"></a>7.1 delete 测试</h3><p><strong>1. slave_skip_errors=1032,1062</strong><br>slave:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select @@slave_skip_errors, @@slave_exec_mode;</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line">| @@slave_skip_errors | @@slave_exec_mode |</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line">| 1032,1062           | STRICT            |</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p><table><br><tr><td>master(每轮测试都执行)</td><td>slave</td></tr><br><tr><br><td><pre><br>mysql&gt; begin;<br>Query OK, 0 rows affected (0.00 sec)<br><br>mysql&gt; delete from t_repl_test where id in (1,3,4);<br>Query OK, 3 rows affected (0.00 sec)<br><br>mysql&gt; delete from t_repl_test where id in (5);<br>Query OK, 1 row affected (0.01 sec)<br><br>mysql&gt; commit;<br>Query OK, 0 rows affected (0.00 sec)<br></pre></td><br><td><pre><br>mysql&gt; select * from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  2 | b    |   20 |<br>|  4 | d    |   40 |<br>+—-+——+——+<br></pre></td></tr><br></table><p>在从库，1和5被删除，4被跳过了，<code>skip_error=1032</code>作用在statement上，并且已经部分成功了的statement 不会回滚。</p><p><strong>2. slave_exec_mode=IDEMPOTENT</strong><br>复原。不是设置skip, 设置idempotent， slave:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select @@slave_skip_errors, @@slave_exec_mode;</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line">| @@slave_skip_errors | @@slave_exec_mode |</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line">| OFF                 | IDEMPOTENT        |</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from t_repl_test;</span><br><span class="line">+----+------+------+</span><br><span class="line">| id | name | age  |</span><br><span class="line">+----+------+------+</span><br><span class="line">|  2 | b    |   20 |</span><br><span class="line">+----+------+------+</span><br></pre></td></tr></table></figure><p>这次1, 4, 5都被删除，也就是4是一个 statement 里面某一个row_event，没有受到 id=3 error 1032的影响。</p><p><strong>注意</strong><br>如果slave同时设置 slave_skip_errors 和 slave_exec_mode，那么优先生效的是 slave_skip_errors。</p><h3 id="7-2-insert"><a href="#7-2-insert" class="headerlink" title="7.2 insert"></a>7.2 insert</h3><p><strong>1. slave_skip_errors=1032,1062 slave_exec_mode=STRICT</strong>  </p><table><br><tr><td>master(每轮测试都执行)</td><td>slave</td></tr><br><tr><br><td><pre><br>mysql&gt; begin;<br>mysql&gt; insert into t_repl_test values(6,’f’,60),<br>(2,’bb’,200),(7,’g’,70);<br>Query OK, 3 rows affected (0.00 sec)<br><br>mysql&gt; insert into t_repl_test values(8,’h’,80);<br>Query OK, 1 row affected (0.01 sec)<br><br>mysql&gt; commit;<br></pre></td><br><td><pre><br><br>mysql&gt; select * from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  1 | a    |   10 |<br>|  2 | b    |   20 |<br>|  4 | d    |   40 |<br>|  5 | e    |   50 |<br>|  6 | f    |   60 |<br>|  8 | h    |   80 |<br>+—-+——+——+<br></pre></td></tr><br></table><p>6成功，2和7失败，8成功。与delete作用范围一致。</p><p><strong>2. slave_skip_errors=OFF slave_exec_mode=IDEMPOTENT</strong><br>slave:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select @@slave_skip_errors, @@slave_exec_mode;</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line">| @@slave_skip_errors | @@slave_exec_mode |</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line">| OFF                 | IDEMPOTENT        |</span><br><span class="line">+---------------------+-------------------+</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from t_repl_test;</span><br><span class="line">+----+------+------+</span><br><span class="line">| id | name | age  |</span><br><span class="line">+----+------+------+</span><br><span class="line">|  1 | a    |   10 |</span><br><span class="line">|  2 | bb   |  200 |</span><br><span class="line">|  4 | d    |   40 |</span><br><span class="line">|  5 | e    |   50 |</span><br><span class="line">|  6 | f    |   60 |</span><br><span class="line">|  7 | g    |   70 |</span><br><span class="line">|  8 | h    |   80 |</span><br><span class="line">+----+------+------+</span><br></pre></td></tr></table></figure><p>6, 7, 8 都插入成功，id=2的id=2被更新。所以从库在 idempotent 模式下遇到1062，是replace操作。</p><p><strong>3. slave_skip_errors=OFF slave_exec_mode=IDEMPOTENT unique_key</strong><br>再来看一个好玩的（id是主键，name是唯一索引）: 从库应用relay log遇到 Duplicate entry 错误有不同处理动作。</p><table><br><tr><td>master</td><td>slave</td></tr><br><tr><br><td><pre><br>mysql&gt; select <em> from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  1 | a    |   10 |<br>|  3 | c    |   30 |<br>|  4 | d    |   40 |<br>+—-+——+——+<br>3 rows in set (0.00 sec)<br><br>mysql&gt; insert into t_repl_test values(9,’b’,200);<br>Query OK, 1 row affected (0.00 sec)<br><br>mysql&gt; update t_repl_test set name=’e’ where id=4;<br>Query OK, 1 row affected (0.01 sec)<br>Rows matched: 1  Changed: 1  Warnings: 0<br><br><br>mysql&gt; select </em> from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  1 | a    |   10 |<br>|  3 | c    |   30 |<br>|  4 | e    |   40 |<br>|  9 | b    |  200 |<br>+—-+——+——+<br>4 rows in set (0.00 sec)<br></pre></td><br><td><pre><br>mysql&gt; select <em> from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  1 | a    |   10 |<br>|  2 | b    |   20 |<br>|  4 | d    |   40 |<br>|  5 | e    |   50 |<br>+—-+——+——+<br>4 rows in set (0.00 sec)<br><br><br><br><br><br><br><br><br>mysql&gt; select </em> from t_repl_test;<br>+—-+——+——+<br>| id | name | age  |<br>+—-+——+——+<br>|  1 | a    |   10 |<br>|  4 | d    |   40 |<br>|  5 | e    |   50 |<br>|  9 | b    |  200 |<br>+—-+——+——+<br>4 rows in set (0.00 sec)<br></pre></td></tr><br></table><p>第一条 insert 值在从库上 name=b 已经存在，违反唯一约束，所以被 <strong>replace</strong> 掉了。<br>第二条 update 值在从库上 name=e 已经存在，违反唯一约束，在从库 <strong>被忽略</strong> 了。看从从库的imdepotent错误日志:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2018-02-02 14:50:35 24325 [Warning] Slave SQL: Could not execute Update_rows event on table d_ec_crmlog.t_repl_test; </span><br><span class="line">Duplicate entry &apos;e&apos; for key &apos;uk_name&apos;, Error_code: 1062; handler error HA_ERR_FOUND_DUPP_KEY; </span><br><span class="line">the event&apos;s master log mysql-bin.000015, end_log_pos 27072, Error_code: 1062</span><br></pre></td></tr></table></figure></p><p>为什么会有这个行为，可以从源码里面找到答案：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Write_rows_log_event::do_before_row_operations()</span><br><span class="line">  if ((slave_exec_mode == SLAVE_EXEC_MODE_IDEMPOTENT) ||</span><br><span class="line">      (m_table-&gt;s-&gt;db_type()-&gt;db_type == DB_TYPE_NDBCLUSTER))</span><br><span class="line">  &#123;</span><br><span class="line">    /*</span><br><span class="line">      We are using REPLACE semantics and not INSERT IGNORE semantics</span><br><span class="line">      when writing rows, that is: new rows replace old rows.  We need to</span><br><span class="line">      inform the storage engine that it should use this behaviour.</span><br><span class="line">    */</span><br><span class="line">    </span><br><span class="line">    /* Tell the storage engine that we are using REPLACE semantics. */</span><br><span class="line">    thd-&gt;lex-&gt;duplicates= DUP_REPLACE;</span><br><span class="line">    </span><br><span class="line">    /*</span><br><span class="line">      Pretend we&apos;re executing a REPLACE command: this is needed for</span><br><span class="line">      InnoDB and NDB Cluster since they are not (properly) checking the</span><br><span class="line">      lex-&gt;duplicates flag.</span><br><span class="line">    */</span><br><span class="line">    thd-&gt;lex-&gt;sql_command= SQLCOM_REPLACE;</span><br><span class="line">    /* </span><br><span class="line">       Do not raise the error flag in case of hitting to an unique attribute</span><br><span class="line">    */</span><br><span class="line">    m_table-&gt;file-&gt;extra(HA_EXTRA_IGNORE_DUP_KEY);</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><hr><p>本文链接地址：<a href="http://seanlook.com/2018/03/11/mysql-replication-error-and-idempotent/">http://seanlook.com/2018/03/11/mysql-replication-error-and-idempotent/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-slave-exec-mode-参数作用&quot;&gt;&lt;a href=&quot;#1-slave-exec-mode-参数作用&quot; class=&quot;headerlink&quot; title=&quot;1. slave_exec_mode 参数作用&quot;&gt;&lt;/a&gt;1. slave_exec_mode 参数作用&lt;/h1&gt;&lt;p&gt;&lt;code&gt;slave_exec_mode&lt;/code&gt; 可以在主从复制中遇到 duplicate-key 和 no-key-found 错误时，自动覆盖或者略过binlog里面这个row_event，避免报错停止复制。&lt;/p&gt;
&lt;p&gt;这个参数原本是解决像 NDB Cluster 多节点写入冲突的情况，也可以在普通主从、双主、环形复制等情况下解决冲突，保持幂等性。幂等性怎么定义，感兴趣的可以阅读&lt;a href=&quot;http://http://blog.wl0.org/2016/05/the-differences-between-idempotent-and-my-suggested-auto-repair-mode/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The differences between IDEMPOTENT and AUTO-REPAIR mode&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;set global slave_exec_mode=IDEMPOTENT&lt;/code&gt; （可以动态修改）使从库运行在 幂等模式，对1062，1032等不同的错误类型，有不同的处理：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;write_row event 遇到主键冲突或唯一索引冲突，这一行被覆写(delete + insert)。&lt;br&gt;delete时候不是full value match，仅需要主键或唯一索引找到记录则删除&lt;/li&gt;
&lt;li&gt;delete_row event 遇到记录不存在，忽略这一行&lt;/li&gt;
&lt;li&gt;update_row event 修改唯一索引导致的冲突，忽略这一行&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意：  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;idempotent 模式都是对有疑问的&lt;strong&gt;行&lt;/strong&gt;进行replace或ignore，不影响其它row。&lt;/li&gt;
&lt;li&gt;idempotent 模式要求表上必须要有主键&lt;/li&gt;
&lt;li&gt;binlog必须是 FULL RBR 模式&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;2-slave-skip-errors&quot;&gt;&lt;a href=&quot;#2-slave-skip-errors&quot; class=&quot;headerlink&quot; title=&quot;2. slave-skip-errors&quot;&gt;&lt;/a&gt;2. slave-skip-errors&lt;/h1&gt;&lt;p&gt;这个参数不能在线修改，只能加到配置文件里面或者启动的时候带上&lt;code&gt;--slave-skip-errors=1032,1062&lt;/code&gt;。除非你真的理解它skip掉了什么，否则不建议使用。&lt;/p&gt;
&lt;p&gt;讲一个我所遇到的坑。在我们的一个分库项目中，需要把一个database里面的数据拆成32份，于是做了个主从，把从库里面不需要的那份删除，但复制过来肯定会报 HA_ERR_KEY_NOT_FOUND 错误，于是这也是所期望的，就设置了&lt;code&gt;--slave-skip-errors=1032&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;但接下来就出现 1062:HA_ERR_FOUND_DUPP_KEY 错误！从库只会删数据，不会写入和更新，怎么会出现重复数据？读者不妨试想一下为什么。&lt;/p&gt;
&lt;p&gt;这里做个说明：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;① insert into t values (1, &amp;apos;a&amp;apos;), (2, &amp;apos;b&amp;apos;), (3, &amp;apos;c&amp;apos;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;② begin;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;③ delete from t where id=1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;④ delete from t where id in (1, 2, 3);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;⑤ insert into t where (3, &amp;apos;c&amp;apos;), (4, &amp;apos;d&amp;apos;), (5, &amp;apos;e&amp;apos;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;⑥ update t set ... id=1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;⑦ commit;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;事务包括显式事务和隐式事务(transaction)，语句①落在binlog里面也会有begin和end&lt;/li&gt;
&lt;li&gt;一个事物可以包含多个语句(statement)&lt;/li&gt;
&lt;li&gt;一个语句可以影响多行(row)，但属于一个event&lt;/li&gt;
&lt;li&gt;一个语句在binlog里面有多个event (row log event, table map event, xid event…)&lt;/li&gt;
&lt;li&gt;event在binlog里面以 event group 组合起来&lt;br&gt;事务引擎如 InnoDB，event group 就一个事务；非事务引擎如 MyISAM，event group就是一条语句&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="replication" scheme="http://seanlook.com/tags/replication/"/>
    
  </entry>
  
  <entry>
    <title>Binlog可视化搜索：实现类似阿里RDS数据追踪功能</title>
    <link href="http://seanlook.com/2018/01/25/maxwell-graylog/"/>
    <id>http://seanlook.com/2018/01/25/maxwell-graylog/</id>
    <published>2018-01-25T07:32:49.000Z</published>
    <updated>2018-01-25T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。</p><p>本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。<br>功能类似：<a href="https://yq.aliyun.com/articles/338423" target="_blank" rel="noopener">10分钟搭建MySQL Binlog分析+可视化方案</a></p><h2 id="1-主要技术"><a href="#1-主要技术" class="headerlink" title="1. 主要技术"></a>1. 主要技术</h2><p>项目地址： <a href="https://github.com/seanlook/maxwell-graylog" target="_blank" rel="noopener">https://github.com/seanlook/maxwell-graylog</a></p><ul><li><p>docker<br>使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。<br>本文基于阿里云的容器服务。  </p></li><li><p>maxwell<br>从mysql server获取binlog和字段信息，组装成json流。建议先阅读 <a href="http://seanlook.com/2018/01/13/maxwell-binlog/">http://seanlook.com/2018/01/13/maxwell-binlog/</a><br>官网：<a href="http://maxwells-daemon.io/" target="_blank" rel="noopener">http://maxwells-daemon.io/</a>  </p></li><li><p>graylog<br>代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。<br>官网：<a href="https://www.graylog.org/" target="_blank" rel="noopener">https://www.graylog.org/</a>  </p></li><li><p>nxlog<br>nxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。<br>参考：<a href="http://blog.csdn.net/weixin_29477879/article/details/52183746" target="_blank" rel="noopener">http://blog.csdn.net/weixin_29477879/article/details/52183746</a>  </p></li><li><p>rabbitmq<br>一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 <a href="http://seanlook.com/2018/01/06/rabbitmq-introduce/">http://seanlook.com/2018/01/06/rabbitmq-introduce/</a> 。<br>你也可以把消息队列换成kafka。</p></li></ul><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/maxwell-graylog.png" alt="maxwell-graylog.png"></p><h2 id="2-使用说明"><a href="#2-使用说明" class="headerlink" title="2. 使用说明"></a>2. 使用说明</h2><h3 id="2-1-举例"><a href="#2-1-举例" class="headerlink" title="2.1 举例"></a>2.1 举例</h3><blockquote><p>查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流</p></blockquote><p>提前创建一个 Swarm容器集群，名字叫 maxwell。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/compose-template.png" alt="compose-template.png"></p><p>在【编排模板】里选择 <em>maxwell-graylog-rabbitmq</em>，【创建应用】下一步修改编排模板：<br>（只修改 environment 里面的变量值）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">mysql-binlogsvr:</span><br><span class="line">  image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3</span><br><span class="line">  volumes:</span><br><span class="line">    - maxwellgraylog_db_data:/var/lib/mysql</span><br><span class="line">  environment:</span><br><span class="line">    DBINSTANCE_ID: rm-bp19t9it7c2998633</span><br><span class="line">    START_TIME: &apos;2018-01-22 13:00:00&apos;</span><br><span class="line">    END_TIME: &apos;2018-01-22 14:00:00&apos;</span><br><span class="line">    ACCESS_ID: LTAIXKHm0v6ob5P4</span><br><span class="line">    ACCESS_SECRET: F7g***************Nll19no</span><br><span class="line">    MYSQL_ROOT_PASSWORD: strongpassword</span><br><span class="line"></span><br><span class="line">maxwell-svr:</span><br><span class="line">  image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3</span><br><span class="line">  depends_on:</span><br><span class="line">    - mysql-binlogsvr</span><br><span class="line">  environment:</span><br><span class="line">    producer: rabbitmq</span><br><span class="line">    MYSQL_HOST:</span><br><span class="line">    MYSQL_USER:</span><br><span class="line">    MYSQL_PASSWORD:</span><br><span class="line">    MYSQL_HOST_GIT: db_some_shard3</span><br><span class="line">    include_dbs:</span><br><span class="line">    include_tables: t_ecsome_detail</span><br><span class="line">    include_column_values:</span><br><span class="line">    init_position:</span><br><span class="line">    rabbitmq_host: 10.81.xx.xxx</span><br><span class="line">    rabbitmq_virtual_host: /maxwell</span><br><span class="line">    rabbitmq_user: admin</span><br><span class="line">    rabbitmq_pass: admin</span><br><span class="line">    kafka_server:</span><br><span class="line">    kafka_producer_partition_by: database</span><br><span class="line">    MAXWELL_OPTS:</span><br><span class="line">  volumes:</span><br><span class="line">    - maxwellgraylog_db_data:/var/lib/mysql</span><br><span class="line">  links:</span><br><span class="line">    - mysql-binlogsvr:mysql_binlogsvr</span><br></pre></td></tr></table></figure></p><h3 id="2-2-变量-参数说明："><a href="#2-2-变量-参数说明：" class="headerlink" title="2.2 变量/参数说明："></a>2.2 变量/参数说明：</h3><ul><li><code>DBINSTANCE_ID</code><br>需要分析哪个实例的binlog。必须提供  </li><li><code>ACCESS_ID</code>, <code>ACCESS_SECRET</code><br>从OSS下载该实例binlog的key，这个key的用户需要RDS的读权限。必须提供  </li><li><code>START_TIME</code>, <code>END_TIME</code><br>需要分析 binlog 大致位于哪个时间段。请尽可能的精确，如果时间范围过大，可能耗时非常久。3个binlog入完graylog大约6分钟。不能保持示例默认的值<br>如果你想从 <code>MYSQL_HOST</code> 直接在线拉取binlog，则不要设置设置 START_TIME 和 END_TIME，程序会一致从当前位置持续读取。  </li><li><code>MYSQL_ROOT_PASSWORD</code><br>mysql binlogsvr 的root的密码。默认为 strongpassword  <a id="more"></a></li><li><code>producer</code><br>指定maxwell产生的binlog json流输出到哪里，完整的支持<code>file</code>, <code>rabbitmq</code>, <code>kafka</code>  </li><li><code>MYSQL_HOST</code>, <code>MYSQL_USER</code>, <code>MYSQL_PASSWORD</code><br>它在两种情况下使用：  <ol><li>前面的<code>START_TIME</code>、<code>END_TIME</code>留空，这里的 MYSQL_HOST 代表的是maxwell直接连接的地址，持续获取binlog。maxwell的 schema_database 也在这个库上(monitor，用户需要有读写这个db的权限)  </li><li>前面的<code>START_TIME</code>、<code>END_TIME</code>有值，并且没有设置 <code>MYSQL_HOST_GIT</code>，那么 MYSQL_HOST 代表的是从这个地址拉取表结构，相当于maxwell的 schema_host 地址（当然获取binlog还是从 mysql_binlogsvr ）  </li></ol></li><li><code>MYSQL_HOST_GIT</code>, <code>MYSQL_HOST_GIT_COMMIT</code><br>从git仓库拉取表结构信息，<code>MYSQL_HOST_GIT</code>指定仓库里面实例目录名，<code>MYSQL_HOST_GIT_COMMIT</code>可以满足指定某个 提交 时候的表机构版本。在 START_TIME, END_TIME 有设置的情况下才有效。<br>仓库见：<a href="http://seanlook.com/2016/11/28/mysql-schema-gather-structure/">http://seanlook.com/2016/11/28/mysql-schema-gather-structure/</a></li><li><code>rabbitmq_host</code>, <code>rabbitmq_virtual_host</code>, <code>rabbitmq_user</code>, <code>rabbitmq_pass</code>, <code>rabbitmq_exchange_type</code><br>在 producer=rabbitmq 才有效。这些rabbitmq_xxx选项，与maxwell配置文件里面的完全相同  </li><li>过滤选项<br><code>include_dbs</code>, <code>include_tables</code>, <code>include_column_values</code><br>与maxwell配置文件里面的完全相同。这里没有列出 exclude_xxx 相关过滤项，如果要指定，请使用 <code>MAXWELL_OPTS</code><br><code>exclude_columns</code>，去除哪些列是值不予展示，可用于脱敏。<br>支持的值参考maxwell的配置文件里面正则说明。  </li><li><code>kafka_server</code><br>在 rabbitmq=kafka 时有效。对应 maxwell 的 <code>kafka.bootstrap.servers</code> 选项<br>其它选项如果要指定，可以使用<code>MAXWELL_OPTS</code>  </li><li><code>MAXWELL_OPTS</code><br>因为现有 environment 变量没有覆盖所有的maxwell选项，所有其它选项可以直接像 maxwell 命令行参数一样，指定在 <code>MAXWELL_OPTS</code> 里面。</li></ul><p>创建完后，可以看到两个容器：<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/maxwell-binlog-container.png" alt="maxwell-binlog-container.png"></p><p>其中 <code>maxwell-svr</code> 在等待 mysql_binlogsvr 就绪:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:08.424411112Z waiting for mysql_binlogsvr prepared</span><br><span class="line">maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:28.427993770Z waiting for mysql_binlogsvr prepared</span><br><span class="line">maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:48.431136523Z binlog download is done, wait more seconds for mysql_binlogsvr ready</span><br></pre></td></tr></table></figure></p><p><code>mysql-binlogsvr</code> 在初始化 mysql server 的数据，下载binlog。完成的标志是在 <code>/var/lib/mysql/initialized.lock</code>里面写入 1 或 2，来通知 maxwell-svr。（1和2的意义见下面的Dockerfile说明）<br>在 <code>maxwell-svr</code> 日志里面看到 <code>INFO  BinlogConnectorLifecycleListener - Binlog connected.</code> 字样，表示已经在binlog往外推。</p><p>此时在 graylog 里面就可以看到输出内容了: <a href="http://graylog.workec.com:3003/search?q=gl2_source_input%3A5a655c3ba002a0526615062a&amp;relative=0" target="_blank" rel="noopener">http://graylog.workec.com:3003/search?q=gl2_source_input%3A5a655c3ba002a0526615062a&amp;relative=0</a></p><p>处理速度大概在 10000msg/s，在graylog里面没有看到新数据进来，就代表分析完成。<br>现在比较麻烦的地方在于，处理完结束后，销毁容器容易，但前面创建的持久存储卷，阿里云的容器服务并不会删除本地的卷，它所提供的存储推荐是 OSS,NAS,云盘 这些存储服务，然后要为它单独创建子账号，单独对某个盘、bucket授权，十分麻烦。</p><p>本地卷并不能自动的删除，如果下次启动这个binlog分析服务，因为挂在的是同样的 db_data，里面已经有脏数据，所以需要<strong>手动删除</strong> 主机上的 <code>rm -rf /var/lib/docker/volumes/maxwellgraylog_db_data/_data/*</code></p><h3 id="2-3-其它编排模板"><a href="#2-3-其它编排模板" class="headerlink" title="2.3 其它编排模板"></a>2.3 其它编排模板</h3><p>上面的示例，是基于 <code>maxwell-graylog-rabbitmq</code> 的编排模板，已经自定义了一下compose模板：</p><ul><li><p><code>maxwell-graylog-rabbitmq</code><br>依赖于外部 rabbitmq server，需要明确指定 <code>rabbitmq_host</code> 等信息。<br>第一次使用，通过<code>rabbitmq-init-for-maxwell.sh</code>去初始化 maxwell-graylog 所需要的exchange,queue等。</p></li><li><p><code>maxwell-graylog-rabbitmq-nodeps</code><br>会比上面的多起一个容器： rabbitmq-server，但是它的数据要通过容器集群的LB，才能被外面的graylog服务消费。<br>它的 <code>rabbitmq_host</code>被指定为<code>maxwell-rabbitmq-server</code> (container link)</p></li><li><p><code>maxwell-graylog-file</code><br>不适用消息队列，直接写入文件，通过 nxlog 将数据推到 graylog，所以会多出一个 nxlog 容器<br>多出三个 environment variabeles:  </p><ul><li><code>graylogserver</code><br>nxlog将“日志”上报的 graylog server 地址  </li><li><code>graylog_maxwell_gelf_port</code><br>graylog 节点为接收这个消息监听的端口 (NXlog Outputs)  </li><li><code>graylog_maxwell_source_collector</code><br>graylog 为这个消息定义好的collecter名字 （collecter是graylog的入口，在它之上定义流转、拆解、存储等流程）</li></ul><p>graylog的配置方法和搜索使用，见后文。</p></li><li><p><code>maxwell-graylog-kafka</code><br>使用 kafka 作为消息队列。需要指定现有的 kafka_server 。<br>这个编排模板，没有提供很详细的实现，请结合 <code>MAXWELL_OPTS</code> 使用。</p></li></ul><p><strong>提示：</strong></p><ol><li>在使用时，如果容器启动失败，观察日志后，一般可以放心的直接重启容器，已做良好的修复处理。  </li><li>选择哪个模板和设置什么变量值，主要考虑两个因素：从哪里获取binlog，maxwell将binlog生产到哪里</li><li>输出到file，nxlog读取的交给graylog处理的压力会非常大，可能会导致graylog响应慢。输出到rabbitmq，可以控制流入graylog的速度(Allow throttling this input?)</li></ol><h3 id="2-4-docker-compose-yml"><a href="#2-4-docker-compose-yml" class="headerlink" title="2.4 docker-compose.yml"></a>2.4 docker-compose.yml</h3><p>阿里云的编排模板，与标准的 docker compose 并不完全一样。在 docker-compose 目录中，提供了6种编排方案，可使用自建的docker平台来做。<br>4个容器和变量的组合，应对不同的场景：</p><ul><li><p><strong>docker-compose.file.yml</strong><br>启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。</p></li><li><p><strong>docker-compose.file-schema.yml</strong><br>启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。<br>表结构从 schema_host 获取，而不是git仓库。monitor用户需要 REPLICATION SLAVE, REPLICATION CLIENT 权限。</p></li><li><p><strong>docker-compose.rabbitmq.yml</strong><br>启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有rabbitmq。</p></li><li><p><strong>docker-compose.rabbitmq-nodeps.yml</strong><br>启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。<br>不依赖外部rabbitmq。</p></li><li><p><strong>docker-compose.rabbitmq-nobinlog-svr.yml</strong><br>启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。<br>mysql-binlogsvr启动后会停止，这里直接从 MYSQL_HOST 在线持续拉取binlog，用户需要能够读取表结构的权限。</p></li><li><p><strong>docker-compose.kafka.yml</strong><br>启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有kafka。</p></li></ul><p>也可以逐个启动容器，不适用 docker-compose.yml。各个容器详情见后文。</p><h2 id="3-graylog配置和使用"><a href="#3-graylog配置和使用" class="headerlink" title="3. graylog配置和使用"></a>3. graylog配置和使用</h2><p>生成的binlog json流要在graylog里面可视化展示，还需要对graylog设置。下面分别以 file 和 rabbitmq 的输出为例。</p><h3 id="3-1-Input-file"><a href="#3-1-Input-file" class="headerlink" title="3.1 Input: file"></a>3.1 Input: file</h3><p>上面已经通过 maxwell容器 将数据写入了 <code>output_file</code>=<code>/var/lib/mysql/maxwell_binlog_stream.json.log</code>，又通过 nxlog容器 tail监控这个日志文件。</p><ol><li><strong>创建一个 GELF TCP Input</strong><br>[System / Inputs] -&gt; [Inputs]<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/graylog-fileinput.png" alt="graylog-fileinput.png"></li></ol><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/graylog-fileinput-create.png" alt="graylog-fileinput-create.png"></p><p>勾选 Global 表示所有的 graylog 集群节点，都可以接收这个日志，Port： <code>12201</code> 便是监听的端口。前文编排模板里面要求提供的参数 <code>graylogserver</code> 和 <code>graylog_maxwell_gelf_port</code>，就是从这来的。</p><p>那么 Collecter <code>graylog_maxwell_source_collector</code> 呢，可以任意设置一个字符串。在标准的 graylog 配置流程里面，collecter 就是一个 nxlog 进程，一般一台机器就一个 nxlog，所以collecter对应的其实是收集日志的机器。</p><p>nxlog 是一个单独的组件，与graylog没多大关系，而为了将两者整合在一起，需要 graylog-sidecar 来下发 nxlog 的配置，告诉它日志目录在哪、怎么读取日志。</p><p>所以我们的docker容器只需要nxlog进程，不需要graylog-sidecar来交代配置，也就不需要在graylog Web界面配置NXLog Outputs/Inputs，而是直接通过变量传递来完成 nxlog.conf 模板的配置。</p><p>下面的过程实际是不需要的，只是为了理解如何生成 nxlog.conf。</p><ol start="2"><li>Create configuration<br>给这个 configuration 设置 <code>tags</code> 例如<code>maxwell_binlog</code>。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/graylog-nxlog-config.png" alt="graylog-nxlog-config.png"></li></ol><p>graylog-sidecar 会把 tag 打给某个机器(collecter)，告诉nxlog或其他收集组件，当前机器有哪几种日志需要收集</p><ol start="3"><li><p>编写 NXLog Outputs<br>相当于 nxlog.conf 中 <code>&lt;Output&gt;</code>部分，Host、Port 即第1步里面的graylog接收binlog json流而监听的地址和端口。<br>Type选择 <code>[NXLog]GELF TCP output</code>。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/graylog-nxlog-output.png" alt="graylog-nxlog-output.png"></p></li><li><p>编写 NXLog Inputs<br>相当于 nxlog.conf 中 <code>&lt;Input&gt;</code>部分，这里指定日志输入来源于<strong>文件</strong>,<code>Type</code>选择<code>[NXLog]file input</code><br><img src="http://7q5fot.com1.z0.glb.clouddn.com/graylog-nxlog-input.png" alt="graylog-nxlog-input.png"></p></li></ol><p><code>Forward to</code> 设置刚才创建的 Output<br><code>File</code>，要收集的日志路径为<code>/var/lib/mysql/maxwell_binlog_stream.json.log</code><br><code>Pool Interval</code>，即检查日志文件的间隔时间。剩下的保持默认</p><ol start="5"><li><strong>使用 JSON extractor 解析message</strong><br>经过上面几步，启动maxwell和nxlog服务/容器之后，在graylog的 WebUI 上找到第1步建的Input，就可以看到有日志进来了。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/maxwell-graylog-message.png" alt="maxwell-graylog-message.png"></li></ol><p>选择任意一个message，[Create extractor for field message] -&gt; [JSON]，将json数据解压出来，存储，便可以快速根据字段名来搜索binlog内容。</p><h3 id="3-2-Input-rabbitmq"><a href="#3-2-Input-rabbitmq" class="headerlink" title="3.2 Input: rabbitmq"></a>3.2 Input: rabbitmq</h3><p>使用rabbitmq更简单，不需要nxlog，直接在第1步里，把新建<code>GELF TCP</code>改成<code>Raw/Plaintext AMQP</code>。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/maxwell-graylog-rabbitmq.png" alt="maxwell-graylog-rabbitmq.png"></p><p>需要填写的就是AMQP协议里broker, port, user, exchange, queue, routing_key。<br>就可以在binlog里面，可视化看到binlog内容了。</p><h3 id="3-3-在graylog里面搜索binlog日志"><a href="#3-3-在graylog里面搜索binlog日志" class="headerlink" title="3.3 在graylog里面搜索binlog日志"></a>3.3 在graylog里面搜索binlog日志</h3><p>搜索语法：<a href="http://docs.graylog.org/en/2.4/pages/queries.html" target="_blank" rel="noopener">http://docs.graylog.org/en/2.4/pages/queries.html</a></p><p>例如，查看 t_ecsome_detail 表中 f_some_id=1242036566 在给定时间内的变化过程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gl2_source_input:5a38cc9bd56c001305aaefc0 AND data_f_some_id: 1242036566 OR old_f_some_id: 1242036566</span><br></pre></td></tr></table></figure></p><p>例如使用Quick values功能，快速得到全国各地区对t_ecsome_detail表的操作量：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gl2_source_input:5a38cc9bd56c001305aaefc0 AND NOT data_f_company_region: 0</span><br></pre></td></tr></table></figure></p><p>我们有做db分库，查看各个分库下的请求量数据是不是平均的，database: quick value：<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/maxwell-graylog-quickvalue.png" alt="maxwell-graylog-quickvalue.png"></p><h2 id="4-容器镜像说明：Dockerfile"><a href="#4-容器镜像说明：Dockerfile" class="headerlink" title="4. 容器镜像说明：Dockerfile"></a>4. 容器镜像说明：Dockerfile</h2><p>本节是关于细节实现的部分，与上面的介绍会略有重复。</p><h3 id="4-1-Dockerfile-binlogsvr"><a href="#4-1-Dockerfile-binlogsvr" class="headerlink" title="4.1 Dockerfile.binlogsvr"></a>4.1 Dockerfile.binlogsvr</h3><p>承载 binlog 的mysql server服务。<br>它首先根据提供的数据库实例信息、日期时间信息，去OSS拉取已经上传的binlog到本地，修改 <code>mysql-bin.index</code>文件，提供binlog来源。<br>因为容器停止或者销毁后，内部的数据也随之丢失，所以需要一个主机上的目录来挂在到容器中，做数据的持久化，我们把这个数据卷命名为 db_data 。</p><ul><li><code>binlogsvr-entrypoint.sh</code><br>容器入口。因为 mysql server 启动第一次都要进行初始化，假如容器启动失败，再次启动时不需要再次初始化。<br>脚本内通过 <code>lockfile=/var/lib/mysql/initialized.lock</code> 区分三种工作模式：  <ul><li>lockfile 存在：mysql server 已经初始化  </li><li>lockfile 内容为0：mysql server 作为binlogsvr  </li><li>lockfile 内容为2: binlog已经下载完成。避免重启容器导致重复下载binlog  </li><li>lockfile 内容为1：该容器无用，因为判断 START_TIME 和 END_TIME 为空。实际上表示后续maxwell  拉取，是直接从原 MYSQL_HOST 读取，不需要该binlogsvr<br>lockfile 里面的值会被 maxwell 容器读取，以便决定工作模式</li></ul></li></ul><ul><li><p><code>download_binlog.py</code><br>从阿里OSS下载binlog，需要提供 DBINSTANCE_ID 和 时间界限。<br>requirements.txt：python环境依赖</p></li><li><p><code>mysql_3306.cnf</code><br>binlogsvr的启动配置文件</p></li></ul><h3 id="4-2-Dockerfile-maxwell"><a href="#4-2-Dockerfile-maxwell" class="headerlink" title="4.2 Dockerfile.maxwell"></a>4.2 Dockerfile.maxwell</h3><p>  maxwell服务容器，主版本1.12.0，加上修改了点内容：<a href="https://github.com/seanlook/maxwell" target="_blank" rel="noopener">https://github.com/seanlook/maxwell</a>  </p><ul><li><p><code>maxwell-entrypoint.sh</code><br>容器入口。会等待 mysql_binlogsvr 初始化完成，maxwell的结构、postion等信息存放在binlogsvr的 monitor 库。  </p><ul><li><code>work_mode=1</code>: 直接从 <code>MYSQL_HOST</code> 拉取binlog，不需要binlogsvr，可以实现持续读取现网的binlog  </li><li><code>work_mode=0</code>: 从 mysql_binlogsvr 拉取binlog<br>该模式下因为 binlogsvr 里并没有maxwell需要的表结构，支持两种方法： <ul><li>如果设置了 <code>MYSQL_HOST_GIT</code>，表示从我们的git仓库里面拉取表结构  </li><li>否则从 <code>MYSQL_HOST</code> 拉取表结构，对应maxwell变量 <code>schema_host</code> 。即这个时候的 MYSQL_HOST 不是指定binlog来源，而是表结构来源。  </li><li>如果都没设置，异常退出  </li></ul></li></ul><p>maxwell启动时需要指定 init_position，即从binlog_svr哪个binlog位置开始拉取：  </p><ul><li>如果从直接从原数据库实例拉取，则指定为最新的binlog起始点；  </li><li>如果为 binlogsvr 拉取，则指定为下载的binlog最小的那个binlog起始点；  </li><li>在容器启动的时候，也可以直接指定 init_postion ，优先生效。<br><code>lockfile=/var/lib/mysql/initialized_maxwell.lock</code> 表示已经通过 init_postion 启动，如果重启maxwell容器，应该从上次停止的地方继续。</li></ul><p>容器启动时，可以指定 producer 为 file, rabbitmq, kafka，根据对应的生产者，应该设置子选项。见后文。  </p></li></ul><ul><li><p><code>maxwell-retrive-tablemeta.sh</code><br>从git拉取所需要的表结构，并用 myloader 工具导入到 binlogsvr 。<br>因为考虑到需求通常要过滤表，所以这里也这会在 binlogsvr 创建需要的表结构。<br>如果指定了 <code>MYSQL_HOST_GIT_COMMIT</code>，可以拉取git上历史表结构。<br><code>id_rsa</code>：文件是拉起表结构用的 ssh key。 </p></li><li><p><code>maxwell-src-1.12.0.tar.gz</code>:<br>已下载的maxwell包，会通过maven编译。  </p></li></ul><h3 id="4-3-Dockerfile-nxlog"><a href="#4-3-Dockerfile-nxlog" class="headerlink" title="4.3 Dockerfile.nxlog"></a>4.3 Dockerfile.nxlog</h3><p>  在 <code>producer=file</code> 时，maxwell产生的binlog stream 是文件，要把文件放到 graylog 用到 nxlog 。<br>  它也会挂在 db_data，读取 <code>output_file=/var/lib/mysql/maxwell_binlog_stream.json.log</code> 内容，发送到 graylog server 。  </p><ul><li><code>graylogserver</code>: graylog server 地址  </li><li><code>graylog_maxwell_gelf_port</code>: 在graylog提前配置好的接收maxwell数据的端口  </li><li><p><code>graylog_maxwell_source_collector</code>: 对应graylog的 collector id.<br>配置graylog 方法见后文。  </p></li><li><p><code>nxlog-entrypoint.sh</code><br>容器入口。主要是对 /etc/nxlog/nxlog.conf 进行变量替换。<br>提示：也会读取 <code>/var/lib/mysql/maxwell_instance_id</code> 里面由 mysql_binlogsvr 传递过来的 instance_id 作为 message 的一部分</p></li><li><p><code>nxlog.conf</code><br>nxlog的配置文件模板，用于替换成上面的变量。  </p></li></ul><h3 id="4-4-Dockerfile-rabbitmq"><a href="#4-4-Dockerfile-rabbitmq" class="headerlink" title="4.4 Dockerfile.rabbitmq"></a>4.4 Dockerfile.rabbitmq</h3><p>  在 <code>producer=rabbitmq</code> 时，maxwell需要 rabbitmq server 作为队列。<br>  这里提供两种使用方法：  </p><ul><li>如果已经有现成的 rabbitmq ，则自己创建 vhost, exchange, user，需要提供的内容见 <code>rabbitmq-init-formaxwell.sh</code>  </li><li><p>如果没有rabbitmq，则通过这个 Dockerfile 创建 rabbitmq server container  </p></li><li><p><code>rabbitmq-entrypoint.sh</code><br>容器入口。只是为了调用 <code>rabbitmq-init-formaxwell.sh</code>，在rabbitmq起来后，创建 <code>--vhost=/maxwell --username=admin --password=admin</code>,<code>exchange=maxwell.binlog queue=maxwell_binlog binding_key=#</code> 给maxwell和graylog使用。<br>在后台通过 <a href="https://github.com/vishnubob/wait-for-it" target="_blank" rel="noopener"><code>wait-for-it.sh</code></a> 来同步等待 rabbitmq ok.  </p></li></ul><h3 id="4-5-build-image"><a href="#4-5-build-image" class="headerlink" title="4.5 build image"></a>4.5 build image</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">docker build -f Dockerfile.binlogsvr . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3</span><br><span class="line">docker build -f Dockerfile.maxwell . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3</span><br><span class="line">docker build -f Dockerfile.nxlog . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3</span><br><span class="line">docker build -f Dockerfile.rabbitmq . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3</span><br><span class="line"></span><br><span class="line">docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3</span><br><span class="line">docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3</span><br><span class="line">docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3</span><br><span class="line">docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3</span><br></pre></td></tr></table></figure><p><strong>参考</strong></p><hr><p>原文连接地址：<a href="http://seanlook.com/2018/01/25/maxwell-graylog/">http://seanlook.com/2018/01/25/maxwell-graylog/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。&lt;/p&gt;
&lt;p&gt;本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。&lt;br&gt;功能类似：&lt;a href=&quot;https://yq.aliyun.com/articles/338423&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;10分钟搭建MySQL Binlog分析+可视化方案&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-主要技术&quot;&gt;&lt;a href=&quot;#1-主要技术&quot; class=&quot;headerlink&quot; title=&quot;1. 主要技术&quot;&gt;&lt;/a&gt;1. 主要技术&lt;/h2&gt;&lt;p&gt;项目地址： &lt;a href=&quot;https://github.com/seanlook/maxwell-graylog&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/seanlook/maxwell-graylog&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;docker&lt;br&gt;使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。&lt;br&gt;本文基于阿里云的容器服务。  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;maxwell&lt;br&gt;从mysql server获取binlog和字段信息，组装成json流。建议先阅读 &lt;a href=&quot;http://seanlook.com/2018/01/13/maxwell-binlog/&quot;&gt;http://seanlook.com/2018/01/13/maxwell-binlog/&lt;/a&gt;&lt;br&gt;官网：&lt;a href=&quot;http://maxwells-daemon.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://maxwells-daemon.io/&lt;/a&gt;  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;graylog&lt;br&gt;代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。&lt;br&gt;官网：&lt;a href=&quot;https://www.graylog.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.graylog.org/&lt;/a&gt;  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;nxlog&lt;br&gt;nxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。&lt;br&gt;参考：&lt;a href=&quot;http://blog.csdn.net/weixin_29477879/article/details/52183746&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://blog.csdn.net/weixin_29477879/article/details/52183746&lt;/a&gt;  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;rabbitmq&lt;br&gt;一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 &lt;a href=&quot;http://seanlook.com/2018/01/06/rabbitmq-introduce/&quot;&gt;http://seanlook.com/2018/01/06/rabbitmq-introduce/&lt;/a&gt; 。&lt;br&gt;你也可以把消息队列换成kafka。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/maxwell-graylog.png&quot; alt=&quot;maxwell-graylog.png&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;2-使用说明&quot;&gt;&lt;a href=&quot;#2-使用说明&quot; class=&quot;headerlink&quot; title=&quot;2. 使用说明&quot;&gt;&lt;/a&gt;2. 使用说明&lt;/h2&gt;&lt;h3 id=&quot;2-1-举例&quot;&gt;&lt;a href=&quot;#2-1-举例&quot; class=&quot;headerlink&quot; title=&quot;2.1 举例&quot;&gt;&lt;/a&gt;2.1 举例&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;提前创建一个 Swarm容器集群，名字叫 maxwell。&lt;br&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/compose-template.png&quot; alt=&quot;compose-template.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;在【编排模板】里选择 &lt;em&gt;maxwell-graylog-rabbitmq&lt;/em&gt;，【创建应用】下一步修改编排模板：&lt;br&gt;（只修改 environment 里面的变量值）&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql-binlogsvr:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  volumes:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - maxwellgraylog_db_data:/var/lib/mysql&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  environment:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    DBINSTANCE_ID: rm-bp19t9it7c2998633&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    START_TIME: &amp;apos;2018-01-22 13:00:00&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    END_TIME: &amp;apos;2018-01-22 14:00:00&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ACCESS_ID: LTAIXKHm0v6ob5P4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ACCESS_SECRET: F7g***************Nll19no&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    MYSQL_ROOT_PASSWORD: strongpassword&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;maxwell-svr:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  depends_on:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - mysql-binlogsvr&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  environment:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    producer: rabbitmq&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    MYSQL_HOST:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    MYSQL_USER:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    MYSQL_PASSWORD:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    MYSQL_HOST_GIT: db_some_shard3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    include_dbs:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    include_tables: t_ecsome_detail&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    include_column_values:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    init_position:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    rabbitmq_host: 10.81.xx.xxx&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    rabbitmq_virtual_host: /maxwell&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    rabbitmq_user: admin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    rabbitmq_pass: admin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    kafka_server:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    kafka_producer_partition_by: database&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    MAXWELL_OPTS:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  volumes:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - maxwellgraylog_db_data:/var/lib/mysql&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  links:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    - mysql-binlogsvr:mysql_binlogsvr&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h3 id=&quot;2-2-变量-参数说明：&quot;&gt;&lt;a href=&quot;#2-2-变量-参数说明：&quot; class=&quot;headerlink&quot; title=&quot;2.2 变量/参数说明：&quot;&gt;&lt;/a&gt;2.2 变量/参数说明：&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;DBINSTANCE_ID&lt;/code&gt;&lt;br&gt;需要分析哪个实例的binlog。必须提供  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;ACCESS_ID&lt;/code&gt;, &lt;code&gt;ACCESS_SECRET&lt;/code&gt;&lt;br&gt;从OSS下载该实例binlog的key，这个key的用户需要RDS的读权限。必须提供  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;START_TIME&lt;/code&gt;, &lt;code&gt;END_TIME&lt;/code&gt;&lt;br&gt;需要分析 binlog 大致位于哪个时间段。请尽可能的精确，如果时间范围过大，可能耗时非常久。3个binlog入完graylog大约6分钟。不能保持示例默认的值&lt;br&gt;如果你想从 &lt;code&gt;MYSQL_HOST&lt;/code&gt; 直接在线拉取binlog，则不要设置设置 START_TIME 和 END_TIME，程序会一致从当前位置持续读取。  &lt;/li&gt;
&lt;li&gt;&lt;code&gt;MYSQL_ROOT_PASSWORD&lt;/code&gt;&lt;br&gt;mysql binlogsvr 的root的密码。默认为 strongpassword
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="binlog" scheme="http://seanlook.com/tags/binlog/"/>
    
  </entry>
  
  <entry>
    <title>基于MySQL binlog增量数据同步方案(maxwell+rabbimt+pydbsync)</title>
    <link href="http://seanlook.com/2018/01/14/rabbitmq-maxwell-consumer/"/>
    <id>http://seanlook.com/2018/01/14/rabbitmq-maxwell-consumer/</id>
    <published>2018-01-14T07:32:49.000Z</published>
    <updated>2018-01-14T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>应用场景：同 <a href="http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/">http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/</a> ，但更灵活：</p><blockquote><p>实时同步部分表到另外一个数据库实例<br>比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。<br>另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。</p><p>正式切库时的回滚措施<br>比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。</p><p>数据库闪回<br>关于数据库误操作的闪回方案，见 <a href="http://seanlook.com/2017/03/03/mysql-flashback_use_purged-binlog/">文章MySQL根据离线binlog快速闪回</a> 。<code>binlog2sql</code>的 <code>-B</code> 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。</p><p>binlog搜索功能<br>目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。<br>结合graylog可以实现阿里云RDS类似的数据追踪功能。见 <a href="http://seanlook.com/2018/01/25/maxwell-graylog/">http://seanlook.com/2018/01/25/maxwell-graylog/</a> </p></blockquote><p>rabbitmq介绍：<a href="http://seanlook.com/2018/01/06/rabbitmq-introduce/">http://seanlook.com/2018/01/06/rabbitmq-introduce/</a></p><p>maxwell介绍：<a href="http://seanlook.com/2018/01/13/maxwell-binlog/">http://seanlook.com/2018/01/13/maxwell-binlog/</a></p><p>数据已经生成，要完成 MySQL binlog 增量数据同步，还差一个消费者程序，将rabbitmq里面的消息取出来，在目标库重放：</p><ul><li><strong> <a href="https://github.com/seanlook/pydbsync" target="_blank" rel="noopener">https://github.com/seanlook/pydbsync</a> </strong></li></ul><p>目前这个增量程序重放动作是：</p><ul><li>binlog里面 insert 和 update 行，都变成 replace into </li><li>binlog里面 delele ，变成 delete ignore xxx limit 1</li><li>alter/create，原封不动</li></ul><p>所以如果表上没有主键或者唯一索引，是非常难搞定的，原本的update变成 replace into 多插入一条数据。当然如果把 update 事件改成 <code>update tables set f1=v1,f2=v2 where f1=v1,f2=vv2 limit 1</code> 也没毛病。</p><p>使用python3，安装rabbitmq 的python客户端即可：<code>pip install pika</code><br><a id="more"></a></p><ul><li><p><strong>config.py</strong><br>增量程序的配置文件</p><ul><li>db_info: 指定要写入的目标db</li><li>rabbitmq_conn_info: 增量数据的来源，rabbitmq连接信息 </li><li>rabbitmq_queue_bind: 指定怎么划分队列<br>默认共用一个队列，按照范例的的格式，根据表的binlog变更量，来划分队列</li><li><p>binary_columns: 指定有哪些是二进制列，因为需要根据提供的信息 base64_decode 成真实数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">select TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, DATA_TYPE from information_schema.`COLUMNS` </span><br><span class="line">where DATA_TYPE in (&apos;binary&apos;, &apos;varbinary&apos;, &apos;blob&apos;, &apos;bit&apos;, &apos;tinyblob&apos;, &apos;mediumblob&apos;, &apos;longblob&apos;)</span><br></pre></td></tr></table></figure><p>没有则留空</p></li><li><p>timestamp_columns: 指定哪些是timestamp类型的列，因为要处理时区的问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select TABLE_SCHEMA, TABLE_NAME, COLUMN_NAME, DATA_TYPE from information_schema.`COLUMNS` where DATA_TYPE = &apos;timestamp&apos;</span><br></pre></td></tr></table></figure><p>没有则留空</p></li><li>dbname_rewrite: 是否修改同步前后的 database name。<br>没有修改则留空</li></ul></li><li><p><strong>mysql_sync.py</strong><br>启动同步。可以用多线程，或多进程<br>默认线程/进程数与 <code>rabbitmq_queue_bind</code> 指定的队列数相同。</p></li><li><p><strong>pydbsync.py</strong><br>通用的增量同步的核心程序。</p><ul><li><code>binlog_consumer.py</code> 是做some分库过程中用的核心程序，因为要对来自binlog的数据，根据 f_some_id 取模，插入到不同的 d_ec_someX 上，需要许多的特殊处理。</li></ul></li></ul><hr><p>原文连接地址：<a href="http://seanlook.com/2018/01/14/rabbitmq-maxwell-consumer/">http://seanlook.com/2018/01/14/rabbitmq-maxwell-consumer/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;应用场景：同 &lt;a href=&quot;http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/&quot;&gt;http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/&lt;/a&gt; ，但更灵活：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;实时同步部分表到另外一个数据库实例&lt;br&gt;比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。&lt;br&gt;另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。&lt;/p&gt;
&lt;p&gt;正式切库时的回滚措施&lt;br&gt;比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。&lt;/p&gt;
&lt;p&gt;数据库闪回&lt;br&gt;关于数据库误操作的闪回方案，见 &lt;a href=&quot;http://seanlook.com/2017/03/03/mysql-flashback_use_purged-binlog/&quot;&gt;文章MySQL根据离线binlog快速闪回&lt;/a&gt; 。&lt;code&gt;binlog2sql&lt;/code&gt;的 &lt;code&gt;-B&lt;/code&gt; 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。&lt;/p&gt;
&lt;p&gt;binlog搜索功能&lt;br&gt;目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。&lt;br&gt;结合graylog可以实现阿里云RDS类似的数据追踪功能。见 &lt;a href=&quot;http://seanlook.com/2018/01/25/maxwell-graylog/&quot;&gt;http://seanlook.com/2018/01/25/maxwell-graylog/&lt;/a&gt; &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;rabbitmq介绍：&lt;a href=&quot;http://seanlook.com/2018/01/06/rabbitmq-introduce/&quot;&gt;http://seanlook.com/2018/01/06/rabbitmq-introduce/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;maxwell介绍：&lt;a href=&quot;http://seanlook.com/2018/01/13/maxwell-binlog/&quot;&gt;http://seanlook.com/2018/01/13/maxwell-binlog/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;数据已经生成，要完成 MySQL binlog 增量数据同步，还差一个消费者程序，将rabbitmq里面的消息取出来，在目标库重放：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt; &lt;a href=&quot;https://github.com/seanlook/pydbsync&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/seanlook/pydbsync&lt;/a&gt; &lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前这个增量程序重放动作是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;binlog里面 insert 和 update 行，都变成 replace into &lt;/li&gt;
&lt;li&gt;binlog里面 delele ，变成 delete ignore xxx limit 1&lt;/li&gt;
&lt;li&gt;alter/create，原封不动&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以如果表上没有主键或者唯一索引，是非常难搞定的，原本的update变成 replace into 多插入一条数据。当然如果把 update 事件改成 &lt;code&gt;update tables set f1=v1,f2=v2 where f1=v1,f2=vv2 limit 1&lt;/code&gt; 也没毛病。&lt;/p&gt;
&lt;p&gt;使用python3，安装rabbitmq 的python客户端即可：&lt;code&gt;pip install pika&lt;/code&gt;&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="binlog" scheme="http://seanlook.com/tags/binlog/"/>
    
      <category term="rabbitmq" scheme="http://seanlook.com/tags/rabbitmq/"/>
    
      <category term="maxwell" scheme="http://seanlook.com/tags/maxwell/"/>
    
  </entry>
  
  <entry>
    <title>自建Binlog订阅服务 —— Maxwell</title>
    <link href="http://seanlook.com/2018/01/13/maxwell-binlog/"/>
    <id>http://seanlook.com/2018/01/13/maxwell-binlog/</id>
    <published>2018-01-13T07:32:49.000Z</published>
    <updated>2018-01-13T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>Maxwell 是java语言编写的能够读取、解析MySQL binlog，将行更新以json格式发送到 Kafka、RabbitMQ、AWS Kinesis、Google Cloud Pub/Sub、文件，有了增量的数据流，可以想象的应用场景实在太多了，如ETL、维护缓存、收集表级别的dml指标、增量到搜索引擎、数据分区迁移、切库binlog回滚方案，等等。</p><p>它还提供其它功能：</p><ul><li>支持<code>SELECT * FROM table</code> 的方式做全量数据初始化</li><li>支持主库发生failover后，自动恢复binlog位置（GTID）</li><li>灵活的对数据进行分区，解决数据倾斜的问题。kafka支持 database, table, column等级别的数据分区</li><li>它的实现方式是伪装成MySQL Server的从库，接收binlog events，然后根据schemas信息拼装，支持ddl,xid,rows等各种event.</li></ul><p>maxwell由 zendesk 开源：<a href="https://github.com/zendesk/maxwell" target="_blank" rel="noopener">https://github.com/zendesk/maxwell</a> ，而且维护者相当活跃。</p><p>网上已有人对 Alibaba Cannal, Zendesk Maxwell, Yelp mysql_streamer进行对比，见文后参考 实时抓取MySQL的更新数据到Hadoop。</p><p>类似功能的还有：<a href="http://debezium.io/docs/connectors/mysql/" target="_blank" rel="noopener">http://debezium.io/docs/connectors/mysql/</a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>使用 maxwell 非常简单，只需要jdk环境<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk-1.8.0.121-1.b13.el6.x86_64</span><br><span class="line"></span><br><span class="line">curl -sLo - https://github.com/zendesk/maxwell/releases/download/v1.12.0/maxwell-1.12.0.tar.gz \</span><br><span class="line">       | tar zxvf -</span><br><span class="line">cd maxwell-1.12.0</span><br><span class="line"></span><br><span class="line"># 默认寻找当前目录下的 config.properties 配置文件</span><br></pre></td></tr></table></figure></p><p>要求 mysql server binlog格式是 <code>ROW</code>， row_image 是 <code>FULL</code>。感受一下输出结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update test.e set m = 5.444, c = now(3) where id = 1;</span><br><span class="line">&#123;</span><br><span class="line">   &quot;database&quot;:&quot;test&quot;,</span><br><span class="line">   &quot;table&quot;:&quot;e&quot;,</span><br><span class="line">   &quot;type&quot;:&quot;update&quot;,</span><br><span class="line">   &quot;ts&quot;:1477053234,</span><br><span class="line">   &quot;commit&quot;: true,</span><br><span class="line">   ...</span><br><span class="line">   &quot;data&quot;:&#123;</span><br><span class="line">      &quot;id&quot;:1,</span><br><span class="line">      &quot;m&quot;:5.444,</span><br><span class="line">      &quot;c&quot;:&quot;2016-10-21 05:33:54.631000&quot;,</span><br><span class="line">      &quot;comment&quot;:&quot;I am a creature of light.&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;old&quot;:&#123;</span><br><span class="line">      &quot;m&quot;:4.2341,</span><br><span class="line">      &quot;c&quot;:&quot;2016-10-21 05:33:37.523000&quot;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">mysql&gt; create table test.e ( ... )</span><br><span class="line">&#123;</span><br><span class="line">   &quot;type&quot;:&quot;table-create&quot;,</span><br><span class="line">   &quot;database&quot;:&quot;test&quot;,</span><br><span class="line">   &quot;table&quot;:&quot;e&quot;,</span><br><span class="line">   &quot;def&quot;:&#123;</span><br><span class="line">      &quot;database&quot;:&quot;test&quot;,</span><br><span class="line">      &quot;charset&quot;:&quot;utf8mb4&quot;,</span><br><span class="line">      &quot;table&quot;:&quot;e&quot;,</span><br><span class="line">      &quot;columns&quot;:[</span><br><span class="line">         &#123;&quot;type&quot;:&quot;int&quot;, &quot;name&quot;:&quot;id&quot;, &quot;signed&quot;:true&#125;,</span><br><span class="line">         &#123;&quot;type&quot;:&quot;double&quot;, &quot;name&quot;:&quot;m&quot;&#125;,</span><br><span class="line">         &#123;&quot;type&quot;:&quot;timestamp&quot;, &quot;name&quot;:&quot;c&quot;, &quot;column-length&quot;:6&#125;,</span><br><span class="line">         &#123;&quot;type&quot;:&quot;varchar&quot;, &quot;name&quot;:&quot;comment&quot;, &quot;charset&quot;:&quot;latin1&quot;&#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;primary-key&quot;:[</span><br><span class="line">         &quot;id&quot;</span><br><span class="line">      ]</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;ts&quot;:1477053126000,</span><br><span class="line">   &quot;sql&quot;:&quot;create table test.e ( id int(10) not null primary key auto_increment, m double, c timestamp(6), comment varchar(255) charset &apos;latin1&apos; )&quot;,</span><br><span class="line">   &quot;position&quot;:&quot;master.000006:800050&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>data</code>是 After image, <code>old</code> 是 Before image。 insert 只有后镜像，delete只有前镜像（<code>data</code>）<br><code>type</code>是语句类型：<code>insert</code>, <code>update</code>, <code>delete</code>, <code>database-create</code>, <code>database-alter</code>, <code>database-drop</code>, <code>table-create</code>, <code>table-alter</code>, <code>table-drop</code> 。</p><a id="more"></a><h2 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h2><p>config.properties 配置文件里面的所有选项，都可以在启动 maxweill <code>./bin/maxwell</code> 是指定，覆盖配置文件的内容。这里只讲一些常用的。</p><h3 id="mysql-options"><a href="#mysql-options" class="headerlink" title="mysql options"></a>mysql options</h3><ul><li>host<br>指定从哪个地址的mysql获取binlog</li><li>replication_host<br>如果指定了 <code>replication_host</code>，那么它是真正的binlog来源的mysql server地址，而那么上面的<code>host</code>用于存放maxwell表结构和binlog位置的地址。<br>将两者分开，可以避免 replication_user 往生产库里写数据。</li><li><p>schema_host<br>从哪个host获取表结构。binlog里面没有字段信息，所以maxwell需要从数据库查出schema，存起来。<br>schema_host一般用不到，但在binlog-proxy场景下就很实用。比如要将已经离线的binlog通过maxwell生成json流，于是自建一个mysql server里面没有结构，只用于发送binlog，此时表机构就可以制动从 <code>schema_host</code> 获取。</p></li><li><p>gtid_mode<br>如果 mysql server 启用了GTID，maxwell也可以基于gtid取event。如果mysql server发生failover，maxwell不需要手动指定newfile:postion</p></li></ul><p>正常情况下，replication_host 和 schema_host都不需要指定，只有一个 <code>--host</code>。</p><ul><li>schema_database<br>使用这个db来存放 maxwell 需要的表，比如要复制的databases, tables, columns, postions, heartbeats.</li></ul><h3 id="filtering"><a href="#filtering" class="headerlink" title="filtering"></a>filtering</h3><ul><li>include_dbs<br>只发送binlog里面这些databases的变更，以<code>,</code>号分隔，中间不要包含空格。<br>也支持java风格的正则，如 <code>include_tables=db1,/db\\d+/</code>，表示 db1, db2, db3…这样的。（下面的filter都支持这种regex）<br>提示：这里的dbs指定的是真实db。比如binlog里面可能 <code>use db1</code> 但 <code>update db2.ttt</code>，那么maxwell生成的json <code>database</code> 内容是db2。</li><li>exclude_dbs<br>排除指定的这些 databbases</li><li>include_tables<br>只发送这些表的数据变更。不只需要指定 database.</li><li>exclude_tables<br>排除指定的这些表</li><li>exclude_columns<br>不输出这些字段。如果字段名在row中不存在，则忽略这个filter。</li><li><p>include_column_values<br>1.12.0新引入的过滤项。只输出满足 column=values 的行，比如 <code>include_column_values=bar=x,foo=y</code>，如果有<code>bar</code>字段，那么只输出值为<code>x</code>的行，如果有<code>foo</code>字段，那么只输出值为<code>y</code>的行。<br>如果没有对应字段，如只有<code>bar=x</code>没有<code>foo</code>字段，那么也成立。（即不是 或，也不是 与）</p></li><li><p>blacklist_dbs<br>一般不用。<code>blacklist_dbs</code>字面上难以与<code>exclude_dbs</code> 分开，官网的说明也是模棱两可。<br>从代码里面看出的意思是，屏蔽指定的这些dbs,tables的<strong>结构变更</strong>，与行变更过滤，没有关系。它应对的场景是，某个表上频繁的有ddl，比如truncate。</p></li></ul><p>因为往往我们只需要观察部分表的变更，所以要注意这些 include 与 exclude 的关系，记住三点：</p><ol><li>只要 include 有值，那么不在include里面的都排除</li><li>只要在 exclude 里面的，都排除</li><li>其它都正常输出</li></ol><p>举个比较极端的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># database: db1,db2,db3,mydb</span><br><span class="line">① include_dbs=db1,/db\\d+/</span><br><span class="line">② exclude_dbs=db2</span><br><span class="line">③ inlcude_tables=t1,t2,t3</span><br><span class="line">④ exclude_tables=t3</span><br></pre></td></tr></table></figure></p><p>配置了 include_dbs，那么mydb不在里面，所以排除；<br>配置了 exclude_dbs，那么db2排除。剩下db1,db3<br>同样对 tables，剩下t1,t2<br>所以db1.t1, db1.t2, db3.t1, db3.t2是筛选后剩下可输出的。如果没有指定include_dbs，那么mydb.t1也可以输出。</p><h3 id="formatting"><a href="#formatting" class="headerlink" title="formatting"></a>formatting</h3><ul><li>output_ddl<br>是否在输出的json流中，包含ddl语句。<strong>默认 false</strong>  </li><li>output_binlog_position<br>是否在输出的json流中，包含binlog filename:postion。默认 false</li><li>output_commit_info<br>是否在输出的json流里面，包含 commit 和 xid 信息。默认 true<br>比如一个事物里，包含多个表的变更，或一个表上多条数据的变更，那么他们都具有相同的 xid，最后一个row event输出 commit:true 字段。这有利于消费者实现 事务回放，而不仅仅是行级别的回放。</li><li>output_thread_id<br>同样，binlog里面也包含了 thread_id ，可以包含在输出中。默认 false<br>消费者可以用它来实现更粗粒度的事务回放。还有一个场景是用户审计，用户每次登陆之后将登陆ip、登陆时间、用户名、thread_id记录到一个表中，可轻松根据thread_id关联到binlog里面这条记录是哪个用户修改的。</li></ul><h3 id="monitoring"><a href="#monitoring" class="headerlink" title="monitoring"></a>monitoring</h3><p>如果是长时间运行的maxwell，添加monitor配置，maxwell提供了http api返回监控数据。</p><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><ul><li>init_position<br>手动指定maxwell要从哪个binlog，哪个位置开始。指定的格式<code>FILE:POSITION:HEARTBEAT</code>。只支持在启动maxwell的命令指定，比如 <code>--init_postion=mysql-bin.0000456:4:0</code>。<br>maxwell 默认从连接上mysql server的当前位置开始解析，如果指定 init_postion，要确保文件确实存在，如果binlog已经被purge掉了，可能需要想其它办法。见 <a href="xx">Binlog可视化搜索：实现类似阿里RDS数据追踪功能</a></li></ul><h2 id="2-选择合适的生产者"><a href="#2-选择合适的生产者" class="headerlink" title="2. 选择合适的生产者"></a>2. 选择合适的生产者</h2><p>Maxwell是将binlog解析成json这种比较通用的格式，那么要去用它可以选择输出到哪里，比如Kafka, rabbitmq, file等，总之送到消息队列里去。每种 Producer 有自己对应的选项。</p><h3 id="2-1-file"><a href="#2-1-file" class="headerlink" title="2.1 file"></a>2.1 file</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">producer=file</span><br><span class="line">output_file=/tmp/mysql_binlog_data.log</span><br></pre></td></tr></table></figure><p>比较简单，直接指定输出到哪个文件<code>output_file</code>。有什么日志收集系统，可以直接从这里拿。</p><h3 id="2-2-rabbitmq"><a href="#2-2-rabbitmq" class="headerlink" title="2.2 rabbitmq"></a>2.2 rabbitmq</h3><p>rabbitmq 是非常流行的一个AMQP协议的消息队列服务，相关介绍请参考 <a href="xx">rabbitmq入门</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">producer=rabbitmq</span><br><span class="line"></span><br><span class="line">rabbitmq_host=10.81.xx.xxx</span><br><span class="line">rabbitmq_user=admin</span><br><span class="line">rabbitmq_pass=admin</span><br><span class="line">rabbitmq_virtual_host=/some0</span><br><span class="line">rabbitmq_exchange=maxwell.some</span><br><span class="line">rabbitmq_exchange_type=topic</span><br><span class="line">rabbitmq_exchange_durable=true</span><br><span class="line">rabbitmq_exchange_autodelete=false</span><br><span class="line">rabbitmq_routing_key_template=%db%.%table%</span><br></pre></td></tr></table></figure></p><p>上面的参数都很容易理解，1.12.0版本新加入<code>rabbitmq_message_persistent</code>控制发布消息持久化的参数。<br><code>rabbitmq_routing_key_template</code>是按照 db.tbl 的格式指定 routing_key，在创建队列时，可以根据不同的表进入不同的队列，提高并行消费而不乱序的能力。</p><p>因为rabbitmq搭建起来非常简单，所以我习惯用这个。</p><h3 id="2-3-kafka"><a href="#2-3-kafka" class="headerlink" title="2.3 kafka"></a>2.3 kafka</h3><p>kafka是maxwell支持最完善的一个producer，并且内置了 多个版本的 kafka client(0.8.2.2, 0.9.0.1, 0.10.0.1, 0.10.2.1 or 0.11.0.1)，默认 <code>kafka_version=0.11.0.1</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">producer=kafka</span><br><span class="line"></span><br><span class="line"># 指定kafka brokers 地址</span><br><span class="line">kafka.bootstrap.servers=hosta:9092,hostb:9092</span><br><span class="line"></span><br><span class="line"># kafka主题可以是固定的，可以是 `maxwell_%&#123;database&#125;_%&#123;table&#125;` 这种按表去自动创建的动态topic</span><br><span class="line">kafka_topic=maxwell</span><br><span class="line"></span><br><span class="line"># ddl单独使用的topic</span><br><span class="line">ddl_kafka_topic=maxwell_ddl</span><br><span class="line"></span><br><span class="line"># kafka和kenesis都支持分区，可以选择根据 database, table, primary_key, 或者column的值去做partition</span><br><span class="line"># maxwell默认使用database，在启动的时候会去检查是否topic是否有足够多数量的partitions，所以要提前创建好</span><br><span class="line">#  bin/kafka-topics.sh --zookeeper ZK_HOST:2181 --create \</span><br><span class="line">#                      --topic maxwell --partitions 20 --replication-factor 2</span><br><span class="line">producer_partition_by=database</span><br><span class="line"></span><br><span class="line"># 如果指定了 producer_partition_by=column, 就需要指定下面两个参数</span><br><span class="line"># 根据user_id,create_date两列的值去分区，partition_key形如 1178532016-10-10 18:29:04</span><br><span class="line">producer_partition_columns=user_id,create_date</span><br><span class="line"># 如果不存在user_id或create_date，则按照database分区:</span><br><span class="line">producer_partition_by_fallback=database</span><br></pre></td></tr></table></figure></p><p>maxwell会读取<code>kafka.</code>开头的参数，设置到连接参数里，比如<code>kafka.acks=1</code>,<code>kafka.retries=3</code>等</p><h3 id="2-4-redis"><a href="#2-4-redis" class="headerlink" title="2.4 redis"></a>2.4 redis</h3><p>redis也有简单的发布订阅(<code>pub/sub</code>)功能<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">producer=redis</span><br><span class="line"></span><br><span class="line">redis_host=10.47.xx.xxx</span><br><span class="line">redis_port=6379</span><br><span class="line"># redis_auth=redis_auth</span><br><span class="line">redis_database=0</span><br><span class="line">redis_pub_channel=maxwell</span><br></pre></td></tr></table></figure></p><p>但是试用一番之后，发现如果订阅没有连上去的话，所有pub的消息是会丢失的。所以最好使用<code>push/pop</code>去实现。</p><h2 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3. 注意事项"></a>3. 注意事项</h2><p>下面的是在使用过程中遇到的一些小问题，做下总结。</p><h3 id="timestamp-column"><a href="#timestamp-column" class="headerlink" title="timestamp column"></a>timestamp column</h3><p>maxwell对时间类型（datetime, timestamp, date）都是当做字符串处理的，这也是为了保证数据一致(比如<code>0000-00-00 00:00:00</code>这样的时间在timestamp里是非法的，但mysql却认，解析成java或者python类型就是null/None)。</p><p>如果MySQL表上的字段是 timestamp 类型，是有时区的概念，binlog解析出来的是标准UTC时间，但用户看到的是本地时间。比如 <code>f_create_time timestamp</code> 创建时间是北京时间<code>2018-01-05 21:01:01</code>，那么mysql实际存储的是<code>2018-01-05 13:01:01</code>，binlog里面也是这个时间字符串。如果不做消费者不做时区转换，会少8个小时。被这个狠狠坑了一把。</p><p>与其每个客户端都要考虑这个问题，我觉得更合理的做法是提供时区参数，然后maxwell自动处理时区问题，否则要么客户端先需要知道哪些列是timestamp类型，或者连接上原库缓存上这些类型。</p><h3 id="binary-column"><a href="#binary-column" class="headerlink" title="binary column"></a>binary column</h3><p>maxwell可以处理binary类型的列，如<code>blob</code>、<code>varbinary</code>，它的做法就是对二进制列使用 base64_encode，当做字符串输出到json。消费者拿到这个列数据后，不能直接拼装，需要 base64_decode。</p><h3 id="表结构不同步"><a href="#表结构不同步" class="headerlink" title="表结构不同步"></a>表结构不同步</h3><p>如果是拿比较老的binlog，放到新的mysql server上去用maxwell拉去，有可能表结构已经发生了变化，比如binlog里面字段比 schema_host 里面的字段多一个。目前这种情况没有发现异常，比如阿里RDS默认会为 无主键无唯一索引的表，增加一个<code>__##alibaba_rds_rowid##__</code>，在 show create table 和 schema里面都看不到这个隐藏主键，但binlog里面会有，同步到从库。</p><p>另外我们有通过git去管理结构版本，如果真有这种场景，也可以应对。</p><h3 id="大事务binlog"><a href="#大事务binlog" class="headerlink" title="大事务binlog"></a>大事务binlog</h3><p>当一个事物产生的binlog量非常大的时候，比如迁移日表数据，maxwell为了控制内存使用，会自动将处理不过来的binlog放到文件系统<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Using kafka version: 0.11.0.1</span><br><span class="line">21:16:07,109 WARN  MaxwellMetrics - Metrics will not be exposed: metricsReportingType not configured.</span><br><span class="line">21:16:07,380 INFO  SchemaStoreSchema - Creating maxwell database</span><br><span class="line">21:16:07,540 INFO  Maxwell - Maxwell v?? is booting (RabbitmqProducer), starting at Position[BinlogPosition[mysql-bin.006235:24980714],</span><br><span class="line">lastHeartbeat=0]</span><br><span class="line">21:16:07,649 INFO  AbstractSchemaStore - Maxwell is capturing initial schema</span><br><span class="line">21:16:08,267 INFO  BinlogConnectorReplicator - Setting initial binlog pos to: mysql-bin.006235:24980714</span><br><span class="line">21:16:08,324 INFO  BinaryLogClient - Connected to rm-xxxxxxxxxxx.mysql.rds.aliyuncs.com:3306 at mysql-bin.006235/24980714 (sid:637</span><br><span class="line">9, cid:9182598)</span><br><span class="line">21:16:08,325 INFO  BinlogConnectorLifecycleListener - Binlog connected.</span><br><span class="line">03:15:36,104 INFO  ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell7935334910787514257events</span><br><span class="line">03:17:14,880 INFO  ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell3143086481692829045events</span><br></pre></td></tr></table></figure></p><p>但是遇到另外一个问题，overflow随后就出现异常<code>EventDataDeserializationException: Failed to deserialize data of EventHeaderV4</code>，当我另起一个maxwell指点之前的binlog postion开始解析，却有没有抛异常。事后的数据也表明并没有数据丢失。</p><p>问题产生的原因还不明，Caused by: java.net.SocketException: Connection reset，感觉像读取 binlog 流的时候还没读取到完整的event，异常关闭了连接。这个问题比较顽固，github上面类似问题都没有达到明确的解决。（这也从侧面告诉我们，大表数据迁移，也要批量进行，不要一个insert into .. select 搞定）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">03:18:20,586 INFO  ListWithDiskBuffer - Overflowed in-memory buffer, spilling over into /tmp/maxwell5229190074667071141events</span><br><span class="line">03:19:31,289 WARN  BinlogConnectorLifecycleListener - Communication failure.</span><br><span class="line">com.github.shyiko.mysql.binlog.event.deserialization.EventDataDeserializationException: Failed to deserialize data of EventHeaderV4&#123;time</span><br><span class="line">stamp=1514920657000, eventType=WRITE_ROWS, serverId=2115082720, headerLength=19, dataLength=8155, nextPosition=520539918, flags=0&#125;</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.deserializeEventData(EventDeserializer.java:216) ~[mys</span><br><span class="line">ql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.nextEvent(EventDeserializer.java:184) ~[mysql-binlog-c</span><br><span class="line">onnector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.BinaryLogClient.listenForEventPackets(BinaryLogClient.java:890) [mysql-binlog-connector-java-0</span><br><span class="line">.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.BinaryLogClient.connect(BinaryLogClient.java:559) [mysql-binlog-connector-java-0.13.0.jar:0.13</span><br><span class="line">.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.BinaryLogClient$7.run(BinaryLogClient.java:793) [mysql-binlog-connector-java-0.13.0.jar:0.13.0</span><br><span class="line">]</span><br><span class="line">        at java.lang.Thread.run(Thread.java:745) [?:1.8.0_121]</span><br><span class="line">Caused by: java.net.SocketException: Connection reset</span><br><span class="line">        at java.net.SocketInputStream.read(SocketInputStream.java:210) ~[?:1.8.0_121]</span><br><span class="line">        at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[?:1.8.0_121]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.io.BufferedSocketInputStream.read(BufferedSocketInputStream.java:51) ~[mysql-binlog-connector-</span><br><span class="line">java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.readWithinBlockBoundaries(ByteArrayInputStream.java:202) ~[mysql-binlo</span><br><span class="line">g-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.read(ByteArrayInputStream.java:184) ~[mysql-binlog-connector-java-0.13</span><br><span class="line">.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.io.ByteArrayInputStream.readInteger(ByteArrayInputStream.java:46) ~[mysql-binlog-connector-jav</span><br><span class="line">a-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeLong(AbstractRowsEventDataD</span><br><span class="line">eserializer.java:212) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeCell(AbstractRowsEventDataD</span><br><span class="line">eserializer.java:150) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.AbstractRowsEventDataDeserializer.deserializeRow(AbstractRowsEventDataDeserializer.java:132) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserializeRows(WriteRowsEventDataDeserializer.java:64) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserialize(WriteRowsEventDataDeserializer.java:56) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.WriteRowsEventDataDeserializer.deserialize(WriteRowsEventDataDeserializer.java:32) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        at com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer.deserializeEventData(EventDeserializer.java:210) ~[mysql-binlog-connector-java-0.13.0.jar:0.13.0]</span><br><span class="line">        ... 5 more</span><br><span class="line">03:19:31,514 INFO  BinlogConnectorLifecycleListener - Binlog disconnected.</span><br><span class="line">03:19:31,590 WARN  BinlogConnectorReplicator - replicator stopped at position: mysql-bin.006236:520531744 -- restarting</span><br><span class="line">03:19:31,595 INFO  BinaryLogClient - Connected to rm-xxxxxx.mysql.rds.aliyuncs.com:3306 at mysql-bin.006236/520531744 (sid:6379, cid:9220521)</span><br></pre></td></tr></table></figure><h3 id="tableMapCache"><a href="#tableMapCache" class="headerlink" title="tableMapCache"></a>tableMapCache</h3><p>前面讲过，如果我只想获取某几个表的binlog变更，需要用 <code>include_tables</code> 来过滤，但如果mysql server上现在删了一个表t1，但我的binlog是从昨天开始读取，被删的那个表t1在maxwell启动的时候是拉取不到表结构的。然后昨天的binlog里面有 t1 的变更，因为找不到表结构给来组装成json，会抛异常。</p><p>手动在 maxwell.tables/columns 里面插入记录是可行的。但这个问题的根本是，maxwell在binlog过滤的时候，只在处理row_event的时候，而对 tableMapCache 要求binlog里面的所有表都要有。</p><p>自己提交了一个commit，可以在做 tableMapCache 的时候也仅要求缓存 include_dbs/tables 这些表： <a href="https://github.com/seanlook/maxwell/commit/2618b70303078bf910a1981b69943cca75ee04fb" target="_blank" rel="noopener">https://github.com/seanlook/maxwell/commit/2618b70303078bf910a1981b69943cca75ee04fb</a></p><h3 id="提高消费性能"><a href="#提高消费性能" class="headerlink" title="提高消费性能"></a>提高消费性能</h3><p>再用rabbitmq时，routing_key 是 <code>%db%.%table%</code>，但某些表产生的binlog增量非常大，就会导致各队列消息量很不平均，目前因为还没做到事务xid或者thread_id级别的并发回放，所以最小队列粒度也是表，尽量单独放一个队列，其它数据量小的合在一起。</p><p><strong>参考</strong></p><ul><li><a href="http://maxwells-daemon.io/config/" target="_blank" rel="noopener">http://maxwells-daemon.io/config/</a></li><li><a href="http://bigdatadecode.club/%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96MySQL%E7%9A%84%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%88%B0Hadoop.html" target="_blank" rel="noopener">实时抓取MySQL的更新数据到Hadoop</a></li><li><a href="https://www.percona.com/blog/2016/09/13/mysql-cdc-streaming-binary-logs-and-asynchronous-triggers/" target="_blank" rel="noopener">MySQL CDC, Streaming Binary Logs and Asynchronous Triggers</a></li></ul><hr><p>原文连接地址：<a href="http://seanlook.com/2018/01/13/maxwell-binlog/">http://seanlook.com/2018/01/13/maxwell-binlog/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 介绍&quot;&gt;&lt;/a&gt;1. 介绍&lt;/h2&gt;&lt;p&gt;Maxwell 是java语言编写的能够读取、解析MySQL binlog，将行更新以json格式发送到 Kafka、RabbitMQ、AWS Kinesis、Google Cloud Pub/Sub、文件，有了增量的数据流，可以想象的应用场景实在太多了，如ETL、维护缓存、收集表级别的dml指标、增量到搜索引擎、数据分区迁移、切库binlog回滚方案，等等。&lt;/p&gt;
&lt;p&gt;它还提供其它功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持&lt;code&gt;SELECT * FROM table&lt;/code&gt; 的方式做全量数据初始化&lt;/li&gt;
&lt;li&gt;支持主库发生failover后，自动恢复binlog位置（GTID）&lt;/li&gt;
&lt;li&gt;灵活的对数据进行分区，解决数据倾斜的问题。kafka支持 database, table, column等级别的数据分区&lt;/li&gt;
&lt;li&gt;它的实现方式是伪装成MySQL Server的从库，接收binlog events，然后根据schemas信息拼装，支持ddl,xid,rows等各种event.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;maxwell由 zendesk 开源：&lt;a href=&quot;https://github.com/zendesk/maxwell&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/zendesk/maxwell&lt;/a&gt; ，而且维护者相当活跃。&lt;/p&gt;
&lt;p&gt;网上已有人对 Alibaba Cannal, Zendesk Maxwell, Yelp mysql_streamer进行对比，见文后参考 实时抓取MySQL的更新数据到Hadoop。&lt;/p&gt;
&lt;p&gt;类似功能的还有：&lt;a href=&quot;http://debezium.io/docs/connectors/mysql/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://debezium.io/docs/connectors/mysql/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h3&gt;&lt;p&gt;使用 maxwell 非常简单，只需要jdk环境&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;yum install -y java-1.8.0-openjdk-1.8.0.121-1.b13.el6.x86_64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;curl -sLo - https://github.com/zendesk/maxwell/releases/download/v1.12.0/maxwell-1.12.0.tar.gz \&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;       | tar zxvf -&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd maxwell-1.12.0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;# 默认寻找当前目录下的 config.properties 配置文件&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;要求 mysql server binlog格式是 &lt;code&gt;ROW&lt;/code&gt;， row_image 是 &lt;code&gt;FULL&lt;/code&gt;。感受一下输出结果&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql&amp;gt; update test.e set m = 5.444, c = now(3) where id = 1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;database&amp;quot;:&amp;quot;test&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;table&amp;quot;:&amp;quot;e&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;type&amp;quot;:&amp;quot;update&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;ts&amp;quot;:1477053234,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;commit&amp;quot;: true,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   ...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;data&amp;quot;:&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;id&amp;quot;:1,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;m&amp;quot;:5.444,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;c&amp;quot;:&amp;quot;2016-10-21 05:33:54.631000&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;comment&amp;quot;:&amp;quot;I am a creature of light.&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;#125;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;old&amp;quot;:&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;m&amp;quot;:4.2341,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;c&amp;quot;:&amp;quot;2016-10-21 05:33:37.523000&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mysql&amp;gt; create table test.e ( ... )&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;type&amp;quot;:&amp;quot;table-create&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;database&amp;quot;:&amp;quot;test&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;table&amp;quot;:&amp;quot;e&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;def&amp;quot;:&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;database&amp;quot;:&amp;quot;test&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;charset&amp;quot;:&amp;quot;utf8mb4&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;table&amp;quot;:&amp;quot;e&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;columns&amp;quot;:[&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &amp;#123;&amp;quot;type&amp;quot;:&amp;quot;int&amp;quot;, &amp;quot;name&amp;quot;:&amp;quot;id&amp;quot;, &amp;quot;signed&amp;quot;:true&amp;#125;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &amp;#123;&amp;quot;type&amp;quot;:&amp;quot;double&amp;quot;, &amp;quot;name&amp;quot;:&amp;quot;m&amp;quot;&amp;#125;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &amp;#123;&amp;quot;type&amp;quot;:&amp;quot;timestamp&amp;quot;, &amp;quot;name&amp;quot;:&amp;quot;c&amp;quot;, &amp;quot;column-length&amp;quot;:6&amp;#125;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &amp;#123;&amp;quot;type&amp;quot;:&amp;quot;varchar&amp;quot;, &amp;quot;name&amp;quot;:&amp;quot;comment&amp;quot;, &amp;quot;charset&amp;quot;:&amp;quot;latin1&amp;quot;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      ],&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &amp;quot;primary-key&amp;quot;:[&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &amp;quot;id&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      ]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;#125;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;ts&amp;quot;:1477053126000,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;sql&amp;quot;:&amp;quot;create table test.e ( id int(10) not null primary key auto_increment, m double, c timestamp(6), comment varchar(255) charset &amp;apos;latin1&amp;apos; )&amp;quot;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   &amp;quot;position&amp;quot;:&amp;quot;master.000006:800050&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;data&lt;/code&gt;是 After image, &lt;code&gt;old&lt;/code&gt; 是 Before image。 insert 只有后镜像，delete只有前镜像（&lt;code&gt;data&lt;/code&gt;）&lt;br&gt;&lt;code&gt;type&lt;/code&gt;是语句类型：&lt;code&gt;insert&lt;/code&gt;, &lt;code&gt;update&lt;/code&gt;, &lt;code&gt;delete&lt;/code&gt;, &lt;code&gt;database-create&lt;/code&gt;, &lt;code&gt;database-alter&lt;/code&gt;, &lt;code&gt;database-drop&lt;/code&gt;, &lt;code&gt;table-create&lt;/code&gt;, &lt;code&gt;table-alter&lt;/code&gt;, &lt;code&gt;table-drop&lt;/code&gt; 。&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="binlog" scheme="http://seanlook.com/tags/binlog/"/>
    
  </entry>
  
  <entry>
    <title>RabbitMQ 入门</title>
    <link href="http://seanlook.com/2018/01/06/rabbitmq-introduce/"/>
    <id>http://seanlook.com/2018/01/06/rabbitmq-introduce/</id>
    <published>2018-01-06T07:32:49.000Z</published>
    <updated>2018-01-06T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>rabbitmq可以用一本书取讲，这里只是介绍一些使用过程中，常用到的基本的知识点。<br>官方文档覆盖的内容，非常全面：<a href="http://www.rabbitmq.com/documentation.html" target="_blank" rel="noopener">http://www.rabbitmq.com/documentation.html</a> 。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>RabbitMQ，即消息队列系统，它是一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。</p><p>AMQP是一个公开发布的异步消息的规范，是提供统一消息服务的应用层标准高级消息队列协议，为面向消息的中间件设计.消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。</p><p><a href="https://www.rabbitmq.com/tutorials/amqp-concepts.html" target="_blank" rel="noopener">https://www.rabbitmq.com/tutorials/amqp-concepts.html</a></p><p>相对于JMS(Java Message Service)规范来说，JMS使用的是特定语言的APIs，而消息格式可自由定义，而AMQP对消息的格式和传输是有要求的，但实现不会受操作系统、开发语言以及平台等的限制。</p><p>JMS和AMQP还有一个较大的区别：JMS有队列(Queues)和主题(Topics)两种消息传递模型，发送到 JMS队列 的消息最多只能被一个Client消费，发送到 JMS主题 的消息可能会被多个Clients消费；AMQP只有队列(Queues)，队列的消息只能被单个接受者消费，发送者并不直接把消息发送到队列中，而是发送到Exchange中，该Exchage会与一个或多个队列绑定，能够实现与JMS队列和主题同样的功能。</p><p>另外还有一种 MQTT协议，意为消息队列遥测传输，是IBM开发的一个即时通讯协议。由于其维护一个长连接以轻量级低消耗著称，所以常用于移动端消息推送服务开发。MQTT是基于TCP的应用层协议封装，实现了异步Pub/Sub，在物联网（IoT）应用广泛。</p><p>RabbitMQ可通过库、插件的形式，支持JMS和MQTT协议。参考：<a href="http://geek.csdn.net/news/detail/71894" target="_blank" rel="noopener">http://geek.csdn.net/news/detail/71894</a></p><h3 id="1-1-主要概念"><a href="#1-1-主要概念" class="headerlink" title="1.1 主要概念"></a>1.1 主要概念</h3><p><img src="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_MRG/2/html-single/Messaging_Programming_Reference/images/1083.png" alt=""></p><ol><li><p>Broker<br>接收和分发消息的应用，RabbitMQ Server就是Message Broker</p></li><li><p>Exchange<br>message到达broker的第一站，根据分发规则，匹配查询表中的routing key，分发消息到queue中去。常用的类型有：direct, topic, fanout。<br>如果没有队列绑定到exchange上，那么该exchange上的消息都会被丢弃，因为它不存储消息又不知道该怎么处理消息。</p><a id="more"></a></li><li><p>Queue<br>消息队列载体，每个消息都会被投入到一个或多个队列</p></li><li><p>Binding<br>在exchange和queue之间建立关系就叫Binding，消费者声明队列的时候一般会指定routing_key，也可以叫binding_key。Binding信息被保存到exchange中的查询表中，用于message的分发依据。</p></li><li><p>Routing Key<br>这里区分一下binding和routing: binding是一个将exchange和queue关联起来的<strong>动作</strong>，routing_key可以理解成队列的一个属性，表示这个队列接受符合该routing_key的消息，routing_key需要在发送消息的时候指定。</p></li><li><p>Vhost<br>于多租户和安全因素设计的，把AMQP的基本组件划分到一个虚拟的分组中，类似于网络中的namespace概念。当多个不同的用户使用同一个RabbitMQ server提供的服务时，可以划分出多个vhost，每个用户在自己的vhost创建exchange／queue等</p></li><li><p>Producer<br>消息生产者，就是投递消息的程序。只负责把消息发送exchange，附带一些消息属性。</p></li><li><p>Consumer<br>消息消费者，就是接受消息的程序。</p></li><li><p>Channel<br>如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立TCP Connection的开销将是巨大的，效率也较低。<br>Channel是在connection内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的channel进行通讯，AMQP method包含了channel id帮助客户端和message broker识别channel，所以channel之间是完全隔离的。Channel作为轻量级的Connection极大减少了操作系统建立TCP connection的开销。</p></li></ol><h3 id="1-2-对比"><a href="#1-2-对比" class="headerlink" title="1.2 对比"></a>1.2 对比</h3><p>rabbitmq<br>activemq<br>rocketmq<br>kafka<br>zeromq<br>redis</p><p>celery<br>待续</p><h2 id="2-安装配置"><a href="#2-安装配置" class="headerlink" title="2. 安装配置"></a>2. 安装配置</h2><p>CentOS 6.7，安装3.6.14最新稳定版本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm</span><br><span class="line">rpm -Uvh erlang-solutions-1.0-1.noarch.rpm</span><br><span class="line">rpm --import https://dl.bintray.com/rabbitmq/Keys/rabbitmq-release-signing-key.asc</span><br><span class="line">yum install -y socat</span><br></pre></td></tr></table></figure></p><p>如果机器上有epel源，先把它禁用掉：enabled=0，否则会默认从这个源按照低版本rabbitmq 。<br>如果已安装老版本，可能需要卸载 <code>rpm -qa|grep erlang|awk &#39;{print &quot;yum remove -y &quot;$1}&#39;|sh</code> 。<br>继续<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://packages.erlang-solutions.com/rpm/centos/6/x86_64/erlang-20.1-1.el6.x86_64.rpm</span><br><span class="line">wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.14/rabbitmq-server-3.6.14-1.el6.noarch.rpm</span><br><span class="line"></span><br><span class="line">yum localinstall -y erlang-20.1-1.el6.x86_64.rpm rabbitmq-server-3.6.14-1.el6.noarch.rpm</span><br></pre></td></tr></table></figure></p><p>确保本地主机名能够正常解析出自己的ip，或 127.0.0.1. （ping rabbitmq-01）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ulimit -S -n 4096</span><br><span class="line">ulimit -n 65534</span><br><span class="line"></span><br><span class="line"># limits.conf</span><br><span class="line">cat /etc/security/limits.conf</span><br><span class="line">* soft nofile 65535</span><br><span class="line">* hard nofile 65535</span><br><span class="line"></span><br><span class="line"># 从配置文件模板创建配置文件</span><br><span class="line">sudo cp -a /usr/share/doc/rabbitmq-server-3.6.14/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">/etc/init.d/rabbitmq-server restart</span><br></pre></td></tr></table></figure><p>默认用户名密码 <code>guest</code>/<code>guest</code>， 具有vhost <code>/</code> 的所有权限，只能在本地访问。<br>队列元数据及内容信息，默认在目录 <code>/var/lib/rabbitmq/mnesia</code> 下。</p><h3 id="2-1-配置"><a href="#2-1-配置" class="headerlink" title="2.1 配置"></a>2.1 配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 启用管理插件</span><br><span class="line">rabbitmq-plugins enable rabbitmq_management</span><br><span class="line"></span><br><span class="line"># /etc/rabbitmq/rabbitmq.config 配置</span><br><span class="line">[</span><br><span class="line"> &#123;rabbit,</span><br><span class="line">  [%%</span><br><span class="line">   &#123;tcp_listeners, [5672]&#125;,</span><br><span class="line">   &#123;vm_memory_high_watermark, 0.6&#125;,</span><br><span class="line">   %% &#123;vm_memory_high_watermark_paging_ratio, 0.5&#125;,</span><br><span class="line">   &#123;hipe_compile, true&#125;</span><br><span class="line">  ]&#125;,</span><br><span class="line"> &#123;rabbitmq_management,</span><br><span class="line">  [%% Preload schema definitions from a previously exported definitions file. See</span><br><span class="line">  ]&#125;</span><br><span class="line">].</span><br></pre></td></tr></table></figure><p><code>%%</code>是Erlang的注释符号。</p><ul><li>vm_memory_high_watermark<br>RabbitMQ在使用当前机器的40%以上内存时候，会发出内存警告，并阻止RabbitMQ所有连接（producer连接）。这个阈值便由 <code>vm_memory_high_watermark</code> 控制</li><li>vm_memory_high_watermark_paging_ratio<br>当内存中的数据达到一定数量后，他需要被page out出来。比如默认这个ratio=0.5，机器内存8G，于是 memory watermark=0.4 <em> 8G几即 3.2G。3.2G </em> paging_raio = 1.6G，当消息挤压的量达到1.6G后，开始paging到磁盘上。<br>一搬不去改它。</li><li>hipe_compile<br>开启Erlang HiPE编译选项（相当于Erlang的jit技术），能够提高性能20%-50%。在Erlang R17后HiPE已经相当稳定，RabbitMQ官方也建议开启此选项。<br>开启之后，每次启动 rabbitmq-server，需要多花1分钟左右。</li></ul><p>看下 <code>rabbitmqctl status</code> 信息，混个眼熟：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Status of node &apos;rabbit@rabbitmq-01&apos;</span><br><span class="line">[&#123;pid,6232&#125;,</span><br><span class="line"> &#123;running_applications,</span><br><span class="line">     [&#123;rabbitmq_management,&quot;RabbitMQ Management Console&quot;,&quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,&quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;rabbitmq_web_dispatch,&quot;RabbitMQ Web Dispatcher&quot;,&quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;cowboy,&quot;Small, fast, modular HTTP server.&quot;,&quot;1.0.4&quot;&#125;,</span><br><span class="line">      &#123;rabbitmq_consistent_hash_exchange,&quot;Consistent Hash Exchange Type&quot;,</span><br><span class="line">          &quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;rabbitmq_sharding,&quot;RabbitMQ Sharding Plugin&quot;,&quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;rabbit_common,</span><br><span class="line">          &quot;Modules shared by rabbitmq-server and rabbitmq-erlang-client&quot;,</span><br><span class="line">          &quot;3.6.14&quot;&#125;,</span><br><span class="line">      &#123;os_mon,&quot;CPO  CXC 138 46&quot;,&quot;2.4.3&quot;&#125;,</span><br><span class="line">      &#123;mnesia,&quot;MNESIA  CXC 138 12&quot;,&quot;4.15.1&quot;&#125;,</span><br><span class="line">      &#123;cowlib,&quot;Support library for manipulating Web protocols.&quot;,&quot;1.0.2&quot;&#125;,</span><br><span class="line">      &#123;compiler,&quot;ERTS  CXC 138 10&quot;,&quot;7.1.2&quot;&#125;,</span><br><span class="line">      &#123;recon,&quot;Diagnostic tools for production use&quot;,&quot;2.3.2&quot;&#125;,</span><br><span class="line">      &#123;syntax_tools,&quot;Syntax tools&quot;,&quot;2.1.3&quot;&#125;,</span><br><span class="line">      &#123;crypto,&quot;CRYPTO&quot;,&quot;4.1&quot;&#125;,</span><br><span class="line">      &#123;stdlib,&quot;ERTS  CXC 138 10&quot;,&quot;3.4.2&quot;&#125;,</span><br><span class="line">      &#123;kernel,&quot;ERTS  CXC 138 10&quot;,&quot;5.4&quot;&#125;]&#125;,</span><br><span class="line"> &#123;os,&#123;unix,linux&#125;&#125;,</span><br><span class="line"> &#123;erlang_version,</span><br><span class="line">     &quot;Erlang/OTP 20 [erts-9.1] [source] [64-bit] [smp:4:4] [ds:4:4:10] [async-threads:64] [hipe] [kernel-poll:true]\n&quot;&#125;,</span><br><span class="line"> &#123;memory,</span><br><span class="line">     [&#123;connection_readers,0&#125;,</span><br><span class="line">      &#123;connection_writers,0&#125;,</span><br><span class="line">      &#123;connection_channels,0&#125;,</span><br><span class="line">      &#123;connection_other,8864&#125;,</span><br><span class="line">      &#123;queue_procs,48686248&#125;,</span><br><span class="line">      &#123;queue_slave_procs,0&#125;,</span><br><span class="line">      &#123;plugins,14194848&#125;,</span><br><span class="line">      &#123;other_proc,12618480&#125;,</span><br><span class="line">      &#123;metrics,323944&#125;,</span><br><span class="line">      &#123;mgmt_db,12627800&#125;,</span><br><span class="line">      &#123;mnesia,701856&#125;,</span><br><span class="line">      &#123;binary,22261264&#125;,</span><br><span class="line">      &#123;msg_index,634656&#125;,</span><br><span class="line">      &#123;allocated_unused,364165712&#125;,</span><br><span class="line">      &#123;reserved_unallocated,0&#125;,</span><br><span class="line">      &#123;total,596238336&#125;]&#125;,</span><br><span class="line"> &#123;alarms,[]&#125;,</span><br><span class="line"> &#123;listeners,</span><br><span class="line">     [&#123;clustering,25672,&quot;::&quot;&#125;,&#123;amqp,5672,&quot;0.0.0.0&quot;&#125;,&#123;http,15672,&quot;0.0.0.0&quot;&#125;]&#125;,</span><br><span class="line"> &#123;vm_memory_calculation_strategy,rss&#125;,</span><br><span class="line"> &#123;vm_memory_high_watermark,0.6&#125;,</span><br><span class="line"> &#123;vm_memory_limit,4952820940&#125;,</span><br><span class="line"> &#123;disk_free_limit,50000000&#125;,</span><br><span class="line"> &#123;disk_free,1626125135872&#125;,</span><br><span class="line"> &#123;file_descriptors,</span><br><span class="line">     [&#123;total_limit,65435&#125;,</span><br><span class="line">      &#123;total_used,58&#125;,</span><br><span class="line">      &#123;sockets_limit,58889&#125;,</span><br><span class="line">      &#123;sockets_used,0&#125;]&#125;,</span><br><span class="line"> &#123;processes,[&#123;limit,1048576&#125;,&#123;used,446&#125;]&#125;,</span><br><span class="line"> &#123;run_queue,0&#125;,</span><br><span class="line"> &#123;uptime,1232025&#125;,</span><br><span class="line"> &#123;kernel,&#123;net_ticktime,60&#125;&#125;]</span><br></pre></td></tr></table></figure></p><h3 id="2-2-命令行"><a href="#2-2-命令行" class="headerlink" title="2.2 命令行"></a>2.2 命令行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 添加新的 vhost</span><br><span class="line">rabbitmqctl add_vhost /some0</span><br><span class="line">rabbitmqctl list_vhost</span><br><span class="line"></span><br><span class="line"># 添加登录用户 admin  </span><br><span class="line">rabbitmqctl add_user admin admin</span><br><span class="line">rabbitmqctl list_users</span><br><span class="line"></span><br><span class="line"># 设置为管理员角色</span><br><span class="line">rabbitmqctl set_user_tags admin administrator</span><br><span class="line"></span><br><span class="line"># 设置权限</span><br><span class="line">rabbitmqctl set_permissions -p /some0 admin &apos;.*&apos; &apos;.*&apos; &apos;.*&apos;</span><br><span class="line">rabbitmqctl list_permissions -p /some0</span><br><span class="line">rabbitmqctl list_user_permissions admin</span><br></pre></td></tr></table></figure><p>在开始介绍概念之前，先可以从Web UI上来认识一下rabbitmq:<br>rabbitmq overview 首页监控面板:<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rabbitmq-overview.png" alt="rabbitmq-overview.png"></p><p>rabbitmq 客户端的连接信息:<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rabbitmq-connections.png" alt="rabbitmq-connections.png"></p><p>某个channel的详情:<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rabbitmq-channel-info.png" alt="rabbitmq-channel-info.png"></p><p>exchanges信息:<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rabbitmq-exchanges.png" alt="rabbitmq-exchanges.png"></p><p>queues信息:<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rabbitmq-queues-consuming.png" alt="rabbitmq-queues-consuming.png"></p><p>策略定义:<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rabbitmq-policy.png" alt="rabbitmq-policy.png"></p><!-- more --><h2 id="3-Exchange类型"><a href="#3-Exchange类型" class="headerlink" title="3. Exchange类型"></a>3. Exchange类型</h2><p>AMQP 0-9-1 定义了四种内置类型的exchange type: direct, fanout, topic, header。exchange除了类型以外，还可以指定一些属性：</p><ul><li>Name: 交换器名字。一般以 <code>.</code> 号分隔以作区分  </li><li>Durability: 持久化的exchange在broker重启之后依然存在。相对应是 transient exchange  </li><li>Auto-delete: 如果设置了该属性，在最后一个队列unbound之后，exchange会自动删除  </li><li><p>Arguments: 可以用在满足插件扩展上  </p><ul><li><p>alternate-exchange<br>RabbitMQ自己扩展的功能，不是AMQP协议定义的。<br>Alternate Exchange属性的作用，创建Exchange指定该 <code>x-arguments</code> 的<code>alternate-exchange</code>属性，发送消息的时候根据route key没有找到可以投递的队列，这就会将此消息路由到 Alternate Exchange 属性指定的 Exchange (就是一个普通的exchange)上了。</p><p>比如把MySQL的binlog订阅出来，因为里面有许多表，每个表的dml行数有多有少。我们可以将变更量多的表单独放到一个队列，其它表一起放到一个队列，就可以为原始的exchange添加 alternate-exchange 属性，将其它表的数据重新投递到另一个exchange。</p></li></ul></li></ul><h3 id="3-1-fanout"><a href="#3-1-fanout" class="headerlink" title="3.1 fanout"></a>3.1 fanout</h3><p>fanout类型的exchange是最容易理解的，它会把来自生产者的消息广播到所有绑定的queues上。这种情况一般会把消息的routing_key设置为空<code>&#39;&#39;</code>，甚至不关心队列的名字。如下图：<br><img src="https://www.rabbitmq.com/img/tutorials/python-three-overall.png" alt=""></p><p><code>amq.gen-RQ6...</code>和<code>amq.gen-As8...</code>是消费者随机生成了两个队列，绑定到fanout exchange上，C1,C2会各自收到一模一样的消息。</p><h3 id="3-2-direct"><a href="#3-2-direct" class="headerlink" title="3.2 direct"></a>3.2 direct</h3><p>direct类型的exchange转发消息到队列里，是直接基于消息的routing key。<br><img src="https://www.rabbitmq.com/img/tutorials/python-four.png" alt=""></p><p>C1在声明队列的时候，指定routing_key=error。C2的队列上绑定了info,error,warning三个key。<br>于是error类型的消息会被同时发送到C1,C2（准确的说是两个队列上），而info,warning类型的消息只发送到队列a<code>mqp.gen-Agl...</code>。</p><p>如果要达到Round-Robin轮询效果，即两个Consumer依次从同一个队列里取消息，那么可以在声明队列的时候指定相同的 queue name，rabbitmq会自动均衡的发送消息给多个Consumer，可水平扩展消费者的处理能力（如果要保证处理顺序，得设置prefetch_count=1）。</p><h3 id="3-3-topic"><a href="#3-3-topic" class="headerlink" title="3.3 topic"></a>3.3 topic</h3><p>topic类型的exchange大大提升了消息路由的灵活性。不像fanout那样无脑的全部转发，也不像direct那样指定所有的routing_key，否则不匹配的key的消息就会被丢弃。<br>比如有一个收集日志的系统，模块包括auth/cron/kernel/app1/app2，日志级别包括error,info,warning。现在要把所有模块的error日志规整在一起，可以设计routing_key: \&lt;module>.\&lt;severity> (auth.error, auth.info, …, app1.error, app1.info…)，然后设置queue的binding_key=’*.error’</p><p>topic exchange 会根据 <code>.</code> 划分word，有以下两种正则符号用于匹配routing_key：</p><ul><li><code>*</code>: 代表一个word</li><li><code>#</code>: 代表0个或多个word</li></ul><p>拿官网的例图来说：&lt;敏捷度&gt;.&lt;颜色&gt;.&lt;物种&gt;<br><img src="https://www.rabbitmq.com/img/tutorials/python-five.png" alt=""><br>上图创建了3个bindings: </p><ul><li>队列Q1的binding_key=<code>*.orange.*</code>，即对所有橙色的动物感兴趣</li><li>队列Q2绑定了<code>*.*.rabbit</code>和<code>lazy.#</code>，即订阅了所有和兔子相关的消息，以及反应迟钝的动物</li></ul><p>于是：</p><ul><li>routing_key为<code>quick.orange.rabbit</code>的消息，会被发送到两个队列</li><li>routing_key为<code>lazy.orange.elephant</code>的消息，也会被发送到两个队列</li><li>routing_key为<code>quick.orange.fox</code>的消息，只会发送到Q1</li><li>routing_key为<code>lazy.brown.fox</code>的消息，只会发送到Q2</li><li>routing_key为<code>lazy.pink.rabbit</code>的消息，只会发送到Q2。虽然匹配到了<code>lazy.#</code>和<code>*.*.rabbit</code>，但只会发送一次</li><li>routing_key为<code>quick.brown.fox</code>的消息，会被丢弃，因为没有任何绑定的队列得到匹配</li><li>routing_key为<code>lazy.orange.male.rabbit</code>的消息，还是会发送到Q2，因为 <code>lazy.#</code><br>然而<code>orange</code>、<code>quick.orange.male.rabbit</code>，也破坏了约定，但没得到匹配，消息丢弃。</li><li>routing_key为<code>#</code>，接受所有消息，相当于fanout exchange</li><li>routing_key没有<code>*</code>和<code>#</code>时，相当于direct exchange</li></ul><h3 id="3-4-headers"><a href="#3-4-headers" class="headerlink" title="3.4 headers"></a>3.4 headers</h3><p>header类型的exchange用的不多，是在routing_key不能满足使用场景的情况下(如routing_key必须是字符串)，在消息的头部加入一个或多个key/value，然后在声明队列的时候也指定要绑定的header。</p><p>binding的时候有个参数<code>x-match</code>，指定headers所有的k/v都要匹配成功（<code>all</code>）还是任意一个匹配则接受（<code>any</code>）。</p><h3 id="3-5-x-consistent-hash"><a href="#3-5-x-consistent-hash" class="headerlink" title="3.5 x-consistent-hash"></a>3.5 x-consistent-hash</h3><p>这是个第三方插件形式存在的exchange，目前已内置于rabbitmq：<a href="https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange" target="_blank" rel="noopener">https://github.com/rabbitmq/rabbitmq-consistent-hash-exchange</a></p><p><code>x-consistent-hash</code>类型的exchange可以根据routing_key，用一致性哈希算法，将消息路由到不同的队列上。它可以尽可能的保证每个队列上的消息数量相同，也可以随时添加更多的队列来“分流”，并且能保证同一个routing_key会进入相同的queue。</p><p>要达到这样的效果，queue routing key必须是一个字符串类型的数字。比如Q1:routing_key=’10’, Q2:routing_key=’20’，那么消息就会按照1:2的比例，发送到Q1,Q2。</p><h3 id="3-6-x-modulus-hash"><a href="#3-6-x-modulus-hash" class="headerlink" title="3.6 x-modulus-hash"></a>3.6 x-modulus-hash</h3><p>第三方插件形成存在的exchange，从3.6.0版本开始，也内置到了rabbitmq发行版：<a href="https://github.com/rabbitmq/rabbitmq-sharding" target="_blank" rel="noopener">https://github.com/rabbitmq/rabbitmq-sharding</a></p><p><code>x-modulus-hash</code>类型的exchange与 <code>x-consistent-hash</code> 很像，也叫 sharding exchange，即将message在多个队列之间进行分区发送。它的实现方法是根据 routing_key 先获得hash，再用 <code>Hash mod N</code> 得到队列，N就是绑定到exchange上的队列个数。</p><h2 id="4-Queue属性"><a href="#4-Queue属性" class="headerlink" title="4. Queue属性"></a>4. Queue属性</h2><p>Queue 要先于 Exchange 创建，否则生产者发布的消息，在没有绑定队列之前，会丢失。<br>已存在的Queue可以重复declare，但前提是属性要相同。</p><ul><li>Name: 队列名称。可以在应用里面指定，或者交给broker生成  </li><li>Durable：持久化的Queue在broker重启之后，依然存在。<br>注意，这里的持久化与消息持久无关。是个 property  </li><li>Exclusive: 为True时，表示当Consumer的Connection端口之后，队列自动删除。一般由broker生成的随机队列名，指定这个选项 。<br>排他队列是基于连接可见的，同一连接的不同信道是可以同时访问同一个连接创建的排他队列的</li><li><p>Auto-delete: 当最后一个consumer取消订阅之后，队列自动删除</p></li><li><p>Arguments: 设置可选的一些参数，如  </p><ul><li><p>x-message-ttl<br>消息在队里里最大存活时间，超过这个ttl就会被丢弃。单位毫秒</p></li><li><p>x-max_length<br>队列里最多容纳的消息个数，超过这个值，则会从队列头部drop掉消息</p></li><li><p>x-max-priority<br>设置了这个参数，就表示这是一个具有优先级的队列。它的值是可定义的优先级最大值，一般10以内就够了。<br>在生产商Publish消息的时候，消息Property上可设置Priority</p></li><li><p>x-queue-mode<br>这个参数是控制是否为”延迟队列”，Lazy Queue是在3.6.0引入的，它会尽量把消息存在磁盘上，节省内存<br>RabbitMQ一开始的设计初衷，是做异步、解耦，所以会把消息放在内存里面，以便快速的发送给消费者（持久化类型的消息会同时存在于磁盘和内存缓存中）。</p><p>如果用它来暂时存放大量消息，而不消费或者消费太慢，会导致性能明显下降，因为为了释放内存，消息得swap到磁盘上 —— 会阻塞队列接收新消息。如果内存使用达到broker设置的 water-mark，也会拒绝接收新消息。<br>Lazy Queue(<code>x-queue-mode=lazy</code>)的作用就是一接收到新消息，马上存到文件系统，完全避免了前面提到的内存占用。这会增加磁盘I/O（顺序的），与处理持久化类型的消息很相似。</p></li><li><p>x-dead-letter-exchange<br>死信。当消息在一个队列中变成死信后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。消息变成死信一向有以下几种情况：</p><ul><li>消息被拒绝（basic.reject or basic.nack）并且requeue=false</li><li>消息TTL过期</li><li>队列达到最大长度</li></ul><p>DLX也是一下正常的Exchange同一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性，当这个队列中有死信时，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange中去，进而被路由到另一个队列。<br>死信被重新 requeue 时，可以改变它的routing_key，以便新的队列处理，routing_key用<code>x-dead-letter-routing-key</code>指定，如果不指定则继续使用消息原来的routing_key。</p></li></ul></li></ul><h2 id="5-Message属性"><a href="#5-Message属性" class="headerlink" title="5. Message属性"></a>5. Message属性</h2><ul><li>routing_key<br>路由关键字，exchange根据这个关键字进行消息投递</li><li>delivery_mode<ul><li>1: Non-persistent，消息不持久化到磁盘，尽快被消费掉。重启broker之后消息丢失</li><li>2: Persistent，消息持久化。当然被取走的消息，也就不存在了</li></ul></li><li>headers<br>消息头信息，key/value形式，可以认为给消息打上了各种各样的标签。可用于代替 routing_key 去路由（结合headers来下的exchange），或者第三方插件使用。</li><li>properties<br>实际上 headers 和 delivery_mode 也是properties的一部分，因为使用较多，所以单独拿出去。这里也只提几个：<ul><li>priority<br>消息优先级。数字，优先级高的消息会排在队列头部  </li><li>correlation_id 和 reply_to<br>这两个一般用于实现服务间RPC调用， 即生产者发起请求到rabbitmq队列，等待处理结果返回，消费者处理完消息后返回结果给调用方。<br>reply_to 在消息里面告诉消费者，处理完的结果放到哪个队列，调用方根据 correlation_id 找到结果。详情参考 <a href="https://www.rabbitmq.com/tutorials/tutorial-six-python.html" target="_blank" rel="noopener">https://www.rabbitmq.com/tutorials/tutorial-six-python.html</a></li><li>expiration<br>消息自身的Time-To-Live，用的较少，也叫 Per-Message TTL In Publisher.<br>前面提到，队列的arguemnts可以设置 x-message-ttl ，也叫 Per-Queue Message TTL In Queues.消息是否过期以两者的最小值为准，并且消息自身过期时间到了之后，不会自动从队列删除，而是在发送给消费者的时候丢弃。<br>队列自身也有个 <code>x-expires</code>，它指的是队列在多久没有消费者连上来，超过这个时间后队列自动删除。</li></ul></li><li>payload: 消息正文</li></ul><h2 id="6-插件"><a href="#6-插件" class="headerlink" title="6. 插件"></a>6. 插件</h2><p>RabbitMQ支持插件式的来扩展功能。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">列举server上安装的所有插件</span><br><span class="line"># rabbitmq-plugins list</span><br><span class="line"> Configured: E = explicitly enabled; e = implicitly enabled</span><br><span class="line"> | Status:   * = running on rabbit@rabbitmq-01</span><br><span class="line"> |/</span><br><span class="line">[e*] amqp_client                       3.6.14</span><br><span class="line">[e*] cowboy                            1.0.4</span><br><span class="line">[e*] cowlib                            1.0.2</span><br><span class="line">[  ] rabbitmq_amqp1_0                  3.6.14</span><br><span class="line">[  ] rabbitmq_auth_backend_ldap        3.6.14</span><br><span class="line">[  ] rabbitmq_auth_mechanism_ssl       3.6.14</span><br><span class="line">[E*] rabbitmq_consistent_hash_exchange 3.6.14</span><br><span class="line">[  ] rabbitmq_event_exchange           3.6.14</span><br><span class="line">[  ] rabbitmq_federation               3.6.14</span><br><span class="line">[  ] rabbitmq_federation_management    3.6.14</span><br><span class="line">[  ] rabbitmq_jms_topic_exchange       3.6.14</span><br><span class="line">[E*] rabbitmq_management               3.6.14</span><br><span class="line">[e*] rabbitmq_management_agent         3.6.14</span><br><span class="line">[  ] rabbitmq_management_visualiser    3.6.14</span><br><span class="line">[  ] rabbitmq_mqtt                     3.6.14</span><br><span class="line">[  ] rabbitmq_random_exchange          3.6.14</span><br><span class="line">[  ] rabbitmq_recent_history_exchange  3.6.14</span><br><span class="line">[E*] rabbitmq_sharding                 3.6.14</span><br><span class="line">[  ] rabbitmq_shovel                   3.6.14</span><br><span class="line">[  ] rabbitmq_shovel_management        3.6.14</span><br><span class="line">[  ] rabbitmq_stomp                    3.6.14</span><br><span class="line">[  ] rabbitmq_top                      3.6.14</span><br><span class="line">[  ] rabbitmq_tracing                  3.6.14</span><br><span class="line">[  ] rabbitmq_trust_store              3.6.14</span><br><span class="line">[e*] rabbitmq_web_dispatch             3.6.14</span><br><span class="line">[  ] rabbitmq_web_mqtt                 3.6.14</span><br><span class="line">[  ] rabbitmq_web_mqtt_examples        3.6.14</span><br><span class="line">[  ] rabbitmq_web_stomp                3.6.14</span><br><span class="line">[  ] rabbitmq_web_stomp_examples       3.6.14</span><br><span class="line">[  ] sockjs                            0.3.4</span><br><span class="line"></span><br><span class="line">启用插件</span><br><span class="line"># rabbitmq-plugins enable plugin-name</span><br></pre></td></tr></table></figure></p><p>下面是几个常用插件：</p><ol><li><p>rabbitmq_management<br>管理 rabbitmq server 的插件，提供给予HTTP的API和 WebUI，提供管理exchanges、管理queues、管理users、管理policies，监控，发布/接收消息。功能强大，基本是必定开启的插件。<br>开启管理插件后，也可以选择不使用Web界面，从 <code>http://localhost:15672/cli/rabbitmqadmin</code> 下载 <code>rabbitmqadmin</code> 命令行工具，它用在一些脚本里面会很方便。（提示： rabbitmqctl 是不能创建exchange和queue，但rabbitmqadmin可以）</p></li><li><p>rabbitmq_federation<br>与MySQL Federated 存储引擎很相似，可以认为 federated exchange 是其它exchange(也叫upstream exchange)的“软连接”、“流量复制”。消息是被publish到上游exchange，然后消费者是从其它broker上的federated exchange订阅消息。<br>Federated exchanges/queues 是通过 AMQP 协议的Erlang客户端从真实broker里面取数据(不会消费源数据)，可以实现跨网络的消息提取，或者将不同地方的消息汇总到一处。应用场景有 broker / cluster 数据迁移，模仿真实数据的线下测试。</p></li><li><p>rabbitmq_shovel<br>shovel插件就是一个 消费者 + 生产者：从一个queue消费内容，发送到另一个exchange上，甚至可以对消息做些转换。你可以自己实现将消息从源broker消费，重新publish到另一个exchange，但shovel帮我们做好了。</p></li><li><p>rabbitmq_mqtt<br>实现了 MQTT 3.1 协议的adapter，如文章开头所述。</p></li><li><p>rabbitmq_consistent_hash_exchange<br>一致性hash exchange，如前文所述。</p></li></ol><h2 id="6-策略-Policy"><a href="#6-策略-Policy" class="headerlink" title="6. 策略 Policy"></a>6. 策略 Policy</h2><p>首先为什么rabbitmq会有策略这个东西。</p><p>前面我们讲到，queue和exchange有一些固定属性，如<code>durable</code>、<code>exclusive</code>、<code>auto-delete</code>等，还有一些可选参数，也叫<code>x-arguments</code>，如<code>x-max-length</code>、<code>x-queue-mode</code>。这些都是客户端在定义队列和交换器时指定的。</p><p>如果事后想修改 TTL 或者 queue length limit ，那么得修改应用、重新部署，甚至涉及到删除队列，重新declare。Policy就是解决这个痛点的，在服务端对匹配的 exchanges 或者 queues 设置参数，无需动应用。更多请参考 <a href="https://www.rabbitmq.com/parameters.html" target="_blank" rel="noopener">https://www.rabbitmq.com/parameters.html</a> </p><p>一个 policy 包含以下内容：</p><ul><li>name: 策略名字</li><li>pattern: 对哪些queues(exchanges)的应用策略，正则表达式</li><li>definition: 策略内容定义，key/value形式（也可以认为是JSON格式）</li><li>apply-to: 策略应用在什么身上，<code>queues</code>、<code>exchanges</code>、<code>all</code>。默认是all</li><li>priority: 策略优先级，默认0</li></ul><p>每个exchange/queue只能“注入”一个policy，所以如果要设置多个策略，把key/value组合成json，定义在一起。设置完成会马上生效，包括后面新创建的exchange、queues。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">将exchange设置为 alternate exchange:(策略名：AE)</span><br><span class="line">rabbitmqctl set_policy -p /some0 AE &quot;^maxwell.some3$&quot; &apos;&#123;&quot;alternate-exchange&quot;:&quot;maxwell.AE&quot;&#125;&apos; --apply-to exchanges</span><br><span class="line"></span><br><span class="line">将vhost /some0 的所有队列都设置成 Lazy Queue</span><br><span class="line">rabbitmqctl set_policy -p /some0 Lazy &quot;^&quot; &apos;&#123;&quot;queue-mode&quot;:&quot;lazy&quot;&#125;&apos; --apply-to queues</span><br><span class="line"></span><br><span class="line">队列名匹配 &apos;two-messages&apos; 的队列，设置最大队列消息数为2，超过之后的行为是 禁止接收新消息（与之对应的是 drop-head: 删除头部老的消息）</span><br><span class="line">rabbitmqctl set_policy my-pol &quot;^two-messages$&quot; &apos;&#123;&quot;max-length&quot;:2,&quot;overflow&quot;:&quot;reject-publish&quot;&#125;&apos; --apply-to queues</span><br></pre></td></tr></table></figure><h2 id="7-消息可靠性"><a href="#7-消息可靠性" class="headerlink" title="7. 消息可靠性"></a>7. 消息可靠性</h2><p>有的系统要保证消息不允许丢失，甚至不允许重复，有的系统追求的是高性能，所以要在性能和可靠性之间权衡。rabbitmq在多个层面提供消息可靠性保证。</p><h3 id="7-1-持久化"><a href="#7-1-持久化" class="headerlink" title="7.1 持久化"></a>7.1 持久化</h3><p>声明持久化的exchange: channel.exchange_delcare(exchange_name, durable)<br>声明持久化的队列：channel.queueDeclare(queue_name, durable, exclusive, auto_delete, arguments)<br>发布的持久化消息，投递模式为2： delivery_mode=2</p><p><a href="http://www.rabbitmq.com/reliability.html" target="_blank" rel="noopener">http://www.rabbitmq.com/reliability.html</a><br>persistent</p><h3 id="7-1-ack-amp-confirm"><a href="#7-1-ack-amp-confirm" class="headerlink" title="7.1 ack &amp; confirm"></a>7.1 ack &amp; confirm</h3><p>持久化保证了在broker或者机器出现异常的时候，消息不会丢失，要保证发送者在pub消息、接收sub消息时出现网络异常，客户端也应该有相应的处理。</p><h4 id="Consumer-Delivery-Acknowledgements"><a href="#Consumer-Delivery-Acknowledgements" class="headerlink" title="Consumer Delivery Acknowledgements"></a>Consumer Delivery Acknowledgements</h4><p>rabbitmq对Consumer处理消息提供 acknowledgements 确认机制，客户端通过<code>basic.consume</code>注册到broker(push)，或者通过<code>basic.get</code> pull 消息，都可以在指定是否开启<code>ack</code>。</p><p><em>delivery tags</em>是实现 ack 的关键，RabbitMQ会用 <code>basic.deliver</code> 方法向消费者推送消息，这个方法携带了一个 delivery tag，它是单调递增的正整数，在一个channel中唯一代表了一次投递。</p><p>确认模式包括自动确认和手动确认。<br>自动确认就是rabbitmq一旦把消息发送出去后，就认为成功，完成确认。此模式性能最高，只要消费者能处理的过来，但自然降低了消息到达处理的可靠性，比如一个消息还在路上，消费者的TCP连接或者channel就关闭了，那么消息也就丢失。如果消费者处理不过来，可能会导致消息在客户端挤压，内存过载，引发异常。所以自动确认一般用在消息比较平稳、客户端能处理的来的系统。</p><p>手动确认，就是客户端需要自己发送确认命令，包括：</p><ul><li>basic.ack —— 确认成功，客户端成功处理</li><li>basic.nack —— 确认失败，客户端处理失败，但依然删掉消息</li><li>basic.reject —— 确认失败，客户端处理失败，消息不删除，可重新发送。</li></ul><p>手动确认模式，可以控制消息处理的速度（流控QoS），通过 prefetch 设置该channel上最大没有确认的消息数，server会等待有空闲的配额时才继续发送给消费者。<br>手动确认模式如果不设置 prefetch_count，那么消费者可能会接收许多的消息但未ack，从而导致内存耗尽，所以这点需要小心。正常来说，100-300是个比较可控的范围。（当然如果是 pull 模式，就不存在QoS一说）</p><p><code>basic.ack</code>和<code>basic.nack</code>可以设置 <code>multiple</code> 字段，批量确认来减少网络传输。比如说在信道 <code>ch</code> 上有 delivery tags 5, 6, 7, 8 没有确认，当客户端发回的确认帧是8并且 multiple=true，那么5-8的tags都被ack。</p><p>在启用手动确认时，发生网络连接断开或者消费者崩溃，而无法返回 ack/nack 命令时，（检测方法是 <a href="https://www.rabbitmq.com/heartbeats.html" target="_blank" rel="noopener">heartbead</a>）rabbitmq会自动将没有确认的消息 <strong>requeue</strong>，所以客户端处理消息时，最好能满足幂等性，即能够重复处理这些消息。</p><h4 id="Publisher-Confirms"><a href="#Publisher-Confirms" class="headerlink" title="Publisher Confirms"></a>Publisher Confirms</h4><p>rabbitmq对Producer发布消息提供 confirm 机制：客户端可以发送一个 <code>confirm.select</code> 命令将channel设置成<code>confirm</code>工作模式。<br>所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者(basic.ack)，这就使得生产者知道消息已经正确到达目的队列了。如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker回传给生产者的确认消息中delivery-tag域包含了确认消息的序列号。</p><p>如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息，确保消息不会再发送之前就丢失。</p><p>然后对于需要持久化的消息的确认，不能完全保证数据被刷到磁盘上，因为每个消息调用 fsync 的带来的IO代价太高，rabbitmq会每隔几百毫秒，批量将消息从文件系统缓存 fsync 刷到磁盘。（了解MySQL的话对这个应该不陌生）</p><h3 id="7-2-事务"><a href="#7-2-事务" class="headerlink" title="7.2 事务"></a>7.2 事务</h3><p>RabbitMQ 实现了AMQP 0-9-1协议里的事务，这样说唯一能确保消息不丢失的方式，信道可以设置成 transaction 模式：发布消息，commit/rollback消息。</p><p>但是事务在这里太重了，而且会极大的降低性能。不用。</p><h3 id="7-3-rabbitmq分布式"><a href="#7-3-rabbitmq分布式" class="headerlink" title="7.3 rabbitmq分布式"></a>7.3 rabbitmq分布式</h3><p>待聊</p><h2 id="5-python使用示例"><a href="#5-python使用示例" class="headerlink" title="5. python使用示例"></a>5. python使用示例</h2><p><a href="https://pika.readthedocs.io/en/0.10.0/intro.html" target="_blank" rel="noopener">https://pika.readthedocs.io/en/0.10.0/intro.html</a></p><p>下面的示例是使用Maxwell或者MySQL binlog增量流，json数据进入rabbitmq，然后通过 pika —— python版本的rabbitmq client，重新组装成sql，达到数据增量同步的效果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line">def binlog_sync(self):</span><br><span class="line">     logger.info(&quot;connect to rabbitmq server [%s], vhost=%s&quot;, rabbitmq_conn_info.get(&apos;host&apos;), rabbitmq_conn_info.get(&apos;vhost&apos;, &apos;/&apos;))</span><br><span class="line">     ## rabbitmq 用户认证信息</span><br><span class="line">     credentials = pika.PlainCredentials(rabbitmq_conn_info.get(&apos;user&apos;, &apos;guest&apos;),</span><br><span class="line">                                         rabbitmq_conn_info.get(&apos;password&apos;, &apos;guest&apos;)</span><br><span class="line">     )</span><br><span class="line">     ## rabbitmq tcp连接</span><br><span class="line">     connection = pika.BlockingConnection(</span><br><span class="line">         pika.ConnectionParameters(</span><br><span class="line">             host=rabbitmq_conn_info.get(&apos;host&apos;),</span><br><span class="line">             port=rabbitmq_conn_info.get(&apos;port&apos;, 5672),</span><br><span class="line">             virtual_host=rabbitmq_conn_info.get(&apos;vhost&apos;, &apos;/&apos;),</span><br><span class="line">             credentials=credentials</span><br><span class="line">         )</span><br><span class="line">     )</span><br><span class="line">     ## rabbitmq 信道，避免频繁tcp断连</span><br><span class="line">     channel = connection.channel()</span><br><span class="line"></span><br><span class="line">     # exchange_name = &apos;maxwell.some&apos; + str(self.corpmod)</span><br><span class="line">     # exchange_other = &apos;maxwell.AE&apos;</span><br><span class="line">     logger.info(&quot;declare mq exchange [%s], type=[%s]&quot;, self.exchange_name, self.exchange_type)</span><br><span class="line">     ## 创建 exchange，如果已经存在相同名字，就不会重复创建，但要求属性要相同</span><br><span class="line">     ## 指定exchange_type，durable, arguments 。这里的alternate-exchange放到策略里从创建，因为目前maxwell作为消费者，没有支持arguemnts参数</span><br><span class="line">     channel.exchange_declare(exchange=self.exchange_name,</span><br><span class="line">                              exchange_type=self.exchange_type,</span><br><span class="line">                              durable=True,</span><br><span class="line">                              # arguments=&#123;&apos;alternate-exchange&apos;: exchange_other&#125;</span><br><span class="line">     )</span><br><span class="line"></span><br><span class="line">     &quot;&quot;&quot;</span><br><span class="line">     channel.exchange_declare(exchange=exchange_other, exchange_type=&apos;topic&apos;, durable=True)  # alternative exchange</span><br><span class="line">     channel.queue_declare(queue=&apos;ae_other&apos;, durable=True)</span><br><span class="line">     channel.queue_bind(exchange=exchange_other,</span><br><span class="line">                        queue=&apos;ae_other&apos;,</span><br><span class="line">                        routing_key=&apos;d_ec_some.*&apos;)</span><br><span class="line">     &quot;&quot;&quot;</span><br><span class="line">     logger.info(&quot;declare queue name=[%s]&quot;, self.queue_name)</span><br><span class="line">     ## 创建 queue，如果以经存在相同名字的队列，则不会创建，但要求属性相同，否则报错</span><br><span class="line">     ## 指定了 lazy queue</span><br><span class="line">     channel.queue_declare(queue=self.queue_name, durable=True, arguments=&#123;&apos;x-queue-mode&apos;: &apos;lazy&apos;&#125;)</span><br><span class="line"></span><br><span class="line">     ## 将routing_key 绑定到队列上</span><br><span class="line">     for key in self.queue_bind_key:</span><br><span class="line">         logger.info(&quot;bind routing_key [%s] to queue [%s]&quot;, key, self.queue_name)</span><br><span class="line">         channel.queue_bind(exchange=self.exchange_name,</span><br><span class="line">                            queue=self.queue_name,</span><br><span class="line">                            routing_key=key)</span><br><span class="line"></span><br><span class="line">     # consume callback, internal</span><br><span class="line">     ## 客户端处理消息</span><br><span class="line">     def callback(ch, method, properties, body):</span><br><span class="line">         # print(&quot; [x] Received %s&quot; % body)</span><br><span class="line">         logger.debug(&quot;Received message: %s&quot;, body)</span><br><span class="line">         try:</span><br><span class="line">             data_row = json.loads(body.decode(&apos;utf-8&apos;))</span><br><span class="line">             self.process_data(data_row)</span><br><span class="line"></span><br><span class="line">             if ret == -2:  # requeue</span><br><span class="line">             ## 处理异常，如Ctrl+C断开，重新排队</span><br><span class="line">                 logger.warning(&quot;message data: %s (requeue)&quot;, data_row)</span><br><span class="line">                 ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)</span><br><span class="line">                 # return</span><br><span class="line">         except ValueError as e:</span><br><span class="line">             logger.error(&quot;proces Error: %s(skip)&quot;, e)</span><br><span class="line">             logger.error(&quot;  received data: %s&quot;, body)</span><br><span class="line">             ## 处理异常，但跳过</span><br><span class="line">             ch.basic_ack(delivery_tag=method.delivery_tag)</span><br><span class="line">         except Exception as e:</span><br><span class="line">             logger.error(&quot;proces Error: %s(skip)&quot;, e)</span><br><span class="line">             logger.error(&quot;  message data: %s&quot;, data_row)</span><br><span class="line">             ch.basic_ack(delivery_tag=method.delivery_tag)</span><br><span class="line">         else:</span><br><span class="line">         ## 发送确认成功</span><br><span class="line">             ch.basic_ack(delivery_tag=method.delivery_tag)</span><br><span class="line">     </span><br><span class="line">     ## 设置最多 50 个未确认</span><br><span class="line">     channel.basic_qos(prefetch_count=50)</span><br><span class="line"></span><br><span class="line">     # 开始消费，拿到的消息调用callback处理</span><br><span class="line">     channel.basic_consume(callback, queue=self.queue_name, no_ack=False)</span><br><span class="line"></span><br><span class="line">     # print(&apos; [*] Waiting for messages. To exit press CTRL+C&apos;)</span><br><span class="line">     logger.info(&quot;start comsuming&quot;)</span><br></pre></td></tr></table></figure></p><p><strong>参考</strong></p><ul><li><a href="https://www.rabbitmq.com/tutorials/amqp-concepts.html" target="_blank" rel="noopener">https://www.rabbitmq.com/tutorials/amqp-concepts.html</a></li><li><a href="http://www.rabbitmq.com/admin-guide.html" target="_blank" rel="noopener">http://www.rabbitmq.com/admin-guide.html</a></li><li><a href="https://geewu.gitbooks.io/rabbitmq-quick/content/index.html" target="_blank" rel="noopener">https://geewu.gitbooks.io/rabbitmq-quick/content/index.html</a></li><li><a href="http://blog.csdn.net/anzhsoft/article/details/19607841" target="_blank" rel="noopener">http://blog.csdn.net/anzhsoft/article/details/19607841</a></li><li><a href="http://dbaplus.cn/news-141-1464-1.html" target="_blank" rel="noopener">http://dbaplus.cn/news-141-1464-1.html</a></li></ul><hr><p>原文连接地址：<a href="http://seanlook.com/2018/01/06/rabbitmq-introduce/">http://seanlook.com/2018/01/06/rabbitmq-introduce/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;rabbitmq可以用一本书取讲，这里只是介绍一些使用过程中，常用到的基本的知识点。&lt;br&gt;官方文档覆盖的内容，非常全面：&lt;a href=&quot;http://www.rabbitmq.com/documentation.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.rabbitmq.com/documentation.html&lt;/a&gt; 。&lt;/p&gt;
&lt;h2 id=&quot;1-介绍&quot;&gt;&lt;a href=&quot;#1-介绍&quot; class=&quot;headerlink&quot; title=&quot;1. 介绍&quot;&gt;&lt;/a&gt;1. 介绍&lt;/h2&gt;&lt;p&gt;RabbitMQ，即消息队列系统，它是一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。&lt;/p&gt;
&lt;p&gt;AMQP是一个公开发布的异步消息的规范，是提供统一消息服务的应用层标准高级消息队列协议，为面向消息的中间件设计.消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.rabbitmq.com/tutorials/amqp-concepts.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.rabbitmq.com/tutorials/amqp-concepts.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;相对于JMS(Java Message Service)规范来说，JMS使用的是特定语言的APIs，而消息格式可自由定义，而AMQP对消息的格式和传输是有要求的，但实现不会受操作系统、开发语言以及平台等的限制。&lt;/p&gt;
&lt;p&gt;JMS和AMQP还有一个较大的区别：JMS有队列(Queues)和主题(Topics)两种消息传递模型，发送到 JMS队列 的消息最多只能被一个Client消费，发送到 JMS主题 的消息可能会被多个Clients消费；AMQP只有队列(Queues)，队列的消息只能被单个接受者消费，发送者并不直接把消息发送到队列中，而是发送到Exchange中，该Exchage会与一个或多个队列绑定，能够实现与JMS队列和主题同样的功能。&lt;/p&gt;
&lt;p&gt;另外还有一种 MQTT协议，意为消息队列遥测传输，是IBM开发的一个即时通讯协议。由于其维护一个长连接以轻量级低消耗著称，所以常用于移动端消息推送服务开发。MQTT是基于TCP的应用层协议封装，实现了异步Pub/Sub，在物联网（IoT）应用广泛。&lt;/p&gt;
&lt;p&gt;RabbitMQ可通过库、插件的形式，支持JMS和MQTT协议。参考：&lt;a href=&quot;http://geek.csdn.net/news/detail/71894&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://geek.csdn.net/news/detail/71894&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;1-1-主要概念&quot;&gt;&lt;a href=&quot;#1-1-主要概念&quot; class=&quot;headerlink&quot; title=&quot;1.1 主要概念&quot;&gt;&lt;/a&gt;1.1 主要概念&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_MRG/2/html-single/Messaging_Programming_Reference/images/1083.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Broker&lt;br&gt;接收和分发消息的应用，RabbitMQ Server就是Message Broker&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Exchange&lt;br&gt;message到达broker的第一站，根据分发规则，匹配查询表中的routing key，分发消息到queue中去。常用的类型有：direct, topic, fanout。&lt;br&gt;如果没有队列绑定到exchange上，那么该exchange上的消息都会被丢弃，因为它不存储消息又不知道该怎么处理消息。&lt;/p&gt;
    
    </summary>
    
      <category term="MQ" scheme="http://seanlook.com/categories/MQ/"/>
    
    
      <category term="消息队列" scheme="http://seanlook.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
      <category term="rabbitmq" scheme="http://seanlook.com/tags/rabbitmq/"/>
    
  </entry>
  
  <entry>
    <title>MySQL数据库表结构同步之SchemaSync</title>
    <link href="http://seanlook.com/2017/11/02/mysql_schemasync/"/>
    <id>http://seanlook.com/2017/11/02/mysql_schemasync/</id>
    <published>2017-11-02T07:32:49.000Z</published>
    <updated>2017-11-02T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>SchemaSync是个能够在mysql数据库之间，比较并生成表结构差异的工具，项目地址 <a href="https://github.com/mmatuson/SchemaSync" target="_blank" rel="noopener">https://github.com/mmatuson/SchemaSync</a>  。</p><h1 id="SchemaSync介绍与使用"><a href="#SchemaSync介绍与使用" class="headerlink" title="SchemaSync介绍与使用"></a>SchemaSync介绍与使用</h1><p>因为工作中经常需要在各个环境之间同步表结构，特别是生产与测试环境之间，长时间的运行后，总会有不一致的。测试环境的表结构一般是测试验证功能之后没有问题，然后通过工单的形式由DBA在生产环境修改。但生产库的结构，如修改索引，紧急修改字段长度，久而久之就会与测试环境有差异，需要同步到测试环境。</p><p>又或者有多套测试环境之间要保持结构同步，又比如同一类db（分库）的情况下，比较schema之间的对象差异。</p><p>SchemaSync不仅限于表结构，它可以处理的对象还有：视图、事件、存储过程、函数、触发器、外键，与 mysql-utilities 相当。但 SchemaSync 更适合于实践：</p><ol><li>默认不会同步 <code>AUTO_INCREMENT</code> 和  COMMENT`，有选项可以控制</li><li>对不存在的对象会生成对应的CREATE，对多余的对象会生成DROP</li><li>对生成 alter…column 的sql，是有列顺序的</li><li>安装简单，相比mysqldiff，要安装mysql-connector-python和一整套mysql-utilities工具</li></ol><p>当然前两点在我自己的 <code>mysqldiff</code> 版本里，已经加入了支持，见 <a href="http://seanlook.com/2017/08/05/mysql_mysqldiff/">MySQL数据库表结构同步之mysqldiff</a></p><p><strong>SchemaSync安装：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（使用virtualenv）</span><br><span class="line">$ pip install mysql-python pymysql schemaobject schemasync</span><br></pre></td></tr></table></figure></p><p>SchemaObject也是同一个作者的，专门用于操作数据库对象的库，于是schemasync只需要获取对象，比较差异，然后调用schemaobect生成sql。（SchemaObject依赖pymysql，SchemaSync依赖MySQLdb，其实可以用同一个）<br><a id="more"></a></p><p><strong>SchemaSync用法：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ schemasync --help</span><br><span class="line">Usage: </span><br><span class="line">                schemasync [options] &lt;source&gt; &lt;target&gt;</span><br><span class="line">                source/target format: mysql://user:pass@host:port/database</span><br><span class="line"></span><br><span class="line">                        A MySQL Schema Synchronization Utility</span><br><span class="line"></span><br><span class="line">Options:</span><br><span class="line">  -h, --help            show this help message and exit</span><br><span class="line">  -V, --version         show version and exit.</span><br><span class="line">  -r, --revision        increment the migration script version number if a</span><br><span class="line">                        file with the same name already exists.</span><br><span class="line">  -a, --sync-auto-inc   sync the AUTO_INCREMENT value for each table.</span><br><span class="line">  -c, --sync-comments   sync the COMMENT field for all tables AND columns</span><br><span class="line">  -D, --no-date         removes the date from the file format</span><br><span class="line">  --charset=CHARSET     set the connection charset, default: utf8</span><br><span class="line">  --tag=TAG             tag the migration scripts as &lt;database&gt;_&lt;tag&gt;. Valid</span><br><span class="line">                        characters include [A-Za-z0-9-_]</span><br><span class="line">  --output-directory=OUTPUT_DIRECTORY</span><br><span class="line">                        directory to write the migration scrips. The default</span><br><span class="line">                        is current working directory. Must use absolute path</span><br><span class="line">                        if provided.</span><br><span class="line">  --log-directory=LOG_DIRECTORY</span><br><span class="line">                        set the directory to write the log to. Must use</span><br><span class="line">                        absolute path if provided. Default is output</span><br><span class="line">                        directory. Log filename is schemasync.log</span><br></pre></td></tr></table></figure></p><p>示例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ schemasync mysql://ecuser:dbpass@10.x.xxx.141:3307/d_dbtest mysql://ecuser:dbpass@192.168.x.xxx:3306/d_dbtest --tag=BASE</span><br><span class="line">Migration scripts created for mysql://192.168.x.xxx/d_dbtest</span><br><span class="line">Patch Script: /home/zx/SchemaSync/d_dbtest_BASE.20171111.patch.sql</span><br><span class="line">Revert Script: /home/zx/SchemaSync/d_dbtest_BASE.20171111.revert.sql</span><br></pre></td></tr></table></figure></p><p>第一个是source db，第二个是target db，是标准的 connection string url 格式。<br><code>--tag</code>, <code>--no-date</code>：都是控制生成的ddl文件名格式。</p><h1 id="问题修复与增强"><a href="#问题修复与增强" class="headerlink" title="问题修复与增强"></a>问题修复与增强</h1><p>有两个小问题都是在SchemaObject里面，而且都有人 <a href="https://github.com/mmatuson/SchemaObject/pulls" target="_blank" rel="noopener">提交patch</a> 但还没合并到主干：</p><ol><li>ADD INDEX 语法错误，<code>alter table t ADD INDEX ON t</code>，不需要这个ON。在不用alter table而直接 ADD INDEX 才要。</li><li>schemaobject 生成 <code>DEFAULT &#39;xx&#39;</code> 时不支持python3。当然文件里也只说了支持2.6,2.7</li></ol><p>目前我们的做法是对 schemaobject/index.py 大概170行的地方，手动修改，也懒的fork自己的分支：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-            return &quot;DROP INDEX `%s` ON `%s`&quot; % (self.name, self.parent.name)</span><br><span class="line">+            return &quot;DROP INDEX `%s`&quot; % (self.name)</span><br></pre></td></tr></table></figure></p><p>另一个增强是如果我想比较一个实例下面的所有database，SchemaSync是要手动一个一个去运行，于是拉了个自己的分支，支持<br><code>mysql://user:pass@host:port/*</code> 的格式，自动遍历实例下面所有的schema（忽略mysql,information_schema,performance_schema,sys），然后递归调用自身。使用起来就方便多了。</p><p>代码地址：<a href="https://github.com/seanlook/SchemaSync" target="_blank" rel="noopener">https://github.com/seanlook/SchemaSync</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ schemasync mysql://ecuser:dbpass@10.x.xxx.141:3307/* mysql://ecuser:dbpass@192.168.x.xxx:3306/* --tag=BASE</span><br><span class="line"> </span><br><span class="line">Migration scripts created for mysql://192.168.x.xxx/d_ec_admin</span><br><span class="line">Patch Script: /home/zx/SchemaSync/d_ec_admin_BASE.20171110.patch.sql</span><br><span class="line">Revert Script: /home/zx/SchemaSync/d_ec_admin_BASE.2017110.revert.sql</span><br><span class="line">...</span><br><span class="line">MySQL Error 1049: Unknown database &apos;d_ec_package_bak_1027&apos; (Ignore)  # 对db在目标库不存在的情况，忽略，不会CREAETE DATABASE</span><br><span class="line">...</span><br><span class="line">Migration scripts created for mysql://192.168.x.xxx/d_ec_package</span><br><span class="line">Patch Script: /home/zx/SchemaSync/d_ec_package_BASE.20171110.patch.sql</span><br><span class="line">Revert Script: /home/zx/SchemaSync/d_ec_package_BASE.20171110.revert.sql</span><br><span class="line"></span><br><span class="line">$ cat *_BASE.20171110.patch.sql &gt; target_schema_BASE.20171110.patch.sql</span><br></pre></td></tr></table></figure><p>生成结构后不要盲目去执行同步，还要审查一遍，否则把不改删的字段删了就惨了。<br>还有，如果你在目标表上只是改变了列名，那么schema比较的时候，也是先drop在add，这个风险要自己把握。</p><p>如果要安装这个增强后的版本，请使用这种方式安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install git+https://github.com/seanlook/SchemaSync.git</span><br></pre></td></tr></table></figure></p><hr><p>原文连接地址：<a href="http://seanlook.com/2017/11/02/mysql_schemasync/">http://seanlook.com/2017/11/02/mysql_schemasync/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;SchemaSync是个能够在mysql数据库之间，比较并生成表结构差异的工具，项目地址 &lt;a href=&quot;https://github.com/mmatuson/SchemaSync&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/mmatuson/SchemaSync&lt;/a&gt;  。&lt;/p&gt;
&lt;h1 id=&quot;SchemaSync介绍与使用&quot;&gt;&lt;a href=&quot;#SchemaSync介绍与使用&quot; class=&quot;headerlink&quot; title=&quot;SchemaSync介绍与使用&quot;&gt;&lt;/a&gt;SchemaSync介绍与使用&lt;/h1&gt;&lt;p&gt;因为工作中经常需要在各个环境之间同步表结构，特别是生产与测试环境之间，长时间的运行后，总会有不一致的。测试环境的表结构一般是测试验证功能之后没有问题，然后通过工单的形式由DBA在生产环境修改。但生产库的结构，如修改索引，紧急修改字段长度，久而久之就会与测试环境有差异，需要同步到测试环境。&lt;/p&gt;
&lt;p&gt;又或者有多套测试环境之间要保持结构同步，又比如同一类db（分库）的情况下，比较schema之间的对象差异。&lt;/p&gt;
&lt;p&gt;SchemaSync不仅限于表结构，它可以处理的对象还有：视图、事件、存储过程、函数、触发器、外键，与 mysql-utilities 相当。但 SchemaSync 更适合于实践：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;默认不会同步 &lt;code&gt;AUTO_INCREMENT&lt;/code&gt; 和  COMMENT`，有选项可以控制&lt;/li&gt;
&lt;li&gt;对不存在的对象会生成对应的CREATE，对多余的对象会生成DROP&lt;/li&gt;
&lt;li&gt;对生成 alter…column 的sql，是有列顺序的&lt;/li&gt;
&lt;li&gt;安装简单，相比mysqldiff，要安装mysql-connector-python和一整套mysql-utilities工具&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当然前两点在我自己的 &lt;code&gt;mysqldiff&lt;/code&gt; 版本里，已经加入了支持，见 &lt;a href=&quot;http://seanlook.com/2017/08/05/mysql_mysqldiff/&quot;&gt;MySQL数据库表结构同步之mysqldiff&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SchemaSync安装：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;（使用virtualenv）&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ pip install mysql-python pymysql schemaobject schemasync&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;SchemaObject也是同一个作者的，专门用于操作数据库对象的库，于是schemasync只需要获取对象，比较差异，然后调用schemaobect生成sql。（SchemaObject依赖pymysql，SchemaSync依赖MySQLdb，其实可以用同一个）&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="表结构" scheme="http://seanlook.com/tags/%E8%A1%A8%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>MySQL order by limit 走错索引(range-&gt;indexscan)</title>
    <link href="http://seanlook.com/2017/10/26/mysql-bad-plan-order_by-limit/"/>
    <id>http://seanlook.com/2017/10/26/mysql-bad-plan-order_by-limit/</id>
    <published>2017-10-26T07:32:49.000Z</published>
    <updated>2017-10-26T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>生产库遇到过好几例本文要讨论的案例，而且比较棘手。简而言之，有类似这样的查询 <code>SELECT * FROM t1 where t1.f2&gt;1 and t2.f2&lt;100 order by t1.id</code>，id是主键，条件里面有个range查询，就会造成优化器是选择主键，还是选择filesort问题，有些特殊情况就会选错索引，比如为了回避内存排序，选择了主键扫描，导致原本走范围过滤再sort 500ms勉强可以结束的查询，5分钟不出结果。</p><p>下面具体来这个案例。</p><h1 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h1><p>阿里云RDS，5.6.16-log。<br>表 d_ec_someextend.t_tbl_test_time_08:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t_tbl_test_time_08` (</span><br><span class="line">  `f_some_id` int(11) unsigned DEFAULT &apos;0&apos;,</span><br><span class="line">  `f_qiye_id` int(11) DEFAULT &apos;0&apos;,</span><br><span class="line">  `f_type` tinyint(3) DEFAULT &apos;0&apos; COMMENT &apos;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段&apos;,</span><br><span class="line">  `f_contact_time` timestamp NULL DEFAULT &apos;1970-01-01 16:00:01&apos;,</span><br><span class="line">  UNIQUE KEY `some_qiye_type` (`f_some_id`,`f_qiye_id`,`f_type`),</span><br><span class="line">  KEY `f_contact_time` (`f_contact_time`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br></pre></td></tr></table></figure></p><p>表索引信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show table status like &quot;t_tbl_test_time_08&quot;;</span><br><span class="line">+-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+</span><br><span class="line">| Name                  | Engine | Version | Row_format | Rows     | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time         | Update_time | Check_time | Collation          | Checksum | Create_options | Comment | Block_format |</span><br><span class="line">+-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+</span><br><span class="line">| t_tbl_test_time_08 | InnoDB |      10 | Compact    | 19264318 |             45 |   882900992 |               0 |   2176843776 | 752877568 | NULL           | 2017-10-25 20:27:08 | NULL        | NULL       | utf8mb4_general_ci | NULL     |                |         | Original     |</span><br><span class="line">+-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+</span><br><span class="line">1 row in set</span><br><span class="line"> </span><br><span class="line">mysql&gt; show index from t_tbl_test_time_08;</span><br><span class="line">+--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| Table              | Non_unique | Key_name        | Seq_in_index | Column_name    | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |</span><br><span class="line">+--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">| t_tbl_test_time_08 |          0 | some_qiye_type  |            1 | f_some_id      | A         |    19264318 | NULL     | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">| t_tbl_test_time_08 |          0 | some_qiye_type  |            2 | f_qiye_id      | A         |    19264318 | NULL     | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">| t_tbl_test_time_08 |          0 | some_qiye_type  |            3 | f_type         | A         |    19264318 | NULL     | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">| t_tbl_test_time_08 |          1 | f_contact_time  |            1 | f_contact_time | A         |     9632159 | NULL     | NULL   | YES  | BTREE      |         |               |</span><br><span class="line">+--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span><br><span class="line">4 rows in set</span><br></pre></td></tr></table></figure></p><p><strong>问题查询：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select f_some_id from d_ec_some1.t_tbl_test_time_08</span><br><span class="line">where f_qiye_id=5077665 and f_type=9</span><br><span class="line">and f_contact_time &gt; &apos;2017-10-17 14:23:49&apos; and f_contact_time &lt; &apos;2017-10-17 14:23:53&apos;</span><br><span class="line">order by f_some_id limit 300</span><br></pre></td></tr></table></figure></p><a id="more"></a><p>该表的其它查询：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SELECT `c`.`f_some_id`, max(f_contact_time) AS `time` FROM `d_ec_some`.`t_some_relation` AS `r`</span><br><span class="line">LEFT JOIN `d_ec_someextend`.`t_tbl_test_time_10` AS `c` ON c.f_some_id=r.f_some_id AND c.f_type in(1,2,3,4,5,6,7)</span><br><span class="line">WHERE (r.f_qiye_id=&apos;4047065&apos; and r.f_user_id=&apos;4047064&apos; and c.f_some_id is not null)</span><br><span class="line">GROUP BY `f_some_id` ORDER BY `time` desc LIMIT 20</span><br><span class="line">-- group-by, order-by</span><br><span class="line">  </span><br><span class="line">select f_some_id, f_type, f_contact_time from d_ec_some1.t_tbl_test_time_08</span><br><span class="line">where f_qiye_id = 1181333</span><br><span class="line">and f_type &gt; 0 and f_type &lt; 11</span><br><span class="line">and f_some_id &gt; 263047293 and f_some_id &lt; 780306437</span><br><span class="line">order by f_some_id</span><br><span class="line">-- 分页</span><br></pre></td></tr></table></figure></p><h1 id="2-explain"><a href="#2-explain" class="headerlink" title="2. explain"></a>2. explain</h1><p>问题查询执行计划：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain extended select f_some_id from d_ec_some1.t_tbl_test_time_08</span><br><span class="line">where f_qiye_id=5077665 and f_type=9</span><br><span class="line">and f_contact_time &gt; &apos;2017-10-17 14:23:49&apos; and f_contact_time &lt; &apos;2017-10-17 14:23:53&apos;</span><br><span class="line">order by f_some_id limit 300;</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+---------------+---------+------+-------+----------+-------------+</span><br><span class="line">| id | select_type | table                 | type  | possible_keys  | key           | key_len | ref  | rows  | filtered | Extra       |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+---------------+---------+------+-------+----------+-------------+</span><br><span class="line">|  1 | SIMPLE      | t_tbl_test_time_08    | index | f_contact_time | some_qiye_type | 12     | NULL | 16032 |  2248.49 | Using where |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+---------------+---------+------+-------+----------+-------------+</span><br><span class="line">1 row in set</span><br><span class="line"> </span><br><span class="line">-- 指定一个索引</span><br><span class="line">mysql&gt; explain extended select f_some_id from d_ec_some1.t_tbl_test_time_08  use index(f_contact_time)</span><br><span class="line">where f_qiye_id=5077665 and f_type=9</span><br><span class="line">and f_contact_time &gt; &apos;2017-10-17 14:23:49&apos; and f_contact_time &lt; &apos;2017-10-17 14:23:53&apos;</span><br><span class="line">order by f_some_id limit 300;</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+----------+---------------------------------------------------------------+</span><br><span class="line">| id | select_type | table                 | type  | possible_keys  | key            | key_len | ref  | rows   | filtered | Extra                                                         |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+----------+---------------------------------------------------------------+</span><br><span class="line">|  1 | SIMPLE      | t_tbl_test_time_08    | range | f_contact_time | f_contact_time | 5       | NULL | 360478 |      100 | Using index condition; Using where; Using MRR; Using filesort |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+----------+---------------------------------------------------------------+</span><br><span class="line">1 row in set</span><br></pre></td></tr></table></figure></p><p>解释：<br>第一个explain结果里面，<code>type=index</code>，表示 full index scan。注意这里看到的 index 不代表“查询用到索引了”。全索引扫描比全表扫描并不好到拿去，甚至更慢（因为随机IO）。是否用到正确的索引要看key那一列:<br><code>some_qiye_type</code> 索引定义是 <code>(f_some_id,f_qiye_id,f_type)</code>，从key_len=12看得出这三列都用上了（12=4+5+3）。但实际这个执行计划需要200多秒。</p><p>第二个explain，在sql里面指定了 <code>use index(f_contact_time)</code>，依据是where条件里面f_contact_time的范围固定4s，猜想数据量不会很大，过滤效果会比较好。<br>解释器结果，<code>type=range</code>，表示是个范围查找(“范围”涵盖的种类不止&lt;/&gt;)，使用的索引是 <code>f_contact_time(f_contact_time)</code>。Extra列:</p><ul><li><code>Using index condition</code>: 用到了索引下推特性。Using where是回表拿数据。关于ICP见文后参考。</li><li><code>Using MRR</code>: 用到了 Multi-Range Read 优化特性。mysql在通过二级索引范围查找的时候，得到的记录在物理上是无序的，为了减少去获取数据的随机IO，它会在内存缓冲区里面先根据rowid快速排序，然后顺序IO去拉取数据。（这个缓冲区大小参数由 read_rnd_buffer_size 控制）</li><li><code>Using filesort</code>: 需要内存排序。对应 order by f_some_id</li></ul><p>rows扫描虽然36w行，比前面的 16032 要多，但这个执行计划实际运行只需要0.7s，要快将近300倍。</p><p>但MySQL优化器默认选择了第一个更慢的执行计划，它的理由是走 some_qiye_type 索引不需要内存排序，候选的 f_contact_time 被淘汰。mysql是基于cost的，所以在想是不是有什么参数可以改变optimizer的行为，让它filesort。<br>（这里提一下，这类查询该表上非常多，绝大部分都走的是 f_contact_time，偶尔会有几条走some_qiye_type。这种执行计划不稳定的查询，实际带来的风险是会很高的，可能会拖垮db）</p><p>这里我们祭出优化sql的两大法宝：profiling和optimizer_trace，来尝试找出是什么因素。</p><ul><li><code>profiling</code>：可以定位出sql从接受到返回结果，时间都耗在哪里</li><li><code>optimizer_trace</code>: 跟踪优化器的成本评估过程，可以情况的看到它如何从多个候选索引里，做出选择</li></ul><h1 id="3-profiling"><a href="#3-profiling" class="headerlink" title="3. profiling"></a>3. profiling</h1><p>先来看两种查询计划 profiling 的结果。</p><p>profiling 默认<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set profiling=1;</span><br><span class="line">mysql&gt; select f_some_id from d_ec_some1.t_tbl_test_time_08 where f_qiye_id=5077665 and f_type=9</span><br><span class="line">and f_contact_time &gt; &apos;2017-10-17 14:23:49&apos; and f_contact_time &lt; &apos;2017-10-17 14:23:53&apos; order by f_some_id limit 300;</span><br><span class="line"></span><br><span class="line">mysql&gt; show profile block io,cpu for query 1;</span><br><span class="line">+----------------------+------------+------------+------------+--------------+---------------+</span><br><span class="line">| Status               | Duration   | CPU_user   | CPU_system | Block_ops_in | Block_ops_out |</span><br><span class="line">+----------------------+------------+------------+------------+--------------+---------------+</span><br><span class="line">| starting             | 0.000121   | 0          | 0          |            0 |             0 |</span><br><span class="line">| checking permissions | 3.2E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| Opening tables       | 3.7E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| init                 | 4.2E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| System lock          | 2.9E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| optimizing           | 3.3E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| statistics           | 0.005796   | 0          | 0.000999   |          448 |             0 |</span><br><span class="line">| preparing            | 4.3E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| Sorting result       | 2.8E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| executing            | 2.7E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| Sending data         | 172.824522 | 189.040262 | 2.441629   |      1504928 |          6896 |</span><br><span class="line">| end                  | 8.3E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| query end            | 3E-5       | 0          | 0          |            0 |             0 |</span><br><span class="line">| closing tables       | 3.3E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| freeing items        | 7E-5       | 0          | 0          |            0 |             0 |</span><br><span class="line">| logging slow query   | 3.1E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| Opening tables       | 3.4E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">| System lock          | 7E-5       | 0          | 0          |            0 |             8 |</span><br><span class="line">| cleaning up          | 9.5E-5     | 0          | 0          |            0 |             0 |</span><br><span class="line">+----------------------+------------+------------+------------+--------------+---------------+</span><br><span class="line">19 rows in set</span><br><span class="line"> </span><br><span class="line">mysql&gt; show status like &quot;Handler%&quot;;</span><br><span class="line">+----------------------------+---------+</span><br><span class="line">| Variable_name              | Value   |</span><br><span class="line">+----------------------------+---------+</span><br><span class="line">| Handler_commit             | 1       |</span><br><span class="line">| Handler_delete             | 0       |</span><br><span class="line">| Handler_discover           | 0       |</span><br><span class="line">| Handler_external_lock      | 4       |</span><br><span class="line">| Handler_mrr_init           | 0       |</span><br><span class="line">| Handler_prepare            | 0       |</span><br><span class="line">| Handler_read_first         | 1       |</span><br><span class="line">| Handler_read_key           | 1       |</span><br><span class="line">| Handler_read_last          | 0       |</span><br><span class="line">| Handler_read_next          | 9430930 |</span><br><span class="line">| Handler_read_prev          | 0       |</span><br><span class="line">| Handler_read_rnd           | 0       |</span><br><span class="line">| Handler_read_rnd_next      | 0       |</span><br><span class="line">| Handler_rollback           | 0       |</span><br><span class="line">| Handler_savepoint          | 0       |</span><br><span class="line">| Handler_savepoint_rollback | 0       |</span><br><span class="line">| Handler_update             | 0       |</span><br><span class="line">| Handler_write              | 1       |</span><br><span class="line">+----------------------------+---------+</span><br><span class="line">18 rows in set</span><br></pre></td></tr></table></figure></p><p>profiling use index:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set profiling=1;</span><br><span class="line">mysql&gt; select .... use index(f_contact_time)</span><br><span class="line">mysql&gt; show profile block io,cpu for query 1;</span><br><span class="line">+----------------------+----------+----------+------------+--------------+---------------+</span><br><span class="line">| Status               | Duration | CPU_user | CPU_system | Block_ops_in | Block_ops_out |</span><br><span class="line">+----------------------+----------+----------+------------+--------------+---------------+</span><br><span class="line">| starting             | 0.00013  | 0        | 0          |            0 |             0 |</span><br><span class="line">| checking permissions | 3.4E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| Opening tables       | 4.5E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| init                 | 4.6E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| System lock          | 3E-5     | 0        | 0          |            0 |             0 |</span><br><span class="line">| optimizing           | 3.9E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| statistics           | 0.000109 | 0        | 0          |            0 |             0 |</span><br><span class="line">| preparing            | 5.5E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| Sorting result       | 3.1E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| executing            | 3.2E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| Sending data         | 3.4E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| Creating sort index  | 1.703224 | 1.718739 | 0.012999   |            0 |             0 |</span><br><span class="line">| end                  | 8.4E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| query end            | 3.2E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| closing tables       | 3.9E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| freeing items        | 7.3E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| logging slow query   | 3.2E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">| Opening tables       | 5E-5     | 0        | 0          |            0 |             0 |</span><br><span class="line">| System lock          | 6.9E-5   | 0        | 0          |            0 |             8 |</span><br><span class="line">| cleaning up          | 4.1E-5   | 0        | 0          |            0 |             0 |</span><br><span class="line">+----------------------+----------+----------+------------+--------------+---------------+</span><br><span class="line">20 rows in set</span><br><span class="line">set profiling=0;</span><br><span class="line"> </span><br><span class="line">mysql&gt; show status like &quot;Handler%&quot;;</span><br><span class="line">+----------------------------+--------+</span><br><span class="line">| Variable_name              | Value  |</span><br><span class="line">+----------------------------+--------+</span><br><span class="line">| Handler_commit             | 1      |</span><br><span class="line">| Handler_delete             | 0      |</span><br><span class="line">| Handler_discover           | 0      |</span><br><span class="line">| Handler_external_lock      | 6      |</span><br><span class="line">| Handler_mrr_init           | 0      |</span><br><span class="line">| Handler_prepare            | 0      |</span><br><span class="line">| Handler_read_first         | 0      |</span><br><span class="line">| Handler_read_key           | 188156 |</span><br><span class="line">| Handler_read_last          | 0      |</span><br><span class="line">| Handler_read_next          | 188155 |</span><br><span class="line">| Handler_read_prev          | 0      |</span><br><span class="line">| Handler_read_rnd           | 188155 |</span><br><span class="line">| Handler_read_rnd_next      | 0      |</span><br><span class="line">| Handler_rollback           | 0      |</span><br><span class="line">| Handler_savepoint          | 0      |</span><br><span class="line">| Handler_savepoint_rollback | 0      |</span><br><span class="line">| Handler_update             | 0      |</span><br><span class="line">| Handler_write              | 1      |</span><br><span class="line">+----------------------------+--------+</span><br><span class="line">18 rows in set</span><br></pre></td></tr></table></figure></p><p><strong>第一个profiling</strong><br>看到第一个profiling里面 <code>Sending data</code> 时间最长，第二个 <code>Creating sort index</code> 最久<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Sending data:</span><br><span class="line">The thread is reading and processing rows for a SELECT statement, and sending data to the client. Because operations occurring during this state tend to perform large amounts of disk access (reads), it is often the longest-running state over the lifetime of a given query.</span><br><span class="line">  </span><br><span class="line">Creating sort index</span><br><span class="line">The thread is processing a SELECT that is resolved using an internal temporary table</span><br></pre></td></tr></table></figure></p><p>Sending data 很具有误导性，它不仅表示发送数据到客户端，还包括“收集”数据，即mysql根据索引条件检索完数据后，得到一堆rowid，再根据rowid回表拿数据，有可能还要对数据过滤、排序，所以抛开网络因素，sending data时间长表明有大量的读磁盘操作，是非常笼统的一个状态。<br>下面的status里面</p><ul><li><code>Handler_read_first</code>: 索引里面第一条记录被读取的次数，为1，说明做了一次索引全扫描。与前面 explain 结果 type=index 是一致的。</li><li><code>Handler_read_key</code>：根据索引定位到一行记录的次数。这个值越高，说明使用到了高效的索引。</li><li><p><code>Handler_read_next</code>：<br>Number of requests to read the next row in key order, incremented if you are querying an index column<br>with a range constraint or if you are doing an index scan.</p><p>即根据索引key的顺序，依次去获取行数据的次数。<br>这个值在这里非常的大，表明Server读取从头读取索引 <code>(f_some_id,f_qiye_id,f_type)</code> key的 9430930 行数据之后，找到了300个满足条件的记录，并且已是排好顺序。在这里值会随着limit的增大而增大。</p></li></ul><p><strong>第二个profiling</strong></p><ul><li><p><code>Handler_read_rnd</code>：<br>The number of requests to read a row based on a fixed position. This value is high if you are doing a lot of queries<br>that require sorting of the result. You probably have a lot of queries that require MySQL to scan entire tables or you have joins<br>that don’t use keys properly.</p><p>随机读取行数据的次数，可以认为是有一堆没有顺序的主键，要依次去读取数据的次数（随机IO）。一般在有内存排序的时候，后者join查询的副表关联字段上没有好的索引，这个值都会比较高。</p></li></ul><p>经过计算，条件满足 <code>f_contact_time &gt; &#39;2017-10-17 14:23:49&#39; and f_contact_time &lt; &#39;2017-10-17 14:23:53&#39;</code> 的记录有188155 个，因此根据索引依次读取到的行数 Handler_read_key=188155。</p><p>这里有两个疑问个人没有解开：</p><ol><li>既然有MRR，Handler_read_rnd为什么还这么高呢，不应该是是顺序IO了？<br>这里不太肯定，两种可能：一是MRR不影响这个计数；第二种可能是，我们这个表上没有主键，唯一索引也不满足所有列都NOT NULL定义，也就是这个表的主键实际是innodb内部维持增长的rowid，使用MRR之后，rowid有序但并不连续，读取行的随机性没有得到大的改善。</li><li><code>Using index condition</code> 在这里有点费解，因为似乎没有where条件可以下推，f_contact_time索引只有 f_contact_time 这一列。</li></ol><p>上面的分析过程只能知道实际执行过程是怎样的，直接从explain也能看出结果，这里是顺便理解一下 Hander_read_xxx, MRR, ICP 的含义，大部分sql优化都不用不到profiling和status。</p><h1 id="4-optimizer-trace"><a href="#4-optimizer-trace" class="headerlink" title="4. optimizer_trace"></a>4. optimizer_trace</h1><p>再看 optimizer_trace 跟踪的结果：(因为trace的信息太长，放到github gist上了)</p><ul><li>default： <a href="https://gist.github.com/seanlook/fe7d9065b1c05e766d88b4a5c3babb65" target="_blank" rel="noopener">https://gist.github.com/seanlook/fe7d9065b1c05e766d88b4a5c3babb65</a></li><li>use index：<a href="https://gist.github.com/seanlook/b687daf63c8babee96f567c123cb9ddd" target="_blank" rel="noopener">https://gist.github.com/seanlook/b687daf63c8babee96f567c123cb9ddd</a></li></ul><p>optimizer_trace包含三个步骤，下面是本次trace简化的结构：</p><ol><li>json_preparation</li><li>json_optimization<ul><li>condition_processing<ul><li>equality_propagation</li><li>constant_propagation</li><li>trivial_condition_removal</li></ul></li><li>table_dependencies</li><li>ref_optimizer_key_uses</li><li>rows_estimation<ul><li>range_analysis</li><li>table_scan</li><li>potential_range_indices</li><li>chosen_range_access_summary</li></ul></li><li>considered_execution_plans<ul><li>best_access_path</li></ul></li><li>attaching_conditions_to_tables<ul><li>attached_conditions_computation</li><li>rechecking_index_usage</li></ul></li><li>clause_processing</li><li>refine_plan<ul><li>pushed_index_condition</li><li>access_type</li></ul></li><li>reconsidering_access_paths_for_index_ordering<ul><li>plan_changed</li><li>access_type, index</li></ul></li></ul></li><li>json_execution</li></ol><p>可以看到上面default与use index两次的trace，前大半部分都是一样的，候选索引都是 <em>access_type=range, index=f_contact_time</em>，就在 <code>reconsidering_access_paths_for_index_ordering</code> 的地方，“一票否决”，从而选择了 <em>access_type=index_scan, index=some_qiye_type</em>。</p><p>搜索 reconsidering_access_paths_for_index_ordering 可以在mysql或percona的官网上，找到四五个相关的 bug report ：</p><p><a href="https://bugs.mysql.com/bug.php?id=70245" target="_blank" rel="noopener">#70245</a>，<a href="https://bugs.mysql.com/bug.php?id=78997" target="_blank" rel="noopener">#78997</a>，<a href="https://bugs.launchpad.net/percona-server/+bug/1362212" target="_blank" rel="noopener">percona#1362212</a>，<a href="https://bugs.mysql.com/bug.php?id=74602" target="_blank" rel="noopener">#74602 </a></p><p>网上提及比较多的是 #70245，调整参数 <code>eq_range_index_dive_limit</code> 可解决这个问题。我们也遇到过这个案例，见 <a href="http://imysql.com/2014/08/05/a-fake-bug-with-eq-range-index-dive-limit.shtml" target="_blank" rel="noopener">MySQL 5.6 查询优化器新特性的“BUG”</a> 。但是本文的例子满足range的个数达到18w(explain估算是36w)，也试着加大这个参数从2到800000，都没作用。</p><p><code>#74602</code> 这个说的是low_limit导致的，刚好在 optimizer_trace 里面的 <code>rechecking_index_usage:recheck_reason:low_limit</code> 。<br>测试神奇的发发现，上面的查询limit有个分解值，会选择不同的索引：<br>（<a href="https://gist.github.com/seanlook/64990b956bf986eaeece5b26055f2f18" target="_blank" rel="noopener">https://gist.github.com/seanlook/64990b956bf986eaeece5b26055f2f18</a>  limit 8168后默认选择filesort的trace）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select f_some_id from d_ec_some1.t_tbl_test_time_08</span><br><span class="line">where f_qiye_id=5077665 and f_type=9</span><br><span class="line">and f_contact_time &gt; &apos;2017-10-17 14:23:49&apos; and f_contact_time &lt; &apos;2017-10-17 14:23:53&apos;</span><br><span class="line">order by f_some_id limit 8167;</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+-------------+</span><br><span class="line">| id | select_type | table                 | type  | possible_keys  | key            | key_len | ref  | rows   | Extra       |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+-------------+</span><br><span class="line">|  1 | SIMPLE      | t_tbl_test_time_08    | index | f_contact_time | some_qiye_type | 12      | NULL | 414115 | Using where |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+-------------+</span><br><span class="line">1 row in set</span><br><span class="line"> </span><br><span class="line">mysql&gt; explain select f_some_id from d_ec_some1.t_tbl_test_time_08</span><br><span class="line">where f_qiye_id=5077665 and f_type=9</span><br><span class="line">and f_contact_time &gt; &apos;2017-10-17 14:23:49&apos; and f_contact_time &lt; &apos;2017-10-17 14:23:53&apos;</span><br><span class="line">order by f_some_id limit 8168;</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+---------------------------------------------------------------+</span><br><span class="line">| id | select_type | table                 | type  | possible_keys  | key            | key_len | ref  | rows   | Extra                                                         |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+---------------------------------------------------------------+</span><br><span class="line">|  1 | SIMPLE      | t_tbl_test_time_08    | range | f_contact_time | f_contact_time | 5       | NULL | 360478 | Using index condition; Using where; Using MRR; Using filesort |</span><br><span class="line">+----+-------------+-----------------------+-------+----------------+----------------+---------+------+--------+---------------------------------------------------------------+</span><br><span class="line">1 row in set</span><br></pre></td></tr></table></figure></p><p>具体为啥这样，bug里面没说，只是提到5.7已修复，5.6应该不会修复。</p><h1 id="5-解决办法"><a href="#5-解决办法" class="headerlink" title="5. 解决办法"></a>5. 解决办法</h1><p>其实做sql优化，执行计划不稳定这种，是不容易搞定的，因为并不是这个sql所有都会慢，而是不同值的特征，走不同的索引，会偶发性的慢。优化索引的时候，反而容易把原本较快的查询的索引改掉，造成更大的灾难。</p><p>本文的sql便是如此。从业务那边了解到，f_contact_time范围是固定4s，99%的情况，这个索引效率很高，但是正好有一大批数据(18万) f_contact_time=’2017-10-17 14:23:51’，导致优化器做出了自己以为更优的决定。</p><p>那么解决这个问题，就是要去掉干扰因素，或者提供更优的选项给它。</p><ol><li><p>去掉干扰因素<br>干扰它的索引是 some_qiye_type，是个唯一索引，因为恰好f_some_id开头，索引优化器想当然的用它来避免排序。<br>去掉这个干扰因素就是调换 f_qiye_id,f_some_id的顺序。调换顺序还有个好处，有f_qiye_id等值条件，可以用在索引检索上。<br>但是它的负面作用有两个：</p><ul><li>原本这个表上有 f_some_id 的等值、join ref以及分页查询，调换索引这两个字段顺序后，全都变成慢查询</li><li>f_qiye_id作为第一列，满足条件的值可能会有上百万，对这个查询的改观不大</li></ul></li><li><p>提供更优的索引<br>添加索引 (f_qiye_id,f_contact_time) 看起来不错。这样一来，该类查询都会走这个索引</p></li></ol><p>另外这个表上只有一个唯一索引，而且该唯一索引有字段允许null，所以没有主键。<br>加一个自增主键 f_id bigint unsigned not null<br>修改f_some_id字段为 f_some_id bigint unsigned NOT NULL<br>修改f_qiye_id字段为 f_qiye_id int unsigned NOT NULL<br>修改字段f_type字段为 tinyint NOT NULL<br>总之一句话：所有（作为索引的）字段，都定义为NOT NULL，f_some_id全部定义为bigint。最终表结构：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t_tbl_test_time_16` (</span><br><span class="line">  `f_id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `f_some_id` bigint(20) unsigned NOT NULL,</span><br><span class="line">  `f_qiye_id` int(11) unsigned NOT NULL DEFAULT &apos;0&apos;,</span><br><span class="line">  `f_type` tinyint(3) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段&apos;,</span><br><span class="line">  `f_contact_time` timestamp NOT NULL DEFAULT &apos;1970-01-01 16:00:01&apos;,</span><br><span class="line">  PRIMARY KEY(f_id),</span><br><span class="line">  UNIQUE KEY `some_qiye_type` (`f_some_id`,`f_qiye_id`,`f_type`) USING BTREE,</span><br><span class="line">  KEY `idx_qiye_time` (`f_qiye_id`,`f_contact_time`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br></pre></td></tr></table></figure><p>或者唯一索引变成联合主键（关于自增主键与联合主键的选择，参考 <a href="http://seanlook.com/2016/05/13/mysql-innodb-primary_key/">http://seanlook.com/2016/05/13/mysql-innodb-primary_key/</a> ）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t_tbl_test_time_16` (</span><br><span class="line">  `f_some_id` bigint(20) unsigned NOT NULL,</span><br><span class="line">  `f_qiye_id` int(11) unsigned NOT NULL DEFAULT &apos;0&apos;,</span><br><span class="line">  `f_type` tinyint(3) NOT NULL DEFAULT &apos;0&apos; COMMENT &apos;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段&apos;,</span><br><span class="line">  `f_contact_time` timestamp NOT NULL DEFAULT &apos;1970-01-01 16:00:01&apos;,</span><br><span class="line">  PRIMARY KEY(`f_qiye_id`,`f_some_id`,`f_type`),</span><br><span class="line">  KEY `idx_qiye_time` (`f_qiye_id`,`f_contact_time`),</span><br><span class="line">  KEY `idx_some`(`f_some_id`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br></pre></td></tr></table></figure><hr><p>原文连接地址：<a href="http://seanlook.com/2017/10/26/mysql-bad-plan-order_by-limit/">http://seanlook.com/2017/10/26/mysql-bad-plan-order_by-limit/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;生产库遇到过好几例本文要讨论的案例，而且比较棘手。简而言之，有类似这样的查询 &lt;code&gt;SELECT * FROM t1 where t1.f2&amp;gt;1 and t2.f2&amp;lt;100 order by t1.id&lt;/code&gt;，id是主键，条件里面有个range查询，就会造成优化器是选择主键，还是选择filesort问题，有些特殊情况就会选错索引，比如为了回避内存排序，选择了主键扫描，导致原本走范围过滤再sort 500ms勉强可以结束的查询，5分钟不出结果。&lt;/p&gt;
&lt;p&gt;下面具体来这个案例。&lt;/p&gt;
&lt;h1 id=&quot;1-背景&quot;&gt;&lt;a href=&quot;#1-背景&quot; class=&quot;headerlink&quot; title=&quot;1. 背景&quot;&gt;&lt;/a&gt;1. 背景&lt;/h1&gt;&lt;p&gt;阿里云RDS，5.6.16-log。&lt;br&gt;表 d_ec_someextend.t_tbl_test_time_08:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;CREATE TABLE `t_tbl_test_time_08` (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_some_id` int(11) unsigned DEFAULT &amp;apos;0&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_qiye_id` int(11) DEFAULT &amp;apos;0&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_type` tinyint(3) DEFAULT &amp;apos;0&amp;apos; COMMENT &amp;apos;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `f_contact_time` timestamp NULL DEFAULT &amp;apos;1970-01-01 16:00:01&amp;apos;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  UNIQUE KEY `some_qiye_type` (`f_some_id`,`f_qiye_id`,`f_type`),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  KEY `f_contact_time` (`f_contact_time`)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;表索引信息：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql&amp;gt; show table status like &amp;quot;t_tbl_test_time_08&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| Name                  | Engine | Version | Row_format | Rows     | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time         | Update_time | Check_time | Collation          | Checksum | Create_options | Comment | Block_format |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| t_tbl_test_time_08 | InnoDB |      10 | Compact    | 19264318 |             45 |   882900992 |               0 |   2176843776 | 752877568 | NULL           | 2017-10-25 20:27:08 | NULL        | NULL       | utf8mb4_general_ci | NULL     |                |         | Original     |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1 row in set&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;mysql&amp;gt; show index from t_tbl_test_time_08;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| Table              | Non_unique | Key_name        | Seq_in_index | Column_name    | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| t_tbl_test_time_08 |          0 | some_qiye_type  |            1 | f_some_id      | A         |    19264318 | NULL     | NULL   | YES  | BTREE      |         |               |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| t_tbl_test_time_08 |          0 | some_qiye_type  |            2 | f_qiye_id      | A         |    19264318 | NULL     | NULL   | YES  | BTREE      |         |               |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| t_tbl_test_time_08 |          0 | some_qiye_type  |            3 | f_type         | A         |    19264318 | NULL     | NULL   | YES  | BTREE      |         |               |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| t_tbl_test_time_08 |          1 | f_contact_time  |            1 | f_contact_time | A         |     9632159 | NULL     | NULL   | YES  | BTREE      |         |               |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4 rows in set&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;问题查询：&lt;/strong&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;select f_some_id from d_ec_some1.t_tbl_test_time_08&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;where f_qiye_id=5077665 and f_type=9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;and f_contact_time &amp;gt; &amp;apos;2017-10-17 14:23:49&amp;apos; and f_contact_time &amp;lt; &amp;apos;2017-10-17 14:23:53&amp;apos;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;order by f_some_id limit 300&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="优化" scheme="http://seanlook.com/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>“大”事务引起的锁等待分析案例</title>
    <link href="http://seanlook.com/2017/10/17/mysql-big-trx-lock-case/"/>
    <id>http://seanlook.com/2017/10/17/mysql-big-trx-lock-case/</id>
    <published>2017-10-17T08:32:49.000Z</published>
    <updated>2017-10-17T08:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-现象"><a href="#1-现象" class="headerlink" title="1. 现象"></a>1. 现象</h1><p>生产环境数据库在某一刻突然发现大量活跃连接，而且大部分状态是 <code>updating</code> 。问题出现在周六上午，持续了大概三四分钟，得益于我们自己的快照程序，拿到了当时现场的的processlist, 锁等待关系，innodb status 信息：(经过脱敏处理)</p><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/mysql-bigtrx-lockinfo.png" alt="mysql-bigtrx-lockinfo.png"><br><img src="http://7q5fot.com1.z0.glb.clouddn.com/mysql-bigtrx-processlist.png" alt="mysql-bigtrx-processlist.png"></p><p>innodb_status.txt片段：<br><a href="https://gist.coding.net/u/seanlook/d6ad649f81c64e23a25f3a980c44a1fe" target="_blank" rel="noopener">var_mydb_snapshot.html</a> （也可以通过 pt-stalk 收集）</p><p>首先在 Lock Waits Info 一节，看到每行的trx_id(事务)的role分为 Blocker(引起阻塞的线程) 与 Blockee（被阻塞者）；最后一列 blocking_trx_id 在role是Blockee时才有值，代表谁阻塞了当前事务。<br>根据上面的关系，可以得出以下结论：</p><ol><li>事务 <strong>19705811640</strong> 运行了231s，阻塞了19706118937、19706124453、19706124752，而这些事务都在做同一个UPDATE语句</li><li>被锁定的记录是 mydb.mytable1表的主键索引值为 5317885 行</li><li>事务 19706124752 既被阻塞，也阻塞了别人19706125253</li><li>不难发现 <strong>19705811640</strong> 应该最先运行的事务，且对其它事务产生了链式阻塞，它的thread_id是 9898630，来源IP</li></ol><p>但是当你兴冲冲的找到引起阻塞的事务 19705811640 在做什么事情时，发现它没有任何sql的信息，lock info以及processlist里面都是None。那么有哪些情况会导致在会话是活跃的，但sql的内容为空：</p><ol><li>执行show processlist的时候，刚好在事务里面两个sql的中间</li><li>sql已经执行完成，但长时间没有提交</li></ol><h1 id="2-初步分析"><a href="#2-初步分析" class="headerlink" title="2. 初步分析"></a>2. 初步分析</h1><p>其实这个现象已经遇到过很多次了，第1个原因常发生在 大量单条记录更新 的情况，一个sql在一个事务里循环执行10000次，即使每条都很快，但大部分时间都在网络传输上，（可以改成批量的形式）。在本案例基本上能确定的是第2个原因：事务开启之后，sql也执行了，但中间又做别的事情去了。那么怎样才能知道这个事务是什么内容呢？两个方向去找：</p><ol><li>从来源ip上的应用程序的日志里分析</li><li>binlog里面分析</li></ol><a id="more"></a><p>应用程序日志里可以看 10:21:00 ~ 10:26:00 之间，mydb.mytable1 表上主键id=5317885 在做什么事情。因为我们上了听云，在听云APM里面也可以清楚的看到这个时间点的哪个方法慢：<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/mysql-bigtrx-tingyun.png" alt="mysql-bigtrx-tingyun"></p><p> 响应时间230多秒，从“相关SQL”里面看到操作的记录内容，确定就是它了(根据innodb status快照时间 - ACTIVE 230.874 sec，倒推得到的时间与这里刚好吻合)。从接口名称也清楚的知道是在进行禁用用户的操作，猜想：<br>禁用用户的逻辑上有先挪到回收站，再删资料、删权限、删关系，清理缓存等等一系列操作，放在事务里保证他们的原子性，似乎是合理的。但为什么执行了将近4分钟还没有提交呢，分析相关的sql效率都很高。</p><p>有三种情况：</p><ol><li>这个事务执行到一半，它需要操作的数据被别人锁住，等待了这么久</li><li>类似事务要操作5000条数据，但是一条一条的操作，然后一起提交（已出现过类似的例子）</li><li>事务务执行完成很快，但调用其它接口迟迟没有返回，导致事务没提交。</li></ol><p>不会是1和2，因为从一开始的分析看到事务 <strong>19705811640</strong> 都是在阻塞别人，而不是受害者。那么结合上图中有个有两个操作redis的接口执行时间占比96%，可以下定论了：<br>在禁用用户时，开启了一个事务，四五个增删改很快完成，但是操作redis缓存过程比较慢，也包含在了事务代码之间，长时间没有提交。前端用户操作的时候因为迟迟没有响应，进行了多次重复点击操作，因为影响的还是同一行记录，所以只能等待前面的锁释放。</p><p>Bingo，跟最初的设想一样。但是，开发检查代码之后告诉我，没有用事务！那前面的猜想和结论都不成立了。</p><h1 id="3-论证"><a href="#3-论证" class="headerlink" title="3. 论证"></a>3. 论证</h1><p>于是走另外一个思路，分析binlog。如果binlog里面记录那条记录修改(设置禁用标志)和删除（真正删除）的时间是 10:21:58，说明数据库操作那时候就完成；如果是10:25:xx，说明最后才提交。为了弄明白这个问题，也为了搞情况事务的内容到底是什么，解析当时的binlog。（阿里云rds的数据追踪功能本来挺好用，但这一次用着报内部错误）</p><p>还记得前面那个thread_id吗，可以用在这里过滤(也可以用记录值)：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ mysqlbinlog --base64-output=decode-rows -vv --start-datetime=&quot;2017-09-16 10:21:00&quot;  --stop-datetime=&quot;2017-09-16 10:27:00&quot; mysql-bin.010743 &gt; mysql-bin.010743.sql</span><br><span class="line">$ grep -B5 -A200 &quot;thread_id=9898630&quot; mysql-bin.010743.sql &gt; mysql-bin.010743.sql.txt</span><br><span class="line"></span><br><span class="line">$ ./summarize_binlogs.sh &gt; mysql-bin.010743.sql.xid  # 会比较慢</span><br><span class="line">$ cat mysql-bin.010743.sql.xid|grep Transaction|awk &apos;&#123;if($19&gt;0)print&#125;&apos;</span><br><span class="line">[Transaction total : 10 Insert(s) : 1 Update(s) : 0 Delete(s) : 9 Xid : 99370218911 period : 190 ] </span><br><span class="line">[Transaction total : 10 Insert(s) : 1 Update(s) : 0 Delete(s) : 9 Xid : 99370268888 period : 236 ]</span><br></pre></td></tr></table></figure></p><p>上面的 summarize_binlogs.sh 脚本来源于《MySQL运维内参》，可以汇总分析binlog里面事务的执行时间。</p><p>mysql-bin.010743.sql.txt:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># at 112037144</span><br><span class="line">#170916 10:25:54 server id 1508836346  end_log_pos 112037192 CRC32 0x25216430    GTID [commit=yes]</span><br><span class="line">SET @@SESSION.GTID_NEXT= &apos;56506509-b971-11e6-8c19-6c92bf2c8aaf:10306353216&apos;/*!*/;</span><br><span class="line"># at 112037192</span><br><span class="line">#170916 10:21:58 server id 1508836346  end_log_pos 112037268 CRC32 0x9cddeec2    Query    thread_id=9898630    exec_time=0    error_code=0</span><br><span class="line">SET TIMESTAMP=1505528518/*!*/;</span><br><span class="line">SET @@session.sql_mode=2097152/*!*/;</span><br><span class="line">BEGIN</span><br><span class="line">/*!*/;</span><br><span class="line"># at 112037268</span><br><span class="line">#170916 10:21:58 server id 1508836346  end_log_pos 112037342 CRC32 0x373641db    Table_map: `mydb`.`mytable01_del` mapped to number 950163</span><br><span class="line"># at 112037342</span><br><span class="line">#170916 10:21:58 server id 1508836346  end_log_pos 112037460 CRC32 0x4bba2efb    Write_rows: table id 950163 flags: STMT_END_F</span><br><span class="line"></span><br><span class="line">BINLOG &apos;</span><br><span class="line">xoq8WRP6A+9ZSgAAAN6NrQYAAJN/DgAAAAEACWRfZWNfdXNlcgAKdF91c2VyX2RlbAAMCAgICBEB</span><br><span class="line">CAgRCA8IBAAAyAAAAdtBNjc=</span><br><span class="line">xoq8WRf6A+9ZdgAAAFSOrQYAAJN/DgAAAAEADP//APEL/VAAAAAAAP0kUQAAAAAACKpYGQQAAAAK</span><br><span class="line">/VAAAAAAAFm8isYAAAAAAAAAAAAAAAAAAAAAADojUQAAAAAADOW+kOaxn+e6oue7hOE3BAAAAAAA</span><br><span class="line">+y66Sw==</span><br><span class="line">&apos;/*!*/;</span><br><span class="line">### INSERT INTO `mydb`.`mytable01_del`</span><br><span class="line"># at 112037460</span><br><span class="line">#170916 10:21:58 server id 1508836346  end_log_pos 112037542 CRC32 0x7b55174a    Table_map: `mydb`.`mytable1` mapped to number 950159</span><br><span class="line"># at 112037542</span><br><span class="line">#170916 10:21:58 server id 1508836346  end_log_pos 112037636 CRC32 0x3bdcebf7    Delete_rows: table id 950159 flags: STMT_END_F</span><br><span class="line"></span><br><span class="line">BINLOG &apos;</span><br><span class="line">xoq8WRP6A+9ZUgAAAKaOrQYAAI9/DgAAAAEACWRfZWNfdXNlcgAOdF91c2VyX2FjY291bnQADAgC</span><br><span class="line">Dw8BARISAQMBDwiAABAAAADwADgBShdVew==</span><br><span class="line">xoq8WRn6A+9ZXgAAAASPrQYAAI9/DgAAAAEADP//APD9JFEAAAAAAAAACzE3NjA1MTEwMjgwEDc9</span><br><span class="line">OokVkE7wcJ6AvWQXyZMEAJmc6TjAmZzs458AAAAAAAAA9+vcOw==</span><br><span class="line">&apos;/*!*/;</span><br><span class="line">### DELETE FROM `mydb`.`mytable1`</span><br><span class="line">......</span><br><span class="line"># at 112038300</span><br><span class="line">#170916 10:25:54 server id 1508836346  end_log_pos 112038331 CRC32 0x01b508cf    Xid = 99370268888</span><br><span class="line">COMMIT/*!*/;</span><br></pre></td></tr></table></figure></p><p>binlog格式当中，一个事务最先记录的是GTID事件，而这个GTID的值只有在提交的时候才会生成，binlog里面的GTID时间的时间<code>10:25:54</code>就是事务提交的时间。<br>Xid在最末尾，时间也是<code>10:25:54</code>。但中间该事务的其它binlog事件，像UpdateRows/DeleteRows/InsertRows，前面的时间<code>10:21:58</code>是事务开始的时间。中间有4分钟的空档，与前面redis操作4分钟不谋而合。</p><p>这下就更加明朗了：有显式的开启事务。但开发说没有用事务，又该怎么解释呢？</p><p>不同的语言，不同的框架，使用事务的方式不一样。数据库里面开启显式事务有两种方式，一是设置 <code>set autocommit=0</code>，二是运行<code>start transaction</code>。两者都要显式调用<code>commit</code>命令提交事务。<br>为了证实程序的确用了事务，在测试环境应用服务器模拟用户的操作，然后抓包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ sudo tcpdump -s 0 -l -w - dst your_db_ipaddr and port 3306 -i eth0 &gt; mysql_3306.tcp</span><br><span class="line">$ strings mysql_3306.tcp|grep -n commit</span><br><span class="line">28:SET autocommit=0</span><br><span class="line">123:commit</span><br><span class="line">124:SET autocommit=1</span><br><span class="line">222:SET autocommit=0</span><br><span class="line">257:commit</span><br><span class="line">258:SET autocommit=1</span><br><span class="line">268:SET autocommit=0</span><br><span class="line">333:SET autocommit=1</span><br><span class="line">399:commit</span><br><span class="line">400:SET autocommit=1</span><br></pre></td></tr></table></figure></p><p>有发送 <code>set autocommit=0</code>，这下更放心了。开发再次回去检查，发现在Spring框架的时，在类上面用 <code>@Transactional</code> 的方式做了事务，而常规的做法是把注解加在类的方法上，导致忽略了这个因素。</p><h1 id="4-解决"><a href="#4-解决" class="headerlink" title="4. 解决"></a>4. 解决</h1><p>解决办法是把需要做事务控制的地方放到Services接口级别，让redis清理缓存的操作在事务之外，或者异步清理。（但也要考虑这样做会有什么负面影响）<br>另外，Redis操作慢，是否是设计上的问题。（听云监控里面显示该事务里面调用了1300次）</p><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><p>首先根据但是的现场快照，分析锁等待关系；根据以前的经验，怀疑是“大”事务中有无关的调用；根据程序日志和听云分析出对应的接口；但开发说没有事务，于是进一步通过分析binlog，经过tcp抓包，拿出证据；最后解决。</p><p>我们经常说，尽量少用大事务，但由于现在开发都是基于各种框架，使用事务的方式被封装，要理解它们的用法。其次，我们上面的事务并不大，每个sql更新都很快，但是却把其它调用也写在事务里面，就容易阻塞而长时间不提交，也许这样做的初衷是操作db与清理redis缓存放在一个事务里，要么都成功，要么都失败，但是这种分布式设计就不合理（当然有办法是可以做到，这里不展开）。</p><p>本文即是一个大事务锁的分析案例，也展示了引用各种工具，去分析论证的过程。</p><hr><p>本文链接地址：<a href="http://seanlook.com/2017/10/17/mysql-big-trx-lock-case/">http://seanlook.com/2017/10/17/mysql-big-trx-lock-case/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-现象&quot;&gt;&lt;a href=&quot;#1-现象&quot; class=&quot;headerlink&quot; title=&quot;1. 现象&quot;&gt;&lt;/a&gt;1. 现象&lt;/h1&gt;&lt;p&gt;生产环境数据库在某一刻突然发现大量活跃连接，而且大部分状态是 &lt;code&gt;updating&lt;/code&gt; 。问题出现在周六上午，持续了大概三四分钟，得益于我们自己的快照程序，拿到了当时现场的的processlist, 锁等待关系，innodb status 信息：(经过脱敏处理)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/mysql-bigtrx-lockinfo.png&quot; alt=&quot;mysql-bigtrx-lockinfo.png&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/mysql-bigtrx-processlist.png&quot; alt=&quot;mysql-bigtrx-processlist.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;innodb_status.txt片段：&lt;br&gt;&lt;a href=&quot;https://gist.coding.net/u/seanlook/d6ad649f81c64e23a25f3a980c44a1fe&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;var_mydb_snapshot.html&lt;/a&gt; （也可以通过 pt-stalk 收集）&lt;/p&gt;
&lt;p&gt;首先在 Lock Waits Info 一节，看到每行的trx_id(事务)的role分为 Blocker(引起阻塞的线程) 与 Blockee（被阻塞者）；最后一列 blocking_trx_id 在role是Blockee时才有值，代表谁阻塞了当前事务。&lt;br&gt;根据上面的关系，可以得出以下结论：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;事务 &lt;strong&gt;19705811640&lt;/strong&gt; 运行了231s，阻塞了19706118937、19706124453、19706124752，而这些事务都在做同一个UPDATE语句&lt;/li&gt;
&lt;li&gt;被锁定的记录是 mydb.mytable1表的主键索引值为 5317885 行&lt;/li&gt;
&lt;li&gt;事务 19706124752 既被阻塞，也阻塞了别人19706125253&lt;/li&gt;
&lt;li&gt;不难发现 &lt;strong&gt;19705811640&lt;/strong&gt; 应该最先运行的事务，且对其它事务产生了链式阻塞，它的thread_id是 9898630，来源IP&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;但是当你兴冲冲的找到引起阻塞的事务 19705811640 在做什么事情时，发现它没有任何sql的信息，lock info以及processlist里面都是None。那么有哪些情况会导致在会话是活跃的，但sql的内容为空：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行show processlist的时候，刚好在事务里面两个sql的中间&lt;/li&gt;
&lt;li&gt;sql已经执行完成，但长时间没有提交&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;2-初步分析&quot;&gt;&lt;a href=&quot;#2-初步分析&quot; class=&quot;headerlink&quot; title=&quot;2. 初步分析&quot;&gt;&lt;/a&gt;2. 初步分析&lt;/h1&gt;&lt;p&gt;其实这个现象已经遇到过很多次了，第1个原因常发生在 大量单条记录更新 的情况，一个sql在一个事务里循环执行10000次，即使每条都很快，但大部分时间都在网络传输上，（可以改成批量的形式）。在本案例基本上能确定的是第2个原因：事务开启之后，sql也执行了，但中间又做别的事情去了。那么怎样才能知道这个事务是什么内容呢？两个方向去找：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从来源ip上的应用程序的日志里分析&lt;/li&gt;
&lt;li&gt;binlog里面分析&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="lock" scheme="http://seanlook.com/tags/lock/"/>
    
  </entry>
  
  <entry>
    <title>table_open_cache 与 table_definition_cache 对MySQL(内存)的影响</title>
    <link href="http://seanlook.com/2017/10/13/mysql-table_open_cache_file_limits/"/>
    <id>http://seanlook.com/2017/10/13/mysql-table_open_cache_file_limits/</id>
    <published>2017-10-13T08:32:49.000Z</published>
    <updated>2017-10-13T08:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-现象，内存使用大"><a href="#1-现象，内存使用大" class="headerlink" title="1. 现象，内存使用大"></a>1. 现象，内存使用大</h1><p>首先说一下最近遇到的一个现象，因为分库的缘故，单实例里面的表的数量增加了20倍，总数将近达到10000个。在开发环境明显感觉到执行简单查询都很慢，在processlist里面看到状态 opening table 达到好几秒但数据库并没有什么负载。本能的想到应该要加大 <code>table_open_cache</code>，可是加大后发现MySQL刚启动 RES 就占用了2.5G内存，之前才500-600M的样子。</p><p>只是将 <code>table_open_cache</code> 从默认的2000，增加到10000（先不论这个值合不合理），就独占了2G的内存，这对于生产环境内存浪费是不可接受的。还好，关于这个问题的讨论有不少，感兴趣的话可以阅读 <a href="https://bugs.mysql.com/bug.php?id=68287" target="_blank" rel="noopener">#bug 68287</a>, <a href="https://bugs.mysql.com/bug.php?id=68514" target="_blank" rel="noopener">#bug 68514</a>, <a href="https://www.percona.com/forums/questions-discussions/mysql-and-percona-server/percona-server-5-6/12015-percona-5-6-14-56-very-high-memory-usage" target="_blank" rel="noopener">12015-percona-5-6-14-56-very-high-memory-usage</a>。</p><p>Oracle官方工程师并不认为这是个bug，导致初始化分配这么多内存的原因是，<strong>开启了 Performance_Schema</strong> 。P_S测量数据库的性能指标，需要提前一次性分配内存，而不是随着数据库运行逐渐申请内存。</p><p>下表是不同参数组合下内存占用的测试结果：<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/mysql_table_cache_1.png" alt=""></p><p>（注：可以通过这个来查看PFS里面哪些占内存比较多，<code>mysql -hxxxx -Pxxx -uxx -pxx -e &quot;show engine performance_schema status&quot;|grep memory|sort -nr -k3 |head</code> ）</p><p>对于 table_open_cache 设置的非常大的情况下，即使还有许多cache多余，但P_S都需要分配这个数量的内存。解决这个内存大的问题有3个方向：</p><ol><li>table_open_cache, table_definition_cache, max_connections 设置合理</li><li>关闭 performance_schema</li><li>保持 PFS 开启，关闭测量 max_table_instances和max_table_handles  <ul><li>performance_schema_max_table_instances: 最大测量多少个表对象<br>对应 (pfs_table_share).memory，我的环境里固定 277600000 bytes</li><li>performance_schema_max_table_handles: 最大打开表的总数<br>对应(pfs_table).memory，随着 table_open_cache 的增大而增大</li></ul></li></ol><p>关闭的方法是在my.cnf里面设置以上变量为 0 。默认是 -1 ，表示 autosize，即根据 table_open_cache/table_def_cache/max_connections 的值自动设置，相关代码 <code>pfs_autosize.cc</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">PFS_sizing_data *estimate_hints(PFS_global_param *param)</span><br><span class="line">&#123;</span><br><span class="line">  if ((param-&gt;m_hints.m_max_connections &lt;= MAX_CONNECTIONS_DEFAULT) &amp;&amp;</span><br><span class="line">      (param-&gt;m_hints.m_table_definition_cache &lt;= TABLE_DEF_CACHE_DEFAULT) &amp;&amp;</span><br><span class="line">      (param-&gt;m_hints.m_table_open_cache &lt;= TABLE_OPEN_CACHE_DEFAULT))</span><br><span class="line">  &#123;</span><br><span class="line">    /* The my.cnf used is either unchanged, or lower than factory defaults. */</span><br><span class="line">    return &amp; small_data;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  if ((param-&gt;m_hints.m_max_connections &lt;= MAX_CONNECTIONS_DEFAULT * 2) &amp;&amp;</span><br><span class="line">      (param-&gt;m_hints.m_table_definition_cache &lt;= TABLE_DEF_CACHE_DEFAULT * 2) &amp;&amp;</span><br><span class="line">      (param-&gt;m_hints.m_table_open_cache &lt;= TABLE_OPEN_CACHE_DEFAULT * 2))</span><br><span class="line">  &#123;</span><br><span class="line">    /* Some defaults have been increased, to &quot;moderate&quot; values. */</span><br><span class="line">    return &amp; medium_data;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  /* Looks like a server in production. */</span><br><span class="line">  return &amp; large_data;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在阿里RDS中，performance_schema_max***系列变量不能单独disable，只能全局关闭PFS。这里我们尝试寻求一个合理table_cache的范围。<br><a id="more"></a><br>那么 <code>table_open_cache</code> 与 <code>table_definition_cache</code> 设置一个什么值才算合理呢？</p><h1 id="2-理解-table-open-cache-与-table-definition-cache"><a href="#2-理解-table-open-cache-与-table-definition-cache" class="headerlink" title="2. 理解 table_open_cache 与 table_definition_cache"></a>2. 理解 table_open_cache 与 table_definition_cache</h1><p>来理解一下 <code>table_open_cache</code> 到底是来干嘛的，文档里或者网上的文章，通通解释是“用于控制MySQL Server能同时打开表的最大个数”。如果继续问这个个数怎么算呢？</p><p>我来尝试解答一下。MySQL是多线程的，多个会话上有可能会同时访问同一个表，mysql是允许这些会话各自独立的打开这个表，而表最终都是磁盘上的数据文件。(默认假设innodb_file_per_table=1)，打开文件需要获取文件描述符(File Descriptor)，为了加快这个open table的速度，MySQL在Server层设计了这个cache：</p><blockquote><p>The idea behind this cache is that most statements don’t need to go to a central table definition cache to get a TABLE object and therefore don’t need to lock LOCK_open mutex. Instead they only need to go to one Table_cache instance (the specific instance is determined by thread id) and only lock the mutex protecting this cache. DDL statements that need to remove all TABLE objects from all caches need to lock mutexes for all Table_cache instances, but they are rare.</p></blockquote><p>table_cache 减少了表级别 LOCK_open 这个互斥量的获取，改用获取 表对象缓存实例 列表的mutex。简化成如下过程：</p><ol><li>假设当前并发200个连接，table_open_cache=200，其中有50连接都在访问同一张表</li><li>mysql内部维护了一个 unused_table_list，在a表上的请求结束后，会把这个thread刚才用过的 table object 放入unused_table_list</li><li>每个表有个key，可以通过hash快速定位到表a的所有可用object，如果后面一下子100个连接上来访问表a，内部会先从 unused_table_list 去找这个表已经缓存过的对象(get_table)，比如前50个可以直接拿来用(unlink_unused_table)</li><li>后50个则需要调用系统内核，拿到文件描述符。</li><li>用完之后会，放回到unused_table_list，并将这个表的key放到hash表的前面。</li><li>如果缓存的对象个数超过了 table_open_cache，则会通过LRU算法，把认为不用的表对象逐出。</li></ol><p>从上面的过程应该很容易理解 table_open_cache 与 table_definition_cache 的区别。</p><ul><li><code>table_def_cache</code> 也是一个key/value形式的hash表，但每个表只有一个值，值/对象的内容就是表的元数据信息(Data Dictionay，frm文件里面的信息)，如表结构、字段、索引，它是一个全局的结构，并且不占用文件描述符。</li><li>而<code>table_open_cache</code>的key/value的值是一个列表，表示这个表的多个 Table_cache_element，他们共用这个表的 definition (代码层定义为TABLE_SHARE对象)。</li></ul><p>(注：我们在row格式的binlog里面看到的 table_map_id 就是在 TABLE_SHARE 里面定义的，表结构变更、缓存被逐出，都会导致 table_map_id 递增。)</p><h2 id="2-1-源码说明"><a href="#2-1-源码说明" class="headerlink" title="2.1 源码说明"></a>2.1 源码说明</h2><p>源代码里面关键函数</p><ul><li><p>sql_base.cc:</p><ul><li><code>open_table()</code> 打开表的入口<br>打开之前会判断mdl锁条件满不满足，再调用 get_table() 尝试从cache里面获取<br>如果找到，还要判断版本信息，goto table_found<br>如果没找到，注意get_table()接收了一个 table_share 参数，即使没找到table cache，也努力获取table definition，如果拿到table_share则要获取一次LOCK_open互斥量，增加表的引用计数。<br>make a new table: 调用 open_table_from_share() 从磁盘上打开表<br>调用 add_used_table() 将表对象放入缓存，table_open_cache_misses++</li><li><code>get_table_share()</code> 从 table definition cache 获取表定义信息<br>如果cache中没有，则调用 table.cc:open_table_def() 从文件系统上读取</li></ul></li><li><p>table_cache.h:Table_cache::  </p><ul><li><code>m_unused_tables</code><br>该列表内容是table cache中没有被其它线程使用的table object。最近使用过的table object会被添加到列表的尾部，头部就成为最近没被使用的(LRU)</li><li><code>m_table_count</code><br>table objects个数，包括正在使用中，以及unused<br>所有table cache instances中这个count加起来，就是 Open_tables 的结果</li><li><code>get_table()</code> 根据key(表名)从cache hash里面获取 unused table object<br>得到之后，将这个object从列表unlink掉，并且放入used table list</li><li><code>add_used_table()</code> 将新创建的 table object 放入table cache<br>这是说明当前连接要打开的表在cache里面没有，所以要自己打开，并且放入used table list</li><li><code>release_table()</code> 用完后将表对象放回table cache的unused列表<br>如果table_share版本比较旧，则直接remove掉</li><li><code>remove_table()</code>  </li><li><code>free_unused_tables_if_necessary()</code><br>每次 add_used_table() 都会调用，判断是否需要从 table cache object list清除多余的cache，需要锁定LOCK_open。调用remove_table()<br>清除条件：m_table_count &gt; table_cache_size / table_cache_instances  </li></ul></li><li><p>table.cc:</p><ul><li><code>open_table_from_share()</code><br>根据 table_share 信息来打开表。调用 outparam-&gt;file-&gt;ha_open()，<em>too many files opened</em> 错误在这里抛出</li><li><code>open_table_def()</code><br>从 frm 中读取表定义</li></ul></li></ul><p>以上过程没有考虑视图、临时表、分区表。table_cache虽然会有额外的内存开销，但简化了对表状态的维护，打开表这个动作因为省去了获取 LOCK_open mutex 以及直接操作打开数据文件，而变得高效。<br>这部分参考taobao数据库内核月报的2篇文章，会比较清晰：</p><ol><li>open file limits： <a href="http://mysql.taobao.org/monthly/2015/08/07/" target="_blank" rel="noopener">http://mysql.taobao.org/monthly/2015/08/07/</a></li><li>MySQL表定义缓存：<a href="http://mysql.taobao.org/monthly/2015/08/10/" target="_blank" rel="noopener">http://mysql.taobao.org/monthly/2015/08/10/</a></li></ol><h1 id="3-设置参考因素"><a href="#3-设置参考因素" class="headerlink" title="3 设置参考因素"></a>3 设置参考因素</h1><h2 id="3-1-table-open-cache"><a href="#3-1-table-open-cache" class="headerlink" title="3.1 table_open_cache"></a>3.1 table_open_cache</h2><p><code>table_open_cache</code> 默认值 Version&lt;=5.6.7: 400, Version&gt;=5.6.8: 2000，设定它的值有3个因素：</p><ol><li><p><strong>最大并发连接数</strong><br>这是最重要的考量。假设业务高峰期 <strong>活跃并发</strong> 连接是200，60%是单表查询，30%是两个表join，5%是三个表join，5%会创建临时表。那么table_open_cache可以是：<br>200 × (60% × 1 + 30% × 2 + 5% × 3 + 5%  × 2) = 290<br>当然这里不是要如何精确的计算，只是说明有哪些需要考虑的。网上有大部分文章都讲设置 max_connections * N，N是sql里面表的最大个数，我个人觉得如果max_connections值超过2000的话，就不要这样算，因为max_connection一般是不允许达到的，高峰期活跃并发连接数才是比较好的基准。</p></li><li><p><strong>存储引擎</strong></p><ul><li><p>MyISAM引擎<br>因为myisam数据文件和索引是分开存放的，所以<strong>第一次</strong>打开表时需要2个描述符，后续如果并发2个会话访问该表，另一个会话只需要多开一个数据文件的描述符。索引文件描述符可被线程共享。因此它所需要的 table_cache 的值并不是简单上面的值的2倍，而是跟表的访问分布有关。当然现在已经几乎不用MyISAM引擎了。<br>Merge引擎也类似，因为Merge表可以有多个底层表，需要多个文件描述符。</p></li><li><p>InnoDB引擎<br><code>table_open_cache</code>对InnoDB引擎其实作用不大，它是Server层的机制，而InnoDB不依赖server层去管理表空间，它使用自己的内部函数去打开ibd，创建handler来操作表。（handler只是内存对象，不牵涉文件操作。从实验结果看来，innodb每个表最多只有一个File Descriptor打开，myisam表如果并发访问一个表，会打开多个FD并cache起来） </p><p>注： <code>flush tables</code> 命令会关闭所有当前打开的表对象缓存/handler，所以状态变量 <code>open_tables</code> 会置0，但<code>opened_tables(_definition)</code>、<code>Table_open_cache_misses(_hits)</code>只会在实例重启后置0。对MyISAM引擎来说，它还会释放MYI/MYD文件描述符，而InnoDB引擎则不会释放ibd文件描述符。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &quot;table_%&quot;;</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">| Variable_name              | Value |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">| table_definition_cache     | 1400  |</span><br><span class="line">| table_open_cache           | 2000  |</span><br><span class="line">| table_open_cache_instances | 1     |</span><br><span class="line">+----------------------------+-------+</span><br><span class="line">3 rows in set</span><br><span class="line"></span><br><span class="line">mysql&gt; show global status like &quot;%open%&quot;;</span><br><span class="line">+----------------------------+-----------+</span><br><span class="line">| Variable_name              | Value     |</span><br><span class="line">+----------------------------+-----------+</span><br><span class="line">| Com_ha_open                | 0         |</span><br><span class="line">| Com_show_open_tables       | 0         |</span><br><span class="line">| Innodb_num_open_files      | 364       |  -- 打开的ibd文件的数量，打开后一般不会关闭，除非超过了 innodb_open_files 的设定</span><br><span class="line">| Open_files                 | 52        |  -- 打开的常规文件数量，如slow_log,error_log等，不包含socket和具体存储引擎有关的文件，所以一般都无需关注这个，它与innodb_open_files也没关系</span><br><span class="line">| Open_streams               | 0         |</span><br><span class="line">| Open_table_definitions     | 470       |  -- 当前缓存了多少.frm文件</span><br><span class="line">| Open_tables                | 448       |  -- 当前table_cache里面缓存的table object数量</span><br><span class="line">| Opened_files               | 35617170  |</span><br><span class="line">| Opened_table_definitions   | 117134    |</span><br><span class="line">| Opened_tables              | 117409    |  -- 自总MySQL启动以来打开表的总次数，如果在缓存中找到直接使用，不会增加这个值</span><br><span class="line">| Slave_open_temp_tables     | 0         |</span><br><span class="line">| Table_open_cache_hits      | 130148442 |</span><br><span class="line">| Table_open_cache_misses    | 117404    |</span><br><span class="line">| Table_open_cache_overflows | 0         |</span><br><span class="line">+----------------------------+-----------+</span><br><span class="line">14 rows in set</span><br><span class="line"></span><br><span class="line">mysql&gt; flush tables;</span><br><span class="line">Query OK, 0 rows affected</span><br><span class="line"></span><br><span class="line">mysql&gt; show global status like &quot;%open%&quot;;</span><br><span class="line">+----------------------------+-----------+</span><br><span class="line">| Variable_name              | Value     |</span><br><span class="line">+----------------------------+-----------+</span><br><span class="line">| Com_ha_open                | 0         |</span><br><span class="line">| Com_show_open_tables       | 0         |</span><br><span class="line">| Innodb_num_open_files      | 364       |</span><br><span class="line">| Open_files                 | 4         |</span><br><span class="line">| Open_streams               | 0         |</span><br><span class="line">| Open_table_definitions     | 6         |</span><br><span class="line">| Open_tables                | 6         |</span><br><span class="line">| Opened_files               | 35617220  |</span><br><span class="line">| Opened_table_definitions   | 117140    |</span><br><span class="line">| Opened_tables              | 117415    |</span><br><span class="line">| Slave_open_temp_tables     | 0         |</span><br><span class="line">| Table_open_cache_hits      | 130148523 |</span><br><span class="line">| Table_open_cache_misses    | 117410    |</span><br><span class="line">| Table_open_cache_overflows | 0         |</span><br><span class="line">+----------------------------+-----------+</span><br><span class="line">14 rows in set</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>opened_tables</strong><br>根据第一步的最大并发数设定的值不一定准确，在MySQL运行一段时间后，可以观察 opened_tables 增加的速度，决定是否需要扩大 table_open_cache。如果查询里面有许多要用到temporary table，这个值也会增加的很快，此时也可以比较 Table_open_cache_hits 与 Table_open_cache_misses 的值，正常的话 hits/(hits+misses ) 应该在99.9%以上。</p></li></ol><p>还有一个标准，<code>Open_tanles</code>的值如果与 <code>table_open_cache</code>很接近，那么也要考虑增大 table_open_cache 。</p><p>但不要设置的太大，大部分情况不要超过10000，原因一是如第一部分看到，performance_schema会分配过多内存；二是cache的查找速度会因为越来越多而变慢；三是某些情况不缓存也许更好，比如几万张表，他们都很均匀的被使用，如果不全部缓存起来，那么缓存始终会被不断的逐出更新，效率反而更低。</p><h1 id="3-2-table-definition-cache-与-innodb-open-files"><a href="#3-2-table-definition-cache-与-innodb-open-files" class="headerlink" title="3.2 table_definition_cache 与 innodb_open_files"></a>3.2 table_definition_cache 与 innodb_open_files</h1><p>至于 table_definition_cache，默认值是 <em>400 + (table_open_cache / 2)</em>，默认最大2000。如果实际表的数据量比较多，最好是能够把元数据全部cache起来，设置与表的总数量差不多大就行。</p><p>InnoDB engine层有自己参数 <code>innodb_open_files</code>，限制同时打开 ibd 文件的句柄数，作用与 table_definition_cache 相同，逐出策略也是一样采用LRU算法。innodb读取INNODB_SYS_TABLES,INNODB_SYS_COLUMNS,INNODB_SYS_FIELDS,INNODB_SYS_INDEXES等数据字典，放入 table_dict 。当需要访问这个表的时候，创建 handler 对象。<br>这两个变量本身没啥关系，但是设置不合理的时候mysql会改变它的值：</p><p>innodb_open_files的值如果设置大于 open_files_limit，且大于table_open_cache，那么会自动设置为table_def_cache大小。<code>innobase\handler\ha_innodb.cc</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">if (innobase_open_files &lt; 10) &#123;</span><br><span class="line">  innobase_open_files = 300;</span><br><span class="line">  if (srv_file_per_table &amp;&amp; table_cache_size &gt; 300) &#123;</span><br><span class="line">    innobase_open_files = table_cache_size;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if (innobase_open_files &gt; (long) open_files_limit) &#123;</span><br><span class="line">  fprintf(stderr,</span><br><span class="line">                    &quot;innodb_open_files should not be greater&quot;</span><br><span class="line">                    &quot; than the open_files_limit.\n&quot;);</span><br><span class="line">  if (innobase_open_files &gt; (long) table_cache_size) &#123;</span><br><span class="line">    innobase_open_files = table_cache_size;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><hr><p>这里顺便提一下 <code>open_file_limit</code>, 它限制的是mysqld进程总共能够打开文件描述符的个数，是个Server层的参数，它的值应该要小于服务器的最大限制，否则OS层报错会比mysql error log报错更惨。<br>关于它的计算公式，网上有很多，不属本文的内容，感兴趣可以参考 <a href="http://www.cnblogs.com/zhoujinyi/archive/2013/01/31/2883433.html" target="_blank" rel="noopener">http://www.cnblogs.com/zhoujinyi/archive/2013/01/31/2883433.html</a> </p><p>参考</p><ul><li><a href="http://hidba.org/?p=170" target="_blank" rel="noopener">http://hidba.org/?p=170</a></li><li><a href="https://dev.mysql.com/doc/refman/5.6/en/table-cache.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.6/en/table-cache.html</a></li><li><a href="http://mysql.taobao.org/monthly/2015/08/07/" target="_blank" rel="noopener">http://mysql.taobao.org/monthly/2015/08/07/</a></li><li><a href="https://dev.mysql.com/doc/dev/mysql-server/8.0.0/classTable__cache.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/dev/mysql-server/8.0.0/classTable__cache.html</a></li><li><a href="http://www.orczhou.com/index.php/2010/10/mysql-open-file-limit/" target="_blank" rel="noopener">http://www.orczhou.com/index.php/2010/10/mysql-open-file-limit/</a></li></ul><hr><p>本文链接地址：<a href="http://seanlook.com/2017/10/13/mysql-table_open_cache_file_limits/">http://seanlook.com/2017/10/13/mysql-table_open_cache_file_limits/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-现象，内存使用大&quot;&gt;&lt;a href=&quot;#1-现象，内存使用大&quot; class=&quot;headerlink&quot; title=&quot;1. 现象，内存使用大&quot;&gt;&lt;/a&gt;1. 现象，内存使用大&lt;/h1&gt;&lt;p&gt;首先说一下最近遇到的一个现象，因为分库的缘故，单实例里面的表的数量增加了20倍，总数将近达到10000个。在开发环境明显感觉到执行简单查询都很慢，在processlist里面看到状态 opening table 达到好几秒但数据库并没有什么负载。本能的想到应该要加大 &lt;code&gt;table_open_cache&lt;/code&gt;，可是加大后发现MySQL刚启动 RES 就占用了2.5G内存，之前才500-600M的样子。&lt;/p&gt;
&lt;p&gt;只是将 &lt;code&gt;table_open_cache&lt;/code&gt; 从默认的2000，增加到10000（先不论这个值合不合理），就独占了2G的内存，这对于生产环境内存浪费是不可接受的。还好，关于这个问题的讨论有不少，感兴趣的话可以阅读 &lt;a href=&quot;https://bugs.mysql.com/bug.php?id=68287&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;#bug 68287&lt;/a&gt;, &lt;a href=&quot;https://bugs.mysql.com/bug.php?id=68514&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;#bug 68514&lt;/a&gt;, &lt;a href=&quot;https://www.percona.com/forums/questions-discussions/mysql-and-percona-server/percona-server-5-6/12015-percona-5-6-14-56-very-high-memory-usage&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;12015-percona-5-6-14-56-very-high-memory-usage&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Oracle官方工程师并不认为这是个bug，导致初始化分配这么多内存的原因是，&lt;strong&gt;开启了 Performance_Schema&lt;/strong&gt; 。P_S测量数据库的性能指标，需要提前一次性分配内存，而不是随着数据库运行逐渐申请内存。&lt;/p&gt;
&lt;p&gt;下表是不同参数组合下内存占用的测试结果：&lt;br&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/mysql_table_cache_1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;（注：可以通过这个来查看PFS里面哪些占内存比较多，&lt;code&gt;mysql -hxxxx -Pxxx -uxx -pxx -e &amp;quot;show engine performance_schema status&amp;quot;|grep memory|sort -nr -k3 |head&lt;/code&gt; ）&lt;/p&gt;
&lt;p&gt;对于 table_open_cache 设置的非常大的情况下，即使还有许多cache多余，但P_S都需要分配这个数量的内存。解决这个内存大的问题有3个方向：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;table_open_cache, table_definition_cache, max_connections 设置合理&lt;/li&gt;
&lt;li&gt;关闭 performance_schema&lt;/li&gt;
&lt;li&gt;保持 PFS 开启，关闭测量 max_table_instances和max_table_handles  &lt;ul&gt;
&lt;li&gt;performance_schema_max_table_instances: 最大测量多少个表对象&lt;br&gt;对应 (pfs_table_share).memory，我的环境里固定 277600000 bytes&lt;/li&gt;
&lt;li&gt;performance_schema_max_table_handles: 最大打开表的总数&lt;br&gt;对应(pfs_table).memory，随着 table_open_cache 的增大而增大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;关闭的方法是在my.cnf里面设置以上变量为 0 。默认是 -1 ，表示 autosize，即根据 table_open_cache/table_def_cache/max_connections 的值自动设置，相关代码 &lt;code&gt;pfs_autosize.cc&lt;/code&gt;：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;PFS_sizing_data *estimate_hints(PFS_global_param *param)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  if ((param-&amp;gt;m_hints.m_max_connections &amp;lt;= MAX_CONNECTIONS_DEFAULT) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      (param-&amp;gt;m_hints.m_table_definition_cache &amp;lt;= TABLE_DEF_CACHE_DEFAULT) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      (param-&amp;gt;m_hints.m_table_open_cache &amp;lt;= TABLE_OPEN_CACHE_DEFAULT))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    /* The my.cnf used is either unchanged, or lower than factory defaults. */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return &amp;amp; small_data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  if ((param-&amp;gt;m_hints.m_max_connections &amp;lt;= MAX_CONNECTIONS_DEFAULT * 2) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      (param-&amp;gt;m_hints.m_table_definition_cache &amp;lt;= TABLE_DEF_CACHE_DEFAULT * 2) &amp;amp;&amp;amp;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      (param-&amp;gt;m_hints.m_table_open_cache &amp;lt;= TABLE_OPEN_CACHE_DEFAULT * 2))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    /* Some defaults have been increased, to &amp;quot;moderate&amp;quot; values. */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    return &amp;amp; medium_data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  /* Looks like a server in production. */&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  return &amp;amp; large_data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;在阿里RDS中，performance_schema_max***系列变量不能单独disable，只能全局关闭PFS。这里我们尝试寻求一个合理table_cache的范围。&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="table_cache" scheme="http://seanlook.com/tags/table-cache/"/>
    
  </entry>
  
  <entry>
    <title>MySQL实例阻塞分析一例(线程statistics状态)</title>
    <link href="http://seanlook.com/2017/09/23/rds_disk_io_troubleshooting/"/>
    <id>http://seanlook.com/2017/09/23/rds_disk_io_troubleshooting/</id>
    <published>2017-09-23T08:32:49.000Z</published>
    <updated>2017-09-23T08:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-现象"><a href="#1-现象" class="headerlink" title="1. 现象"></a>1. 现象</h1><p>某日下午下班后低峰期，现网MySQL一个库突然报出大量慢sql，状态是 <code>statistics</code>，但是过后拿这些sql去执行的时候，实际很快。处于 statistics 状态的线程有个特征：查询的都是视图，但看监控那个时间段并没有明显的update/detele/insert。通过我们的快照程序，去分析当时的 innodb status，发现如下信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">SEMAPHORES</span><br><span class="line">----------</span><br><span class="line">OS WAIT ARRAY INFO: reservation count 17208994</span><br><span class="line">--Thread 139964610234112 has waited at srv0srv.cc line 2132 for 14.00 seconds the semaphore:</span><br><span class="line">X-lock (wait_ex) on RW-latch at 0x1635a00 created in file dict0dict.cc line 900</span><br><span class="line">a writer (thread id 139964610234112) has reserved it in mode wait exclusive</span><br><span class="line">number of readers 1, waiters flag 0, lock_word: ffffffffffffffff</span><br><span class="line">Last time read locked in file row0purge.cc line 720</span><br><span class="line">Last time write locked in file /home/admin/146_20161018140650857_13830810_code/rpm_workspace/storage/innobase/srv/srv0srv.cc line 2132</span><br><span class="line">OS WAIT ARRAY INFO: signal count 256984450</span><br><span class="line">Mutex spin waits 626367674, rounds 2776951802, OS waits 1973672</span><br><span class="line">RW-shared spins 149944457, rounds 1650148561, OS waits 3972058</span><br><span class="line">RW-excl spins 72090467, rounds 2017802579, OS waits 11148264</span><br><span class="line">Spin rounds per wait: 4.43 mutex, 11.01 RW-shared, 27.99 RW-excl</span><br><span class="line">...</span><br><span class="line">FILE I/O</span><br><span class="line">--------</span><br><span class="line">I/O thread 0 state: waiting for i/o request (insert buffer thread)</span><br><span class="line">I/O thread 1 state: waiting for i/o request (log thread)</span><br><span class="line">I/O thread 2 state: waiting for i/o request (read thread)</span><br><span class="line">I/O thread 3 state: doing file i/o (read thread) ev set</span><br><span class="line">I/O thread 4 state: waiting for i/o request (read thread)</span><br><span class="line">I/O thread 5 state: doing file i/o (read thread) ev set</span><br><span class="line">I/O thread 6 state: doing file i/o (write thread) ev set</span><br><span class="line">I/O thread 7 state: waiting for i/o request (write thread)</span><br><span class="line">I/O thread 8 state: waiting for i/o request (write thread)</span><br><span class="line">I/O thread 9 state: waiting for i/o request (write thread)</span><br><span class="line">Pending normal aio reads: 18 [0, 12, 0, 6] , aio writes: 1 [1, 0, 0, 0] ,</span><br><span class="line">ibuf aio reads: 0, log i/o&apos;s: 0, sync i/o&apos;s: 0</span><br><span class="line">Pending flushes (fsync) log: 0; buffer pool: 0</span><br><span class="line">1346747614 OS file reads, 2869418806 OS file writes, 524616747 OS fsyncs</span><br><span class="line">22 pending preads, 1 pending pwrites</span><br><span class="line">6.00 reads/s, 16384 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s</span><br><span class="line">...</span><br><span class="line">ROW OPERATIONS</span><br><span class="line">--------------</span><br><span class="line">0 queries inside InnoDB, 0 queries in queue</span><br><span class="line">38 read views open inside InnoDB</span><br><span class="line">Main thread process no. 34414, id 139964610234112, state: enforcing dict cache limit</span><br><span class="line">Number of rows inserted 2546811699, updated 1708150459, deleted 1004154696, read 413168628410</span><br><span class="line">0.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 54.19 reads/s</span><br></pre></td></tr></table></figure></p><h1 id="2-分析"><a href="#2-分析" class="headerlink" title="2. 分析"></a>2. 分析</h1><p>从上面的信息知道 Thread 139964610234112 是主线程，在源码 srv0srv.cc:2132 行的地方等待信号14s，这个信号是在 dict0dict.cc:900 地方创建的 RW-latch 排它锁。那么奇怪了，主线程自己在等待自己的互斥锁。<br>由于环境是阿里云的RDS(基于MySQL 5.6.16-log 版本)，拿不到他们的代码，找来 5.6.35 的来看，行号对不上。但好在上段信息的最后面有一个 Main thread state: <code>enforcing dict cache limit</code>，发现在 srv0srv.cc 函数 srv_master_do_active_tasks() 约2137行的位置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if (cur_time % SRV_MASTER_DICT_LRU_INTERVAL == 0) &#123;</span><br><span class="line">4srv_main_thread_op_info = &quot;enforcing dict cache limit&quot;;</span><br><span class="line">4srv_master_evict_from_table_cache(50);</span><br><span class="line">4MONITOR_INC_TIME_IN_MICRO_SECS(</span><br><span class="line">44MONITOR_SRV_DICT_LRU_MICROSECOND, counter_time);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><a id="more"></a><p>应该是在调用 srv_master_evict_from_table_cache() 从innodb table cache里面清理缓存的地方waiting（这里不是一定会清理，而是先判断空间够不够用，参数50表示只扫描 unused_table list的50%）。<br><code>srv_master_evict_from_table_cache()</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">srv_master_evict_from_table_cache(</span><br><span class="line">/*==============================*/</span><br><span class="line">4ulintpct_check)/*!&lt; in: max percent to check */</span><br><span class="line">&#123;</span><br><span class="line">4ulintn_tables_evicted = 0;</span><br><span class="line"></span><br><span class="line">4rw_lock_x_lock(&amp;dict_operation_lock);</span><br><span class="line"></span><br><span class="line">4dict_mutex_enter_for_mysql();</span><br><span class="line"></span><br><span class="line">4n_tables_evicted = dict_make_room_in_cache(  /** 在dict0dict.cc里面 **/</span><br><span class="line">44innobase_get_table_cache_size(), pct_check);</span><br><span class="line"></span><br><span class="line">4dict_mutex_exit_for_mysql();</span><br><span class="line"></span><br><span class="line">4rw_lock_x_unlock(&amp;dict_operation_lock);</span><br><span class="line"></span><br><span class="line">4return(n_tables_evicted);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是在 <em>rw_lock_x_lock(&amp;dict_operation_lock)</em> 这个地方获取Latch的时候等待了14s，这个锁就是在数据字典模块 dict0dict.cc:dict_init() 约1065行的地方创建的，与innodb status输出基本一致。<br>关于 <code>dict_operation_lock</code> 直接看注释吧：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/** @brief the data dictionary rw-latch protecting dict_sys</span><br><span class="line"></span><br><span class="line">table create, drop, etc. reserve this in X-mode; implicit or</span><br><span class="line">backround operations purge, rollback, foreign key checks reserve this</span><br><span class="line">in S-mode; we cannot trust that MySQL protects implicit or background</span><br><span class="line">operations a table drop since MySQL does not know of them; therefore</span><br><span class="line">we need this; NOTE: a transaction which reserves this must keep book</span><br><span class="line">on the mode in trx_t::dict_operation_lock_mode */</span><br></pre></td></tr></table></figure></p><p>在尝试把表定义逐出缓存时获取的是 dict_operation_lock X-mode lock，可是从已有的信息里看不到另一个数据字典锁是什么。<br>之前是怀疑是不是 table_definition_cache, table_open_cache, innodb_open_files 设置小了，视图一般是多表join，更容易消耗打开表的数量，导致不断的逐出cache而导致锁征用。但是检查一番并没发现什么问题，更何况是14s的等待。关于它们的设置和关系，可以参考我的文章 <a href="http://seanlook.com/2017/10/13/mysql-table_open_cache_file_limits">table_open_cache 与 table_definition_cache 对MySQL的影响</a> 。</p><p>那么得换个思路了，processlist里面有13个长时间处于 statistics 状态的线程，表示正在计算统计数据，以制定一个查询执行计划。 如果一个线程处于这种状态很长一段时间，可能是磁盘IO性能很差，或者磁盘在执行其他工作。</p><p>此时注意到最上面的信息里有 <em>Pending normal aio reads: 18 [0, 12, 0, 6]</em> ，有18个读IO被挂起(实际从监控图 innodb_data_pending_reads看来，有达到过50)，四个read thread有三个处于忙碌状态。再有 innodb_buffer_pool_pages_flushed 在出异常前10s没有任何变化，也就是没有成功的将脏数据刷盘动作。另外这是一个从库，出异常前10s有出现过瞬间20多秒延迟：<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rds_diskio_slave_lag.png" alt=""><br><img src="http://7q5fot.com1.z0.glb.clouddn.com/rds_diskio_bufferpool_flushed.png" alt=""></p><p>(这一切关注的都是 18:59:05 之前的数据，之后的时间，一般恢复了都会有瞬间的读行数上涨，这个时候别把它们反当做起因)</p><h1 id="3-结论"><a href="#3-结论" class="headerlink" title="3. 结论"></a>3. 结论</h1><p>结合上面的 enforcing dict cache limit 和 statistics IO pending，找到两个有关的bug report:</p><ul><li><a href="https://bugs.launchpad.net/percona-server/+bug/1500176" target="_blank" rel="noopener">https://bugs.launchpad.net/percona-server/+bug/1500176</a></li><li><a href="https://bugs.mysql.com/bug.php?id=84424" target="_blank" rel="noopener">https://bugs.mysql.com/bug.php?id=84424</a></li></ul><p>第一个是使用 pt-online-schema-change 去更改分区表的结构，可能会出现，但目前bug状态是Undecided，我们的环境没有分区表，没外键，也没有改表动作。<br>第二个其实 Not a bug：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Thank you for your bug report. This is, however, not a bug, but a very well known issue.</span><br><span class="line"></span><br><span class="line">You have to do several things in order to alleviate the problem:</span><br><span class="line"></span><br><span class="line">* increase the additional memory pool</span><br><span class="line">（注：这里我认为不应该是additional memory pool，而是 buffer_pool，因为现在innodb内存管理基本是调用系统malloc，即innodb_use_sys_malloc=ON，参考https://dev.mysql.com/doc/refman/5.7/en/innodb-performance-use_sys_malloc.html）</span><br><span class="line">* increase total number of file handles available to MySQL</span><br><span class="line">* increase number of file handles for InnoDB</span><br><span class="line">* improve performance of the I/O on your operating system</span><br></pre></td></tr></table></figure></p><p>说到底就是数据库服务器IO遇到问题了，可以通过增加 buffer_pool 来缓存更多的数据，或者提高服务器IO能力，这个范围就广了： <a href="https://dev.mysql.com/doc/refman/5.6/en/optimizing-innodb-diskio.html" target="_blank" rel="noopener">https://dev.mysql.com/doc/refman/5.6/en/optimizing-innodb-diskio.html</a> 。<br>然而生产服务器都运行了1年之久，高峰期都没出现过IO问题，现在何况低峰期，也没有人为操作。那这个锅只能交给阿里RDS了：怀疑是实例所在物理机磁盘有抖动。</p><p>分析这么久得出这个结论，却不能做什么，因为我们没办法看到服务器级别的IO stats。其实想到去年也有实例出现过几例类似 statistics 问题，向阿里云提工单确认物理机状态，得到的结论都是：“是的，物理机有抖动。需要申请迁移实例吗”，但是从来拿不到依据。如果自己能看到OS级别的监控，其实都不需要本文这么冗长的分析。</p><p><strong>参考</strong></p><ul><li><a href="https://dba.stackexchange.com/questions/55969/statistics-state-in-mysql-processlist" target="_blank" rel="noopener">https://dba.stackexchange.com/questions/55969/statistics-state-in-mysql-processlist</a></li><li><a href="http://mysqlinternals.blogspot.com/2015/05/list-of-background-operations-performed.html" target="_blank" rel="noopener">http://mysqlinternals.blogspot.com/2015/05/list-of-background-operations-performed.html</a></li><li><a href="http://imysql.com/2015/06/10/mysql-faq-processlist-thread-states.shtml" target="_blank" rel="noopener">http://imysql.com/2015/06/10/mysql-faq-processlist-thread-states.shtml</a></li><li><a href="http://imysql.com/2016/11/20/mysql-faq-what-cause-diskio-so-high.shtml" target="_blank" rel="noopener">http://imysql.com/2016/11/20/mysql-faq-what-cause-diskio-so-high.shtml</a></li></ul><hr><p>本文链接地址：<a href="http://seanlook.com/2017/09/23/rds_disk_io_troubleshooting/">http://seanlook.com/2017/09/23/rds_disk_io_troubleshooting/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-现象&quot;&gt;&lt;a href=&quot;#1-现象&quot; class=&quot;headerlink&quot; title=&quot;1. 现象&quot;&gt;&lt;/a&gt;1. 现象&lt;/h1&gt;&lt;p&gt;某日下午下班后低峰期，现网MySQL一个库突然报出大量慢sql，状态是 &lt;code&gt;statistics&lt;/code&gt;，但是过后拿这些sql去执行的时候，实际很快。处于 statistics 状态的线程有个特征：查询的都是视图，但看监控那个时间段并没有明显的update/detele/insert。通过我们的快照程序，去分析当时的 innodb status，发现如下信息：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;SEMAPHORES&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;----------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;OS WAIT ARRAY INFO: reservation count 17208994&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;--Thread 139964610234112 has waited at srv0srv.cc line 2132 for 14.00 seconds the semaphore:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;X-lock (wait_ex) on RW-latch at 0x1635a00 created in file dict0dict.cc line 900&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;a writer (thread id 139964610234112) has reserved it in mode wait exclusive&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;number of readers 1, waiters flag 0, lock_word: ffffffffffffffff&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Last time read locked in file row0purge.cc line 720&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Last time write locked in file /home/admin/146_20161018140650857_13830810_code/rpm_workspace/storage/innobase/srv/srv0srv.cc line 2132&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;OS WAIT ARRAY INFO: signal count 256984450&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Mutex spin waits 626367674, rounds 2776951802, OS waits 1973672&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RW-shared spins 149944457, rounds 1650148561, OS waits 3972058&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;RW-excl spins 72090467, rounds 2017802579, OS waits 11148264&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Spin rounds per wait: 4.43 mutex, 11.01 RW-shared, 27.99 RW-excl&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;FILE I/O&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;--------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 0 state: waiting for i/o request (insert buffer thread)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 1 state: waiting for i/o request (log thread)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 2 state: waiting for i/o request (read thread)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 3 state: doing file i/o (read thread) ev set&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 4 state: waiting for i/o request (read thread)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 5 state: doing file i/o (read thread) ev set&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 6 state: doing file i/o (write thread) ev set&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 7 state: waiting for i/o request (write thread)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 8 state: waiting for i/o request (write thread)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;I/O thread 9 state: waiting for i/o request (write thread)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Pending normal aio reads: 18 [0, 12, 0, 6] , aio writes: 1 [1, 0, 0, 0] ,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ibuf aio reads: 0, log i/o&amp;apos;s: 0, sync i/o&amp;apos;s: 0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Pending flushes (fsync) log: 0; buffer pool: 0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;1346747614 OS file reads, 2869418806 OS file writes, 524616747 OS fsyncs&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22 pending preads, 1 pending pwrites&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6.00 reads/s, 16384 avg bytes/read, 0.00 writes/s, 0.00 fsyncs/s&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;ROW OPERATIONS&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;--------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0 queries inside InnoDB, 0 queries in queue&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38 read views open inside InnoDB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Main thread process no. 34414, id 139964610234112, state: enforcing dict cache limit&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Number of rows inserted 2546811699, updated 1708150459, deleted 1004154696, read 413168628410&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;0.00 inserts/s, 0.00 updates/s, 0.00 deletes/s, 54.19 reads/s&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;2-分析&quot;&gt;&lt;a href=&quot;#2-分析&quot; class=&quot;headerlink&quot; title=&quot;2. 分析&quot;&gt;&lt;/a&gt;2. 分析&lt;/h1&gt;&lt;p&gt;从上面的信息知道 Thread 139964610234112 是主线程，在源码 srv0srv.cc:2132 行的地方等待信号14s，这个信号是在 dict0dict.cc:900 地方创建的 RW-latch 排它锁。那么奇怪了，主线程自己在等待自己的互斥锁。&lt;br&gt;由于环境是阿里云的RDS(基于MySQL 5.6.16-log 版本)，拿不到他们的代码，找来 5.6.35 的来看，行号对不上。但好在上段信息的最后面有一个 Main thread state: &lt;code&gt;enforcing dict cache limit&lt;/code&gt;，发现在 srv0srv.cc 函数 srv_master_do_active_tasks() 约2137行的位置：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;if (cur_time % SRV_MASTER_DICT_LRU_INTERVAL == 0) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4srv_main_thread_op_info = &amp;quot;enforcing dict cache limit&amp;quot;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4srv_master_evict_from_table_cache(50);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4MONITOR_INC_TIME_IN_MICRO_SECS(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44MONITOR_SRV_DICT_LRU_MICROSECOND, counter_time);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="table_cache" scheme="http://seanlook.com/tags/table-cache/"/>
    
  </entry>
  
  <entry>
    <title>一个简单的数据订阅程序(for DBA)</title>
    <link href="http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/"/>
    <id>http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/</id>
    <published>2017-09-05T08:32:49.000Z</published>
    <updated>2017-09-05T08:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>本程序基于大众点评github项目 <a href="https://github.com/danfengcao/binlog2sql" target="_blank" rel="noopener">binlog2sql</a> 二次开发而来，可以实现对源库的binlog实时接收，并组装成增量sql。</p><p>原项目默认是把sql输出到控制台，二次开发后的版本把sql放入redis队列，根据需要由另一个程序消费到目标库，模拟了一个“从库”。<br>在测试时<code>--stop-never</code>在qa环境没有作用，添加了在 BinLogStreamReader 实例里面加入 <code>blocking=True</code> 来保证源源不断的接受binlog而不中断。</p><p>另外也加入了更改目标库名的功能，比如原库叫d_my1，生成的sql目标库名是 d_my2 。</p><p>项目地址：<a href="https://github.com/seanlook/binlog2sql" target="_blank" rel="noopener">https://github.com/seanlook/binlog2sql</a></p><h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>目前想到以下应用场景：</p><ul><li><p>实时同步部分表到另外一个数据库实例<br>比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。<br>另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。</p></li><li><p>正式切库时的回滚措施<br>比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。</p></li><li><p>数据库闪回<br>关于数据库误操作的闪回方案，见 <a href="http://seanlook.com/2017/03/03/mysql-flashback_use_purged-binlog/">文章MySQL根据离线binlog快速闪回</a> 。<code>binlog2sql</code>的 <code>-B</code> 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。</p></li><li><p>binlog搜索功能<br>目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。</p></li></ul><a id="more"></a><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><p>安装好python2.7虚拟环境，安装必要模块：pymysql, mysql-replication, redis, rq<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure></p><p>注意：<code>pymysqlreplication</code> 库在处理 ‘0000-00-00 00:00:00’ 时有些不尽人意，可能会导致生产的sql在目标库执行失败，还有对<code>datetime(6)</code>类型有个bug，也对它进行了修复，地址：<a href="https://github.com/seanlook/python-mysql-replication" target="_blank" rel="noopener">https://github.com/seanlook/python-mysql-replication</a> 。</p><p>准备一个redis用于存放sql队列，在环境变量里面设置redis地址<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export REDIS_URL=&apos;redis://localhost:6379&apos;</span><br></pre></td></tr></table></figure></p><p>在主库执行 <code>show master status</code> 得到binlog开始的文件名和postion，然后开始订阅：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">binlog2sql原版使用时：</span><br><span class="line">$ ~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/python binlog2sql.py -h192.168.1.185 -P3306 -uecuser -pecuser \</span><br><span class="line">-d d_ec_contact --tables t_crm_contact_at \</span><br><span class="line">--start-file=&apos;mysql-bin.000001&apos; --start-datetime=&apos;2017-08-30 12:30:00&apos; --start-position=6529058 \</span><br><span class="line">--stop-never &gt; contact0.sql</span><br><span class="line"></span><br><span class="line">加入订阅功能后：</span><br><span class="line">$ ~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/python binlog2sql.py -h192.168.1.185 -P3306 -uecuser -pecuser \</span><br><span class="line">-d d_ec_contact:d_ec_crm --tables t_crm_contact_at t_crm_remark_today \</span><br><span class="line">--start-file=&apos;mysql-bin.000001&apos; --start-datetime=&apos;2017-08-30 12:30:00&apos; --start-position=6529058 \</span><br><span class="line">--dest-dsn h=10.0.200.195,P=3307,u=ecuser,p=ecuser</span><br><span class="line">--stop-never &gt; contact0.sql</span><br></pre></td></tr></table></figure></p><p><code>-d d_ec_contact:d_ec_crm</code> 表上生成目标sql映射关系，如果不改变库名，就不需要 <code>:</code> 指定，与原版兼容。<br><code>--dest-dsn</code>: 表示目标库的地址和认证信息。</p><p>这时在redis里面可以看到sql信息。如果需要在目标库重放，则启动消费程序：（在代码目录下面）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/rq worker</span><br></pre></td></tr></table></figure></p><p>待数据追上之后，可以看到几乎是实时同步的。</p><hr><p>本文链接地址：<a href="http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/">http://seanlook.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本程序基于大众点评github项目 &lt;a href=&quot;https://github.com/danfengcao/binlog2sql&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;binlog2sql&lt;/a&gt; 二次开发而来，可以实现对源库的binlog实时接收，并组装成增量sql。&lt;/p&gt;
&lt;p&gt;原项目默认是把sql输出到控制台，二次开发后的版本把sql放入redis队列，根据需要由另一个程序消费到目标库，模拟了一个“从库”。&lt;br&gt;在测试时&lt;code&gt;--stop-never&lt;/code&gt;在qa环境没有作用，添加了在 BinLogStreamReader 实例里面加入 &lt;code&gt;blocking=True&lt;/code&gt; 来保证源源不断的接受binlog而不中断。&lt;/p&gt;
&lt;p&gt;另外也加入了更改目标库名的功能，比如原库叫d_my1，生成的sql目标库名是 d_my2 。&lt;/p&gt;
&lt;p&gt;项目地址：&lt;a href=&quot;https://github.com/seanlook/binlog2sql&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/seanlook/binlog2sql&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;headerlink&quot; title=&quot;应用场景&quot;&gt;&lt;/a&gt;应用场景&lt;/h1&gt;&lt;p&gt;目前想到以下应用场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;实时同步部分表到另外一个数据库实例&lt;br&gt;比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。&lt;br&gt;另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;正式切库时的回滚措施&lt;br&gt;比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;数据库闪回&lt;br&gt;关于数据库误操作的闪回方案，见 &lt;a href=&quot;http://seanlook.com/2017/03/03/mysql-flashback_use_purged-binlog/&quot;&gt;文章MySQL根据离线binlog快速闪回&lt;/a&gt; 。&lt;code&gt;binlog2sql&lt;/code&gt;的 &lt;code&gt;-B&lt;/code&gt; 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;binlog搜索功能&lt;br&gt;目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="table_cache" scheme="http://seanlook.com/tags/table-cache/"/>
    
  </entry>
  
  <entry>
    <title>网易云跟帖迁移评论到disqus</title>
    <link href="http://seanlook.com/2017/08/29/blog_migrate_gentie163_disqus/"/>
    <id>http://seanlook.com/2017/08/29/blog_migrate_gentie163_disqus/</id>
    <published>2017-08-29T08:32:49.000Z</published>
    <updated>2017-08-29T08:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>早前折腾博客的时候，在众多评论系统中选择了多说，用了2年结果多说倒闭了，也算是影响了网络上众多的站点。</p><p>于是在16年的时候把评论换成了网易云跟帖，以为有网易这个靠山，体验虽然差点但是不会轻易关闭。云跟帖还提供了从多说直接导入的工具，随意旧的评论直接弄过来了。</p><p>可谁想不到一年，网易云跟帖也关闭了。</p><p>现在不怎么去折腾博客这玩意了，往里面写写东西才是王道，所以就决定直接把评论系统换成国外的 disqus，总不至于国内种种原因关闭了，代价就是要懂得科学上网，考虑博客的受众都是IT同仁，也就只好这样了。</p><p>然而被坑了，网上有许多文章和工具可以<a href="https://github.com/JamesPan/duoshuo-migrator/blob/master/duoshuo-migrator.py" target="_blank" rel="noopener">从多说迁移到disqus</a>，但是几乎没看到从网易云跟帖迁移到disqus，三者导出的评论格式不一样。云跟帖导出的是 json，disqus导入是扩展的Wordpress格式。</p><p>在拖了3个月后，找到了从网易云跟帖备份出来的旧评论文件，简单用python转换了一下，现在可以用了。</p><p>WXR格式：<a href="https://help.disqus.com/customer/portal/articles/472150-custom-xml-import-format" target="_blank" rel="noopener">https://help.disqus.com/customer/portal/articles/472150-custom-xml-import-format</a></p><p><strong>转换代码gist地址</strong>：<a href="https://gist.coding.net/u/seanlook/c395cda7c5f4421b85efcd898a8fdf21" target="_blank" rel="noopener">https://gist.coding.net/u/seanlook/c395cda7c5f4421b85efcd898a8fdf21</a>  (comments_convert.py)</p><p>云跟帖导出文件命名为 gentie163.py，懒得用python处理，直接修改这个文件的内容为 python 字典定义：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sed -i &apos;s/&quot;url&quot;:&quot;seanlook.com/&quot;url&quot;:&quot;http:\/\/seanlook.com/g&apos; gentie163.py</span><br><span class="line">sed -i &apos;s/false/False/g&apos; gentie163.py</span><br><span class="line">sed -i &apos;s/:null/:&quot;&quot;/g&apos; gentie163.py</span><br><span class="line">sed -i &apos;s/^/comments = /&apos; gentie163.py</span><br></pre></td></tr></table></figure></p><p>字典直接转xml比较容易：<a href="http://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p05_turning_dictionary_into_xml.html#" target="_blank" rel="noopener">http://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p05_turning_dictionary_into_xml.html#</a></p><p>转换后的文件为 <code>data_output.xml</code>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># python3 comments_convert.py</span><br></pre></td></tr></table></figure></p><p>在这个页面导入：<a href="https://seanlook.disqus.com/admin/discussions/import/platform/generic/" target="_blank" rel="noopener">https://seanlook.disqus.com/admin/discussions/import/platform/generic/</a></p><p>可在页面 <a href="https://import.disqus.com/" target="_blank" rel="noopener">https://import.disqus.com/</a> 看到import进度，包括失败信息。（不要重复导入）</p><p>说明：</p><ul><li>disqus每篇文章有个thread_idendifier，这里处理直接根据文章的时间戳转换来用，不影响</li><li>dsq:remote是设置单点登录，没去深究，直接丢弃这个属性了</li><li>头像信息丢失(因为sso)</li></ul><hr><p>本文链接地址：<a href="http://seanlook.com/2017/08/29/blog_migrate_gentie163_disqus/">http://seanlook.com/2017/08/29/blog_migrate_gentie163_disqus/</a></p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;早前折腾博客的时候，在众多评论系统中选择了多说，用了2年结果多说倒闭了，也算是影响了网络上众多的站点。&lt;/p&gt;
&lt;p&gt;于是在16年的时候把评论换成了网易云跟帖，以为有网易这个靠山，体验虽然差点但是不会轻易关闭。云跟帖还提供了从多说直接导入的工具，随意旧的评论直接弄过来了。&lt;
      
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="blog" scheme="http://seanlook.com/tags/blog/"/>
    
  </entry>
  
  <entry>
    <title>MySQL数据库表结构同步之mysqldiff</title>
    <link href="http://seanlook.com/2017/08/05/mysql_mysqldiff/"/>
    <id>http://seanlook.com/2017/08/05/mysql_mysqldiff/</id>
    <published>2017-08-05T07:32:49.000Z</published>
    <updated>2017-08-05T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mysqldiff"><a href="#mysqldiff" class="headerlink" title="mysqldiff"></a>mysqldiff</h1><p>mysql官方有个 <a href="https://dev.mysql.com/doc/mysql-utilities/1.6/en/mysql-utils-install-rpm.html" target="_blank" rel="noopener">mysql-utilities 工具集</a>，其中 mysqldiff 可用于比较两个db之间的表结构。<br>mysqldiff的语法格式是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4</span><br></pre></td></tr></table></figure></p><p>这个语法有两个用法：</p><ul><li><code>db1:db2</code>：如果只指定数据库，那么就将两个数据库中互相缺少的对象显示出来，不比较对象里面的差异。这里的对象包括表、存储过程、函数、触发器等。<br>如果db1与db2名字相同，可以只指定 <code>db1</code></li><li><code>db1.object1:db2.object1</code>：如果指定了具体表对象，那么就会详细对比两个表的差异，包括表名、字段名、备注、索引、大小写等所有的表相关的对象。<br>如果两边db和对象名都相同，可以只指定 <code>db1.object1</code></li></ul><p>接下来看一些主要的参数：</p><ul><li><code>--server1</code>：配置server1的连接。</li><li><code>--server2</code>：配置server2的连接。</li><li><code>--character-set</code>：配置连接时用的字符集，如果不显示配置默认使用character_set_client。</li><li><code>--width</code>：配置显示的宽度。</li><li><code>--skip-table-options</code>：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。</li><li><code>-d DIFFTYPE,--difftype=DIFFTYPE</code>：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用<code>sql</code>，那么就直接生成差异的SQL，这样非常方便。</li><li><code>--changes-for=</code>：修改对象。例如 –changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。</li><li><code>--show-reverse</code>：在生成的差异修改里面，同时会包含server2和server1的修改。</li><li><code>--force</code>：完成所有的比较，不会在遇到一个差异之后退出</li><li><code>-vv</code>：便于调试，输出许多信息</li><li><code>-q</code>：quiet模式，关闭多余的信息输出</li></ul><h1 id="问题修复与增强"><a href="#问题修复与增强" class="headerlink" title="问题修复与增强"></a>问题修复与增强</h1><p>但是试用下来，发现有以下几大问题</p><ol><li>对象在一方不存在时，比对结果是 object does not exist，而我们通常需要的是，生产 <code>CREATE/DROP XXX</code> 语句</li><li>要比对一个db下面所有的对象（table, view, event, proc, func, trigger），要手动挨个 db1.t1, db2.v2…，而 db1:db2只是检查对象是否存在，不会自动比较db1与db2下的所有对象</li><li>比较时，<code>auto_increment</code>应该忽略，但是 mysqldiff 只提供 <code>--skip-table-options</code> ，忽略全部表选项，包括 auto_increment, engine, charset等等。</li><li>严重bug<ul><li>T1: idx1(f1,f2),  T2: idx1(f1)，这种索引会生成 ADD INDEX idx(f2)</li><li>T1: idx2(f1,f2), idx3(f3,f4),  T2: idx4(f5)，这种组合索引，有可能生成的会乱序</li></ul></li></ol><p>这两个bug与mysqldiff的设计有关系，个人觉得它把比较和生产差异sql完全分开，复杂化了。它得到差异结果之后，生成sql又从db捞各种元数据来组装，其实从差异diff里面就可以获得组装需要的数据，也不容易出现隐藏的bug。参考实现 <a href="https://github.com/hidu/mysql-schema-sync" target="_blank" rel="noopener">https://github.com/hidu/mysql-schema-sync</a></p><p>针对上面几大问题，花了两天的时间阅读并修改了 mysqldiff 以及相关依赖的代码，都一一解决。<br>修复后的地址：<a href="https://github.com/seanlook/mysql-utilities/commits/master" target="_blank" rel="noopener">https://github.com/seanlook/mysql-utilities/commits/master</a><br>(mysql-utilities不像percona-toolkit那样每个工具都是All In One，需要改动mysqldiff.py意外的依赖模块)</p><p>默认情况与官方的 mysqldiff 完全兼容，新增3个选项</p><ol><li><code>--include-create</code>：是否生成创建对象(表等)的语句，而不是仅告知对象不存在。只有在 <code>--difftype=sql</code> 时有效。默认False</li><li><code>--include-drop</code>：是否生成DROP对象的语句，针对对象在原db不存在，而仅目标db存在的情况。只有在指定了<code>--include-create</code> 时起作用。drop操作因为比较危险，默认False，所以多加了这个选项</li><li><code>--skip-opt-autoinc</code>：比较时跳过AUTO_INCREMNT。默认False</li><li>比较对象是，指定 <code>db1.*</code>  或 <code>db1.*:db2.*</code> 时，会比较他们所有的对象差异，而不仅显示缺少的对象</li></ol><h2 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a>使用注意</h2><ol><li>比较时，尽量选择mysql版本相近的实例，比如mysql与mariadb比较，相同的表结构 show create table xxx 时可能得到不同的结果：<ul><li>mariadb会把int字段 default ‘0’ 自动改成 default 0</li><li><code>CURRENT_TIMESTAMP</code>会显示成 <code>current_timestamp()</code></li><li>字段 <code>default NULL</code> 时，mysql connector/python 查 <code>information_schema.COLUMNS.COLUMN_DEFAULT</code> 字段为 <code>‘NULL’</code> （带引号的字符），而不是None（即查出来是NULL），导致与mysql版本用不一样</li></ul></li><li>字段注释 <code>COMMENT &#39;是否批准加入群 默认1批准 0拒绝\0e=&#39;&#39;t_user_g\0&#39;</code> ，是成立的，正常\0后面的都是没用的，但有个 <code>&#39;</code> 号，会导致生产sql时有多余的 <code>&#39;</code> 好，直接执行会失败。<br>所以，字段注释要规范，不要带入这些乱起乱七八糟的字符，特别是用IDE建表时，完成后在命令行 show create table xxx 看一下。</li></ol><a id="more"></a><h1 id="演示对比"><a href="#演示对比" class="headerlink" title="演示对比"></a>演示对比</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">mysqldiff --server1=ecdba:xx@yyyy:3305 --server2=ecdba:xx@yyyy:3305 mydb1.t_user:mydb2.t_user  --changes-for=server2  --difftype=sql</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line"># Comparing mydb1.t_user to mydb2.t_user                           [FAIL]</span><br><span class="line"># Transformation for --changes-for=server2:</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">ALTER TABLE `mydb2`.`t_user`</span><br><span class="line">  DROP INDEX idx_corpid,</span><br><span class="line">  ADD INDEX idx_corpid_deptid (f_corp_id,f_dept_id),</span><br><span class="line">  ADD INDEX idx_dept (f_dept_id);</span><br><span class="line"> </span><br><span class="line"># Compare failed. One or more differences found.</span><br><span class="line">  </span><br><span class="line">这个地方原版里面会将idx_corpid_deptid生成 ADD INDEX idx_corpid_deptid(f_corp_id), ADD INDEX idx_corpid_deptid(f_dept_id)。这里已修复</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">原版：</span><br><span class="line">mydb1.t_test1:mydb2.t_test1  --changes-for=server2  --difftype=sql</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line">ERROR: The object mydb2.t_test1 does not exist.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">新选项 --include-create --include-drop</span><br><span class="line">mydb1.t_test1:mydb2.t_test1  --changes-for=server2  --difftype=sql --include-create --include-drop</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line"> </span><br><span class="line">USE mydb2;</span><br><span class="line">CREATE TABLE `t_test1` (</span><br><span class="line">  `id` int(11) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4&apos;;</span><br><span class="line">&apos;</span><br><span class="line"># Compare failed. One or more differences found.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">新选项，修改changes-for后，生成drop</span><br><span class="line">mydb1.t_test1:mydb2.t_test1  --changes-for=server1  --difftype=sql --include-create --include-drop</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line">DROP TABLE IF EXISTS mydb1.t_test1;</span><br><span class="line"> </span><br><span class="line"># Compare failed. One or more differences found.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">mydb1.t_user_face:mydb2.t_user_face  --changes-for=server2  --difftype=sql --include-create --include-drop</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line"># Comparing mydb1.t_user_face to mydb2.t_user_face                 [FAIL]</span><br><span class="line"># Transformation for --changes-for=server2:</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">ALTER TABLE `mydb2`.`t_user_face`</span><br><span class="line">  DROP INDEX idx_tt2,</span><br><span class="line">  DROP INDEX idx_corp_time,</span><br><span class="line">  DROP COLUMN f_test,</span><br><span class="line">  ADD INDEX idx_corp_time (f_corp_id,f_modify_time),</span><br><span class="line">  CHANGE COLUMN f_corp_id f_corp_id int(11) unsigned NOT NULL COMMENT &apos;企业id&apos;,</span><br><span class="line">  CHANGE COLUMN f_user_id f_user_id int(11) unsigned NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">AUTO_INCREMENT=123434, COLLATE=utf8mb4_general_ci;</span><br><span class="line"> </span><br><span class="line"># Compare failed. One or more differences found.</span><br><span class="line">这个地方原版处理 idx_corp_time 时，因为第一列索引字段相同，会生成 ADD INDEX idx_corp_time(f_modify_time)。这里已修复</span><br><span class="line"> </span><br><span class="line">新选项 --skip-option-autoinc</span><br><span class="line">mydb1.t_user_face:mydb2.t_user_face  --changes-for=server1  --difftype=sql --include-create --include-drop --skip-option-autoinc</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line"># Comparing mydb1.t_user_face to mydb2.t_user_face                 [FAIL]</span><br><span class="line"># Transformation for --changes-for=server1:</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">ALTER TABLE `mydb1`.`t_user_face`</span><br><span class="line">  DROP INDEX idx_corp_time,</span><br><span class="line">  ADD UNIQUE INDEX idx_tt2 (f_user_id,f_modify_time),</span><br><span class="line">  ADD INDEX idx_corp_time (f_corp_id),</span><br><span class="line">  CHANGE COLUMN f_corp_id f_corp_id int(10) unsigned NOT NULL COMMENT &apos;企业id&apos;,</span><br><span class="line">  CHANGE COLUMN f_user_id f_user_id int(10) unsigned NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">  ADD COLUMN f_test varchar(20) NOT NULL DEFAULT &apos;&apos; AFTER f_url,</span><br><span class="line">COLLATE=utf8_general_ci;</span><br><span class="line"> </span><br><span class="line"># Compare failed. One or more differences found.</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">直接指定db，原版预修改版处理相同</span><br><span class="line">mydb1:mydb2  --changes-for=server2  --difftype=sql</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line"># WARNING: Objects in server1.mydb1 but not in server1.mydb2:</span><br><span class="line">#        TABLE: t_test1</span><br><span class="line"># WARNING: Objects in server1.mydb2 but not in server1.mydb1:</span><br><span class="line">#         VIEW: view_test</span><br><span class="line">#        TABLE: t_test2</span><br><span class="line"># Compare failed. One or more differences found.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">指定 db.* ，处理相同</span><br><span class="line">mydb1.*:mydb2.*  --changes-for=server2  --difftype=sql</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line">ERROR: The object mydb1.* does not exist.</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">指定 db.* 和 --include-create ，依次处理全部对象，包括过程，视图等</span><br><span class="line">mydb1.*:mydb2.*  --changes-for=server2  --difftype=sql --difftype=sql --include-create --include-drop --skip-option-autoinc</span><br><span class="line"># WARNING: Using a password on the command line interface can be insecure.</span><br><span class="line"># server1 on 10.xx.xx.127: ... connected.</span><br><span class="line"># server2 on 10.xx.xx.127: ... connected.</span><br><span class="line"># WARNING: Objects in server1.mydb1 but not in server1.mydb2:</span><br><span class="line">#        TABLE: t_test1</span><br><span class="line"># WARNING: Objects in server1.mydb2 but not in server1.mydb1:</span><br><span class="line">#         VIEW: view_test</span><br><span class="line">#        TABLE: t_test2</span><br><span class="line"># Comparing mydb1.t_user_face to mydb2.t_user_face                 [FAIL]</span><br><span class="line"># Transformation for --changes-for=server2:</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">ALTER TABLE `mydb2`.`t_user_face`</span><br><span class="line">  DROP INDEX idx_tt2,</span><br><span class="line">  DROP INDEX idx_corp_time,</span><br><span class="line">  DROP COLUMN f_test,</span><br><span class="line">  ADD INDEX idx_corp_time (f_corp_id,f_modify_time),</span><br><span class="line">  CHANGE COLUMN f_corp_id f_corp_id int(11) unsigned NOT NULL COMMENT &apos;企业id&apos;,</span><br><span class="line">  CHANGE COLUMN f_user_id f_user_id int(11) unsigned NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">COLLATE=utf8mb4_general_ci;</span><br><span class="line"> </span><br><span class="line">DROP VIEW IF EXISTS mydb2.view_test;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">USE mydb2;</span><br><span class="line">CREATE TABLE `t_test1` (</span><br><span class="line">  `id` int(11) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4&apos;;</span><br><span class="line">&apos;</span><br><span class="line"># Comparing mydb1.t_user to mydb2.t_user                           [FAIL]</span><br><span class="line"># Transformation for --changes-for=server2:</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">ALTER TABLE `mydb2`.`t_user`</span><br><span class="line">  DROP INDEX idx_corpid,</span><br><span class="line">  ADD INDEX idx_corpid_deptid (f_corp_id,f_dept_id),</span><br><span class="line">  ADD INDEX idx_dept (f_dept_id);</span><br><span class="line"> </span><br><span class="line"># Comparing mydb1.proc_test to mydb2.proc_test                     [FAIL]</span><br><span class="line"># Transformation for --changes-for=server2:</span><br><span class="line">#</span><br><span class="line"> </span><br><span class="line">DROP PROCEDURE IF EXISTS `mydb2`.`proc_test`;</span><br><span class="line">DELIMITER //</span><br><span class="line">CREATE DEFINER=`ecdba`@`%` PROCEDURE `mydb2`.`proc_test` () CONTAINS SQL SQL SECURITY DEFINER BEGIN</span><br><span class="line">    select 1;</span><br><span class="line"> </span><br><span class="line">END//</span><br><span class="line">DELIMITER ;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">DROP TABLE IF EXISTS mydb2.t_test2;</span><br><span class="line"> </span><br><span class="line"># Compare failed. One or more differences found.</span><br></pre></td></tr></table></figure><hr><p>原文连接地址：<a href="http://seanlook.com/2017/08/05/mysql_mysqldiff/">http://seanlook.com/2017/08/05/mysql_mysqldiff/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;mysqldiff&quot;&gt;&lt;a href=&quot;#mysqldiff&quot; class=&quot;headerlink&quot; title=&quot;mysqldiff&quot;&gt;&lt;/a&gt;mysqldiff&lt;/h1&gt;&lt;p&gt;mysql官方有个 &lt;a href=&quot;https://dev.mysql.com/doc/mysql-utilities/1.6/en/mysql-utils-install-rpm.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;mysql-utilities 工具集&lt;/a&gt;，其中 mysqldiff 可用于比较两个db之间的表结构。&lt;br&gt;mysqldiff的语法格式是：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这个语法有两个用法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;db1:db2&lt;/code&gt;：如果只指定数据库，那么就将两个数据库中互相缺少的对象显示出来，不比较对象里面的差异。这里的对象包括表、存储过程、函数、触发器等。&lt;br&gt;如果db1与db2名字相同，可以只指定 &lt;code&gt;db1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;db1.object1:db2.object1&lt;/code&gt;：如果指定了具体表对象，那么就会详细对比两个表的差异，包括表名、字段名、备注、索引、大小写等所有的表相关的对象。&lt;br&gt;如果两边db和对象名都相同，可以只指定 &lt;code&gt;db1.object1&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来看一些主要的参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--server1&lt;/code&gt;：配置server1的连接。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--server2&lt;/code&gt;：配置server2的连接。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--character-set&lt;/code&gt;：配置连接时用的字符集，如果不显示配置默认使用character_set_client。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--width&lt;/code&gt;：配置显示的宽度。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--skip-table-options&lt;/code&gt;：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-d DIFFTYPE,--difftype=DIFFTYPE&lt;/code&gt;：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用&lt;code&gt;sql&lt;/code&gt;，那么就直接生成差异的SQL，这样非常方便。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--changes-for=&lt;/code&gt;：修改对象。例如 –changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--show-reverse&lt;/code&gt;：在生成的差异修改里面，同时会包含server2和server1的修改。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--force&lt;/code&gt;：完成所有的比较，不会在遇到一个差异之后退出&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-vv&lt;/code&gt;：便于调试，输出许多信息&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-q&lt;/code&gt;：quiet模式，关闭多余的信息输出&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;问题修复与增强&quot;&gt;&lt;a href=&quot;#问题修复与增强&quot; class=&quot;headerlink&quot; title=&quot;问题修复与增强&quot;&gt;&lt;/a&gt;问题修复与增强&lt;/h1&gt;&lt;p&gt;但是试用下来，发现有以下几大问题&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对象在一方不存在时，比对结果是 object does not exist，而我们通常需要的是，生产 &lt;code&gt;CREATE/DROP XXX&lt;/code&gt; 语句&lt;/li&gt;
&lt;li&gt;要比对一个db下面所有的对象（table, view, event, proc, func, trigger），要手动挨个 db1.t1, db2.v2…，而 db1:db2只是检查对象是否存在，不会自动比较db1与db2下的所有对象&lt;/li&gt;
&lt;li&gt;比较时，&lt;code&gt;auto_increment&lt;/code&gt;应该忽略，但是 mysqldiff 只提供 &lt;code&gt;--skip-table-options&lt;/code&gt; ，忽略全部表选项，包括 auto_increment, engine, charset等等。&lt;/li&gt;
&lt;li&gt;严重bug&lt;ul&gt;
&lt;li&gt;T1: idx1(f1,f2),  T2: idx1(f1)，这种索引会生成 ADD INDEX idx(f2)&lt;/li&gt;
&lt;li&gt;T1: idx2(f1,f2), idx3(f3,f4),  T2: idx4(f5)，这种组合索引，有可能生成的会乱序&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这两个bug与mysqldiff的设计有关系，个人觉得它把比较和生产差异sql完全分开，复杂化了。它得到差异结果之后，生成sql又从db捞各种元数据来组装，其实从差异diff里面就可以获得组装需要的数据，也不容易出现隐藏的bug。参考实现 &lt;a href=&quot;https://github.com/hidu/mysql-schema-sync&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/hidu/mysql-schema-sync&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;针对上面几大问题，花了两天的时间阅读并修改了 mysqldiff 以及相关依赖的代码，都一一解决。&lt;br&gt;修复后的地址：&lt;a href=&quot;https://github.com/seanlook/mysql-utilities/commits/master&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/seanlook/mysql-utilities/commits/master&lt;/a&gt;&lt;br&gt;(mysql-utilities不像percona-toolkit那样每个工具都是All In One，需要改动mysqldiff.py意外的依赖模块)&lt;/p&gt;
&lt;p&gt;默认情况与官方的 mysqldiff 完全兼容，新增3个选项&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;--include-create&lt;/code&gt;：是否生成创建对象(表等)的语句，而不是仅告知对象不存在。只有在 &lt;code&gt;--difftype=sql&lt;/code&gt; 时有效。默认False&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--include-drop&lt;/code&gt;：是否生成DROP对象的语句，针对对象在原db不存在，而仅目标db存在的情况。只有在指定了&lt;code&gt;--include-create&lt;/code&gt; 时起作用。drop操作因为比较危险，默认False，所以多加了这个选项&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--skip-opt-autoinc&lt;/code&gt;：比较时跳过AUTO_INCREMNT。默认False&lt;/li&gt;
&lt;li&gt;比较对象是，指定 &lt;code&gt;db1.*&lt;/code&gt;  或 &lt;code&gt;db1.*:db2.*&lt;/code&gt; 时，会比较他们所有的对象差异，而不仅显示缺少的对象&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;使用注意&quot;&gt;&lt;a href=&quot;#使用注意&quot; class=&quot;headerlink&quot; title=&quot;使用注意&quot;&gt;&lt;/a&gt;使用注意&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;比较时，尽量选择mysql版本相近的实例，比如mysql与mariadb比较，相同的表结构 show create table xxx 时可能得到不同的结果：&lt;ul&gt;
&lt;li&gt;mariadb会把int字段 default ‘0’ 自动改成 default 0&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CURRENT_TIMESTAMP&lt;/code&gt;会显示成 &lt;code&gt;current_timestamp()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;字段 &lt;code&gt;default NULL&lt;/code&gt; 时，mysql connector/python 查 &lt;code&gt;information_schema.COLUMNS.COLUMN_DEFAULT&lt;/code&gt; 字段为 &lt;code&gt;‘NULL’&lt;/code&gt; （带引号的字符），而不是None（即查出来是NULL），导致与mysql版本用不一样&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;字段注释 &lt;code&gt;COMMENT &amp;#39;是否批准加入群 默认1批准 0拒绝\0e=&amp;#39;&amp;#39;t_user_g\0&amp;#39;&lt;/code&gt; ，是成立的，正常\0后面的都是没用的，但有个 &lt;code&gt;&amp;#39;&lt;/code&gt; 号，会导致生产sql时有多余的 &lt;code&gt;&amp;#39;&lt;/code&gt; 好，直接执行会失败。&lt;br&gt;所以，字段注释要规范，不要带入这些乱起乱七八糟的字符，特别是用IDE建表时，完成后在命令行 show create table xxx 看一下。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="表结构" scheme="http://seanlook.com/tags/%E8%A1%A8%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>ProxySQL PPT分享</title>
    <link href="http://seanlook.com/2017/07/19/proxysql-tutorials-ec/"/>
    <id>http://seanlook.com/2017/07/19/proxysql-tutorials-ec/</id>
    <published>2017-07-19T13:32:49.000Z</published>
    <updated>2017-07-19T13:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>前些天在公司内部进行了一次 ProxySQL主题的介绍 《ProxySQL数据库中间件使用实践》，因为proxysql是我调研并引入公司的，有必要跟本组开发同学，进行一个正式的介绍和使用说明，以及我们当前的应用情况。</p><p>分享比较偷懒，直接拿来proxysql作者renecannao在 Percona Live Europe 2016 上的PPT，是一个非常全面又具有点睛作用的演示稿了。</p><div class="row">    <embed src="http://7q5fot.com1.z0.glb.clouddn.com/ProxySQL-Tutorials-PerconaLive.pdf" width="100%" height="550" type="application/pdf"></div><p>PPT来源：<a href="https://www.percona.com/live/17/sessions/proxysql-tutorial" target="_blank" rel="noopener">https://www.percona.com/live/17/sessions/proxysql-tutorial</a></p><p>另外一个觉得也还不错：<a href="https://www.slideshare.net/MyDBOPS/proxysql-for-mysql" target="_blank" rel="noopener">https://www.slideshare.net/MyDBOPS/proxysql-for-mysql</a></p><p>– 我只是ppt的搬运工</p><hr><p>原文连接地址：<a href="http://seanlook.com/2017/07/19/proxysql-tutorials-ec/">http://seanlook.com/2017/07/19/proxysql-tutorials-ec/</a></p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前些天在公司内部进行了一次 ProxySQL主题的介绍 《ProxySQL数据库中间件使用实践》，因为proxysql是我调研并引入公司的，有必要跟本组开发同学，进行一个正式的介绍和使用说明，以及我们当前的应用情况。&lt;/p&gt;
&lt;p&gt;分享比较偷懒，直接拿来proxysql作者
      
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="分享" scheme="http://seanlook.com/tags/%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>ProxySQL监控方案</title>
    <link href="http://seanlook.com/2017/07/16/mysql-proxysql-monitor/"/>
    <id>http://seanlook.com/2017/07/16/mysql-proxysql-monitor/</id>
    <published>2017-07-16T13:32:49.000Z</published>
    <updated>2017-07-18T13:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>ProxySQL能监控的信息不多，而且大部分是统计信息，不是性能数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show tables from stats;</span><br><span class="line">+--------------------------------+</span><br><span class="line">| tables                         |</span><br><span class="line">+--------------------------------+</span><br><span class="line">| global_variables               |</span><br><span class="line">| stats_mysql_commands_counters  |</span><br><span class="line">| stats_mysql_connection_pool    |</span><br><span class="line">| stats_mysql_global             |</span><br><span class="line">| stats_mysql_processlist        |</span><br><span class="line">| stats_mysql_query_digest       |</span><br><span class="line">| stats_mysql_query_digest_reset |</span><br><span class="line">| stats_mysql_query_rules        |</span><br><span class="line">+--------------------------------+</span><br></pre></td></tr></table></figure><p>主要关心的指标都在表 <code>stats_mysql_global</code> 里面，源代码 diamond 目录下有个 <em>proxysqlstat.py</em> 脚本，是通过<code>SHOW MYSQL STATUS</code>命令，由diamond收集进程将指标上报到Graphite。有以下几个Metrics：</p><ul><li>并发数<ul><li>Active_Transactions</li><li>Questions</li></ul></li><li>连接相关<ul><li>Client_Connections_connected</li><li>Server_Connections_connected</li><li>Server_Connections_aborted</li></ul></li><li>内存相关<ul><li>Query_Cache_Entries</li><li>Query_Cache_Memory_bytes</li><li>SQLite3_memory_bytes</li><li>ConnPool_memory_bytes</li></ul></li><li>流量相关<ul><li>mysql_backend_buffers_bytes</li><li>mysql_frontend_buffers_bytes</li><li>mysql_session_internal_bytes</li></ul></li><li>其它<ul><li>MySQL_Monitor_Workers</li><li>MySQL_Thread_Workers</li></ul></li></ul><p>但是这些远远不够，还有以下更值得关心的指标：<br>表 <code>stats_mysql_connection_pool</code>:</p><ul><li>对后端DB请求的网络延时 Latency</li><li>对后端各个DB的请求数 Queries</li><li>后端各个DB的当前活跃连接数 ConnUsed</li><li>后端DB的状态 status</li></ul><p>表 <code>stats_mysql_processlist</code>:</p><ul><li>每个用户的当前的连接数</li></ul><p>表 <code>stats_mysql_query_digest</code>:</p><ul><li>各个类型的sql请求量比例、趋势</li></ul><p>在我们的环境下使用的是 InfluxDB + Grafana，通过telegraf收集上报。上述所有的监控脚本见仓库 <a href="https://github.com/seanlook/proxysql_tools" target="_blank" rel="noopener">https://github.com/seanlook/proxysql_tools</a> ：</p><ul><li><p><code>proxysql_stats.py</code>:</p><ul><li>收集 stats_mysql_global 和 stats_mysql_connection_pool 中的信息，打印出 influxdb 数据上报格式</li></ul></li><li><p><code>proxysql_stats_digest.py</code>:</p><ul><li>收集 sql digest，收集的信息用于展示每类sql的执行趋势。<br>因为数据是累计值，所以这里做了增量计算，然后一方面上报给influxdb，一方面存入mysql，可以做更多用途。mysql的表结构 proxysql_stats_digest.sql 。<br>建议收集频率不要过高，比如10分钟一次。</li></ul></li><li><p><code>grafana_proxysql_stats.json</code>:</p><ul><li>Grafana Dashboard，直接导入可用 。</li></ul></li></ul><p>除此外，还需要对proxysql进程的监控，如内存占用、CPU使用，这部分通过telegraf的 procstat 插件去做：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[[inputs.procstat]]</span><br><span class="line">    exe = &quot;proxysql&quot;</span><br><span class="line"></span><br><span class="line">[[inputs.exec]]</span><br><span class="line"></span><br><span class="line">  # the command to run</span><br><span class="line">  command = &quot;/etc/telegraf/telegraf.d/proxysql_stats.py&quot;</span><br><span class="line"></span><br><span class="line">  ## Timeout for each command to complete.</span><br><span class="line">  timeout = &quot;10s&quot;</span><br><span class="line"></span><br><span class="line">  data_format = &quot;influx&quot;</span><br></pre></td></tr></table></figure></p><p>对后端DB status和proxysql端口存活，设置告警。这样就有一个相对完整的ProxySQL监控方案了。<br><a id="more"></a><br>面板示例：</p><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-monitor-1.png" alt="Geneal"><br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-monitor-2.png" alt="Queries"><br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-monitor-3.png" alt="Process"></p><hr><p>原文连接地址：<a href="http://seanlook.com/2017/07/16/mysql-proxysql-monitor/">http://seanlook.com/2017/07/16/mysql-proxysql-monitor/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ProxySQL能监控的信息不多，而且大部分是统计信息，不是性能数据。&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;mysql&amp;gt; show tables from stats;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------------------------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| tables                         |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------------------------------+&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| global_variables               |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| stats_mysql_commands_counters  |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| stats_mysql_connection_pool    |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| stats_mysql_global             |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| stats_mysql_processlist        |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| stats_mysql_query_digest       |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| stats_mysql_query_digest_reset |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;| stats_mysql_query_rules        |&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;+--------------------------------+&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;主要关心的指标都在表 &lt;code&gt;stats_mysql_global&lt;/code&gt; 里面，源代码 diamond 目录下有个 &lt;em&gt;proxysqlstat.py&lt;/em&gt; 脚本，是通过&lt;code&gt;SHOW MYSQL STATUS&lt;/code&gt;命令，由diamond收集进程将指标上报到Graphite。有以下几个Metrics：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;并发数&lt;ul&gt;
&lt;li&gt;Active_Transactions&lt;/li&gt;
&lt;li&gt;Questions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;连接相关&lt;ul&gt;
&lt;li&gt;Client_Connections_connected&lt;/li&gt;
&lt;li&gt;Server_Connections_connected&lt;/li&gt;
&lt;li&gt;Server_Connections_aborted&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;内存相关&lt;ul&gt;
&lt;li&gt;Query_Cache_Entries&lt;/li&gt;
&lt;li&gt;Query_Cache_Memory_bytes&lt;/li&gt;
&lt;li&gt;SQLite3_memory_bytes&lt;/li&gt;
&lt;li&gt;ConnPool_memory_bytes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;流量相关&lt;ul&gt;
&lt;li&gt;mysql_backend_buffers_bytes&lt;/li&gt;
&lt;li&gt;mysql_frontend_buffers_bytes&lt;/li&gt;
&lt;li&gt;mysql_session_internal_bytes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;其它&lt;ul&gt;
&lt;li&gt;MySQL_Monitor_Workers&lt;/li&gt;
&lt;li&gt;MySQL_Thread_Workers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是这些远远不够，还有以下更值得关心的指标：&lt;br&gt;表 &lt;code&gt;stats_mysql_connection_pool&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对后端DB请求的网络延时 Latency&lt;/li&gt;
&lt;li&gt;对后端各个DB的请求数 Queries&lt;/li&gt;
&lt;li&gt;后端各个DB的当前活跃连接数 ConnUsed&lt;/li&gt;
&lt;li&gt;后端DB的状态 status&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表 &lt;code&gt;stats_mysql_processlist&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个用户的当前的连接数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表 &lt;code&gt;stats_mysql_query_digest&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;各个类型的sql请求量比例、趋势&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在我们的环境下使用的是 InfluxDB + Grafana，通过telegraf收集上报。上述所有的监控脚本见仓库 &lt;a href=&quot;https://github.com/seanlook/proxysql_tools&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/seanlook/proxysql_tools&lt;/a&gt; ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;proxysql_stats.py&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集 stats_mysql_global 和 stats_mysql_connection_pool 中的信息，打印出 influxdb 数据上报格式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;proxysql_stats_digest.py&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;收集 sql digest，收集的信息用于展示每类sql的执行趋势。&lt;br&gt;因为数据是累计值，所以这里做了增量计算，然后一方面上报给influxdb，一方面存入mysql，可以做更多用途。mysql的表结构 proxysql_stats_digest.sql 。&lt;br&gt;建议收集频率不要过高，比如10分钟一次。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;grafana_proxysql_stats.json&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Grafana Dashboard，直接导入可用 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除此外，还需要对proxysql进程的监控，如内存占用、CPU使用，这部分通过telegraf的 procstat 插件去做：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[[inputs.procstat]]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    exe = &amp;quot;proxysql&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[[inputs.exec]]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  # the command to run&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  command = &amp;quot;/etc/telegraf/telegraf.d/proxysql_stats.py&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  ## Timeout for each command to complete.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  timeout = &amp;quot;10s&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  data_format = &amp;quot;influx&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;对后端DB status和proxysql端口存活，设置告警。这样就有一个相对完整的ProxySQL监控方案了。&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="中间件" scheme="http://seanlook.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="proxysql" scheme="http://seanlook.com/tags/proxysql/"/>
    
  </entry>
  
  <entry>
    <title>ProxySQL高可用方案</title>
    <link href="http://seanlook.com/2017/07/15/mysql-proxysql-ha-consul/"/>
    <id>http://seanlook.com/2017/07/15/mysql-proxysql-ha-consul/</id>
    <published>2017-07-15T13:32:49.000Z</published>
    <updated>2017-07-18T13:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>MySQL的高可用方案现在如 MHA, Galera, InnoDB Cluster，一旦在上游使用中间件之后，中间件本身可能成为单点。所以本文要介绍的是对于ProxySQL自身高可用的方案对比。<br>首先ProxySQL自身是通过Angel进程的形式运行，即proxysql如果有崩溃，主进程会自动拉起来。但如果是无响应或者网络故障，则需要另外的机制去做到服务的高可用。本文总结了四种方法。</p><p>ProxySQL有关介绍，请参考： <a href="http://seanlook.com/2017/04/10/mysql-proxysql-install-config/">http://seanlook.com/2017/04/10/mysql-proxysql-install-config/</a></p><h1 id="1-与应用一起部署"><a href="#1-与应用一起部署" class="headerlink" title="1. 与应用一起部署"></a>1. 与应用一起部署</h1><p>所有部署应用的地方，都会部署proxysql节点，当这个proxysql挂掉之后，只影响本机的应用。而且不需要多经过一层网络。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-1.png" alt=""><br>但带来的问题是，如果应用节点很多，proxy的数量也会增加：</p><ul><li>会导致proxysql的配置不容易管理</li><li>proxysql对后端db健康检查的请求成倍增加</li><li>限制每个用户或后端db的 max_connections 特性用不了</li></ul><h1 id="2-集中式部署，多ip引用"><a href="#2-集中式部署，多ip引用" class="headerlink" title="2. 集中式部署，多ip引用"></a>2. 集中式部署，多ip引用</h1><p>后端一个db集群，对应中间两个以上的 proxysql 节点，前端应用配置多个ip地址，随机挑选一个使用，完全无状态。仅需要多经过一次网络代理。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-2.png" alt=""><br>这种方式的好处是，不需要再对数据库这种基础服务，多引入一个软件来实现高可用（如下节的keepalive或consul），由应用端获取数据库连接的代码逻辑处理。</p><p>但是因为proxysql访问地址是写在配置文件里面的，如果一个节点挂掉，随机挑选还是会落地这个失败的节点。所以优化方案是，ip列表里面默认取某一个，失败之后再选取下一个重试。</p><p>示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">proxysql_addr_list = [<span class="string">'192.168.1.175'</span>, <span class="string">'192.168.1.176'</span>, <span class="string">'192.168.1.177'</span>]</span><br><span class="line">proxysql_addr_list_len = <span class="number">3</span></span><br><span class="line">hostname = <span class="string">'this_hostname_for_hash_loadbalance'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dbconnection</span><span class="params">()</span>:</span></span><br><span class="line">    list_index = hash(hostname) % proxysql_addr_list_len</span><br><span class="line">    dbconn = <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        dbconn = DBConnect(dbhost=proxysql_addr_list[ list_index ], dbport=<span class="number">3306</span>)  <span class="comment"># timeout 1000ms</span></span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">if</span> (list_index + <span class="number">1</span>) == proxysql_addr_list_len:</span><br><span class="line">            list_index = <span class="number">-1</span>  <span class="comment"># like Circular Array</span></span><br><span class="line">        dbconn = DBConnec(dbhost=proxysql_addr_list[ list_index + <span class="number">1</span> ], dbport=<span class="number">3306</span>)  <span class="comment"># if failed again, through exception</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dbconn</span><br></pre></td></tr></table></figure><p>上述并不完美，比如可以改用环形数组轮巡，允许重试其它更多的ip。<br><a id="more"></a></p><h2 id="能不能不进行多IP引用呢？"><a href="#能不能不进行多IP引用呢？" class="headerlink" title="能不能不进行多IP引用呢？"></a>能不能不进行多IP引用呢？</h2><p>为了避免后端引用IP的单点，可以将上面第1种和这里的第2中结合起来，改进的部署方案：（见文后参考链接）<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-1-1.png" alt=""><br>即在原来的基础上，App上的proxysql后端，挂的还是ProxySQL集群。</p><p>我个人没有验证这样的方案，如果要用需要充分验证proxysql互连的时候，有没有bug。</p><h1 id="3-经典-keepalived"><a href="#3-经典-keepalived" class="headerlink" title="3. 经典 keepalived"></a>3. 经典 keepalived</h1><p>引入keepalived，通过VIP访问两个以上的proxysql节点，既可以减少一次网络传输，又可以实现proxysql自身的高可用，而且甚至不用关心脑裂的问题，因为proxysql配置完全一样，是无状态的，脑裂了也无妨。<br>你也可能意识到，这种方式一次只能一个proxysql提供服务，另一个proxysql节点始终处于备用状态。如果配合LVS或haproxy做负载均衡，部署架构又会多出一层网络请求，而且越发复杂（VIP不在proxysql节点上漂，而是在两个lvs之间）。<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-3.png" alt=""><br>使用keepalived的前提是，局域网允许发组播包。这在阿里云ECS经典网络下是不允许的，如果有其它类似方式，如SLB也是可行的。目前测试环境采用是 haproxy + keepalived 的方式。</p><h1 id="4-Consul服务发现"><a href="#4-Consul服务发现" class="headerlink" title="4. Consul服务发现"></a>4. Consul服务发现</h1><p>如果上面的方式都不适用，那么可以进一步考虑使用第三方的服务发现组件。</p><h2 id="4-1-介绍"><a href="#4-1-介绍" class="headerlink" title="4.1 介绍"></a>4.1 介绍</h2><p>Consul用于实现分布式系统的服务发现与配置，我们将所有proxysql节点注册到consul上作为一个服务来提供，由 Consul agent Server 来判断proxysql节点的存活，每个应用节点上都安装 Consul agent Client 来供应用获取可用地址。</p><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-4.png" alt=""></p><p>这样部署架构的好处是：</p><ol><li>不需要多一层负载均衡，多一层网络链路</li><li>不需要部署大量的proxysql节点</li><li>App或者ProxySQL节点上的Consul故障，不影响其它节点。Consul Server集群的天生具备高可用</li><li>ProxySQL故障会被Consul检查到，踢除故障节点，并通知给所有consul agent</li><li>可以利用Consul的DNS接口实现简单的负载均衡</li></ol><p>其实consul所做的与本文第2节的类似：自动提出不可用的节点，只是一个是被动、手动，一个是主动、自动。<br>下面简单演示一下。</p><h2 id="4-2-部署示例"><a href="#4-2-部署示例" class="headerlink" title="4.2 部署示例"></a>4.2 部署示例</h2><p>Consul Server节点的安装在此略过，网上有不少文章，直接进入到在ProxySQL节点安装配置Consul。</p><p>Consul agent:</p><ul><li>apps-1: <code>10.0.201.168</code></li><li>apps-2: <code>10.0.201.220</code></li><li>apps-3: <code>10.0.201.156</code></li></ul><p>ProxySQL node:<br>每个节点上运行了两个proxysql进程 <code>7033: crm0</code>, <code>7133: crm1</code></p><ul><li>proxysql-1 : <code>192.168.1.170</code></li><li>proxysql-2 : <code>192.168.1.171</code></li></ul><h3 id="配置-proxysql-节点上的Consul"><a href="#配置-proxysql-节点上的Consul" class="headerlink" title="配置 proxysql 节点上的Consul"></a>配置 proxysql 节点上的Consul</h3><p>配置 proxysql-1 节点上的Consul：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">$ sudo vim /etc/consul.d/config.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;data_dir&quot;: &quot;/opt/consul&quot;, </span><br><span class="line">    &quot;datacenter&quot;: &quot;Office_test&quot;, </span><br><span class="line">    &quot;log_level&quot;: &quot;INFO&quot;, </span><br><span class="line">    &quot;node_name&quot;: &quot;proxysql-1&quot;, </span><br><span class="line">    &quot;retry_join&quot;: [</span><br><span class="line">        &quot;10.0.201.168&quot;, </span><br><span class="line">        &quot;10.0.201.220&quot;, </span><br><span class="line">        &quot;10.0.201.156&quot;</span><br><span class="line">    ], </span><br><span class="line">    &quot;telemetry&quot;: &#123;</span><br><span class="line">        &quot;statsd_address&quot;: &quot;10.0.201.34:8125&quot;, </span><br><span class="line">        &quot;statsite_prefix&quot;: &quot;proxysql-1&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;dns_config&quot;: &#123;</span><br><span class="line">        &quot;only_passing&quot;: true</span><br><span class="line">    &#125;</span><br><span class="line">    &quot;acl_datacenter&quot;: &quot;Office_test&quot;, </span><br><span class="line">    &quot;acl_default_policy&quot;: &quot;deny&quot;, </span><br><span class="line">    &quot;encrypt&quot;: &quot;XXXXxxxx==&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ sudo vi /etc/consul.d/proxysql.json</span><br><span class="line">&#123;&quot;services&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;id&quot;: &quot;proxysql_crm0&quot;, </span><br><span class="line">        &quot;name&quot;: &quot;proxysql&quot;, </span><br><span class="line">        &quot;address&quot;: &quot;192.168.1.170&quot;,</span><br><span class="line">        &quot;port&quot;: 7133, </span><br><span class="line">        &quot;tags&quot;: [&quot;test&quot;, &quot;crm0&quot;], </span><br><span class="line">        &quot;check&quot;: &#123;</span><br><span class="line">            &quot;interval&quot;: &quot;5s&quot;, </span><br><span class="line">            &quot;tcp&quot;: &quot;192.168.1.170:7033&quot;, </span><br><span class="line">            &quot;timeout&quot;: &quot;1s&quot;</span><br><span class="line">        &#125;, </span><br><span class="line">        &quot;enableTagOverride&quot;: false, </span><br><span class="line">        &quot;token&quot;: &quot;xxxxxxxx-xxxx&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;id&quot;: &quot;proxysql_crm1&quot;, </span><br><span class="line">        &quot;address&quot;: &quot;192.168.1.170&quot;,</span><br><span class="line">        &quot;name&quot;: &quot;proxysql&quot;, </span><br><span class="line">        &quot;port&quot;: 7133, </span><br><span class="line">        &quot;tags&quot;: [&quot;test&quot;, &quot;crm1&quot;], </span><br><span class="line">        &quot;check&quot;: &#123;</span><br><span class="line">            &quot;interval&quot;: &quot;5s&quot;, </span><br><span class="line">            &quot;tcp&quot;: &quot;192.168.1.170:7133&quot;, </span><br><span class="line">            &quot;timeout&quot;: &quot;1s&quot;</span><br><span class="line">        &#125;, </span><br><span class="line">        &quot;enableTagOverride&quot;: false, </span><br><span class="line">        &quot;token&quot;: &quot;xxxxxxxx-xxxx&quot;</span><br><span class="line">    &#125;</span><br><span class="line">]&#125;</span><br></pre></td></tr></table></figure></p><p>启动consul<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo consul agent -config-dir /etc/consul &amp;</span><br></pre></td></tr></table></figure></p><p>查看日志</p><p>proxysql-2 节点上的Consul配置根据上面的内容去改。</p><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-consul.png" alt=""></p><h2 id="4-4-使用方式"><a href="#4-4-使用方式" class="headerlink" title="4.4 使用方式"></a>4.4 使用方式</h2><p>先来看下效果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@proxysql-1 ~]# dig @127.0.0.1 -p 8600 crm0.proxysql.service.consul SRV</span><br><span class="line"></span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.62.rc1.el6_9.2 &lt;&lt;&gt;&gt; @127.0.0.1 -p 8600 crm0.proxysql.service.consul SRV</span><br><span class="line">; (1 server found)</span><br><span class="line">;; global options: +cmd</span><br><span class="line">;; Got answer:</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 65293</span><br><span class="line">;; flags: qr aa rd; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 2</span><br><span class="line">;; WARNING: recursion requested but not available</span><br><span class="line"></span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;crm0.proxysql.service.consul.INSRV</span><br><span class="line"></span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">crm0.proxysql.service.consul. 0INSRV1 1 7033 proxysql-1.node.office_test.consul.</span><br><span class="line">crm0.proxysql.service.consul. 0INSRV1 1 7033 proxysql-2.node.office_test.consul.</span><br><span class="line"></span><br><span class="line">;; ADDITIONAL SECTION:</span><br><span class="line">proxysql-1.node.office_test.consul. 0 IN A192.168.1.170</span><br><span class="line">proxysql-2.node.office_test.consul. 0 IN A192.168.1.171</span><br><span class="line"></span><br><span class="line">;; Query time: 3 msec</span><br><span class="line">;; SERVER: 127.0.0.1#8600(127.0.0.1)</span><br><span class="line">;; WHEN: Fri May 26 17:01:38 2017</span><br><span class="line">;; MSG SIZE  rcvd: 157</span><br></pre></td></tr></table></figure></p><p>看到域名 <code>crm0.proxysql.service.consul</code> 解析出来有两个可用地址 192.168.1.170，192.168.1.171，SRV记录还带出了端口信息（其实这里的端口对每个proxysql是固定/已知的，所以可不用SRV记录搜索）。</p><p>在应用端想要连接proxysql使用的方式大致有3种：</p><h3 id="DNS接口"><a href="#DNS接口" class="headerlink" title="DNS接口"></a>DNS接口</h3><p>需要将各自开发语言的DNS解析库嵌入到项目，指定 127.0.0.1:8600 为dns地址来解析上面的 crm0.proxysql.service.consul 域名。这种方式会增加开发的复杂度。</p><p>另一种方式是将应用服务器的默认DNS Server配置成本地consul的内置dns地址，并且consul设置 <code>recursors</code> 选项，来处理解析 consul. 以外的域名。这样对运维改动比较大。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&quot;recursors&quot;: [</span><br><span class="line">    &quot;10.143.22.116&quot;,</span><br><span class="line">    &quot;10.143.22.118&quot;,</span><br><span class="line">    &quot;114.114.114.114&quot;</span><br><span class="line">]</span><br></pre></td></tr></table></figure></p><h3 id="HTTP接口"><a href="#HTTP接口" class="headerlink" title="HTTP接口"></a>HTTP接口</h3><p>通过 API 的方式获取services信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -X GET &apos;http://10.0.201.156:8500/v1/health/service/proxysql?tag=crm1&amp;passing=true&apos;</span><br></pre></td></tr></table></figure><p>可以获取到 crm1 库的proxysql所有健康的 Node 和 Service 信息，然后任取一个使用。</p><p>但并不需要每一次访问proxysql都需要请求api，可以定时（如每隔10s）去请求，缓冲在本地或者变量里；在处理数据库连接的时候发现连接ProxySQL错误，则再主动触发一次向Consul请求新的地址，再重连。</p><p>需要考虑的是访问API的地址如果是IP，往往也是单点。另者，java这类jvm语言修改配置后往往需要重启，也不简单。</p><h3 id="consul-template直接生成数据库连接的配置文件"><a href="#consul-template直接生成数据库连接的配置文件" class="headerlink" title="consul-template直接生成数据库连接的配置文件"></a>consul-template直接生成数据库连接的配置文件</h3><p>consul-template通过事先定义好的模板，根据发现服务的健康状态，生成最新可用的配置文件，然后下发。</p><p>如果大但的想一下，各个服务或者语言的配置文件并不相同，直接生成一份 hosts 文件是最简单的，然后通过配置管理工具统一下发应用。也不需要关心是否需要重启应用。</p><h4 id="consul-watch"><a href="#consul-watch" class="headerlink" title="consul watch"></a>consul watch</h4><p>Consul watch 功能，可以检测到service变化之后，主动调用一个脚本，脚本可以去更新数据库配置信息，根据需要决定是否重启，后者生成hosts。与consul-template思想是相同的。</p><p>因为 watch 是通过阻塞式HTTP长连接请求的方式，实时获取到service的监控状态，所以有问题时反馈还比较及时。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&quot;watches&quot;:[&#123;</span><br><span class="line">  &quot;type&quot;: &quot;service&quot;,</span><br><span class="line">  &quot;service&quot;: &quot;proxysql&quot;,</span><br><span class="line">  &quot;tag&quot;: &quot;crm0&quot;,</span><br><span class="line">  &quot;passingonly&quot;: true,</span><br><span class="line">  &quot;handler&quot;: &quot;sh /tmp/consul_watch_test.sh&quot;</span><br><span class="line">&#125;]</span><br></pre></td></tr></table></figure></p><p><code>/tmp/consul_watch_test.sh</code> 脚本里或者python，可以做一些更新数据库配置文件、发送邮件等工作。</p><p><strong>参考</strong></p><ol><li><a href="https://www.percona.com/blog/2016/09/16/consul-proxysql-mysql-ha/" target="_blank" rel="noopener">https://www.percona.com/blog/2016/09/16/consul-proxysql-mysql-ha/</a></li><li><a href="https://www.percona.com/blog/2017/01/19/setup-proxysql-for-high-availability-not-single-point-failure/" target="_blank" rel="noopener">https://www.percona.com/blog/2017/01/19/setup-proxysql-for-high-availability-not-single-point-failure/</a></li><li><a href="https://www.slideshare.net/DerekDowney/proxysql-tutorial-plam-2016" target="_blank" rel="noopener">https://www.slideshare.net/DerekDowney/proxysql-tutorial-plam-2016</a> (本文部分图片出自该PPT)</li></ol><hr><p>原文连接地址：<a href="http://seanlook.com/2017/07/15/mysql-proxysql-ha-consul/">http://seanlook.com/2017/07/15/mysql-proxysql-ha-consul/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MySQL的高可用方案现在如 MHA, Galera, InnoDB Cluster，一旦在上游使用中间件之后，中间件本身可能成为单点。所以本文要介绍的是对于ProxySQL自身高可用的方案对比。&lt;br&gt;首先ProxySQL自身是通过Angel进程的形式运行，即proxysql如果有崩溃，主进程会自动拉起来。但如果是无响应或者网络故障，则需要另外的机制去做到服务的高可用。本文总结了四种方法。&lt;/p&gt;
&lt;p&gt;ProxySQL有关介绍，请参考： &lt;a href=&quot;http://seanlook.com/2017/04/10/mysql-proxysql-install-config/&quot;&gt;http://seanlook.com/2017/04/10/mysql-proxysql-install-config/&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;1-与应用一起部署&quot;&gt;&lt;a href=&quot;#1-与应用一起部署&quot; class=&quot;headerlink&quot; title=&quot;1. 与应用一起部署&quot;&gt;&lt;/a&gt;1. 与应用一起部署&lt;/h1&gt;&lt;p&gt;所有部署应用的地方，都会部署proxysql节点，当这个proxysql挂掉之后，只影响本机的应用。而且不需要多经过一层网络。&lt;br&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;但带来的问题是，如果应用节点很多，proxy的数量也会增加：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;会导致proxysql的配置不容易管理&lt;/li&gt;
&lt;li&gt;proxysql对后端db健康检查的请求成倍增加&lt;/li&gt;
&lt;li&gt;限制每个用户或后端db的 max_connections 特性用不了&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;2-集中式部署，多ip引用&quot;&gt;&lt;a href=&quot;#2-集中式部署，多ip引用&quot; class=&quot;headerlink&quot; title=&quot;2. 集中式部署，多ip引用&quot;&gt;&lt;/a&gt;2. 集中式部署，多ip引用&lt;/h1&gt;&lt;p&gt;后端一个db集群，对应中间两个以上的 proxysql 节点，前端应用配置多个ip地址，随机挑选一个使用，完全无状态。仅需要多经过一次网络代理。&lt;br&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/proxysql-ha-2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;这种方式的好处是，不需要再对数据库这种基础服务，多引入一个软件来实现高可用（如下节的keepalive或consul），由应用端获取数据库连接的代码逻辑处理。&lt;/p&gt;
&lt;p&gt;但是因为proxysql访问地址是写在配置文件里面的，如果一个节点挂掉，随机挑选还是会落地这个失败的节点。所以优化方案是，ip列表里面默认取某一个，失败之后再选取下一个重试。&lt;/p&gt;
&lt;p&gt;示例代码：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;proxysql_addr_list = [&lt;span class=&quot;string&quot;&gt;&#39;192.168.1.175&#39;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&#39;192.168.1.176&#39;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&#39;192.168.1.177&#39;&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;proxysql_addr_list_len = &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;hostname = &lt;span class=&quot;string&quot;&gt;&#39;this_hostname_for_hash_loadbalance&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;get_dbconnection&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    list_index = hash(hostname) % proxysql_addr_list_len&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    dbconn = &lt;span class=&quot;keyword&quot;&gt;None&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;try&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        dbconn = DBConnect(dbhost=proxysql_addr_list[ list_index ], dbport=&lt;span class=&quot;number&quot;&gt;3306&lt;/span&gt;)  &lt;span class=&quot;comment&quot;&gt;# timeout 1000ms&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;except&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (list_index + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) == proxysql_addr_list_len:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            list_index = &lt;span class=&quot;number&quot;&gt;-1&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;# like Circular Array&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        dbconn = DBConnec(dbhost=proxysql_addr_list[ list_index + &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; ], dbport=&lt;span class=&quot;number&quot;&gt;3306&lt;/span&gt;)  &lt;span class=&quot;comment&quot;&gt;# if failed again, through exception&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; dbconn&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;上述并不完美，比如可以改用环形数组轮巡，允许重试其它更多的ip。&lt;br&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="中间件" scheme="http://seanlook.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="proxysql" scheme="http://seanlook.com/tags/proxysql/"/>
    
  </entry>
  
  <entry>
    <title>ProxySQL之改进patch：记录查询sql完整样例与合并digest多个?</title>
    <link href="http://seanlook.com/2017/04/27/mysql-proxysql-patch-querytext-sample/"/>
    <id>http://seanlook.com/2017/04/27/mysql-proxysql-patch-querytext-sample/</id>
    <published>2017-04-27T07:32:49.000Z</published>
    <updated>2017-04-28T07:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>近期一直在思考sql上线审核该怎么做，刚好接触到 ProxySQL 这个中间件，内置了一个计算sql指纹的功能，但是没有记录原始的sql语句。当前正有个紧急的拆库项目也希望知道库上所有的查询。于是把ProxySQL的代码下了回来研究了几天，改了把，加入了两个功能：</p><ol><li>在 <code>stats_mysql_query_digest</code> 表上增加 <code>query_text</code> 字段，当第一次出现这个digest_text时，把原始sql记录下来。</li><li>修改计算指纹的模块，对 IN或者 VALUES 后面的多个 <code>?</code> 合并。这个是目前 <code>c_tokenizer.c</code> 文件里没有做的，用到底1点上可以避免重复记录。</li></ol><p>效果：<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-querytext-sample-digest.png" alt="proxysql-querytext-sample-digest"></p><p>多个 <code>?</code> 被折叠成 <code>?,</code>，有些意外情况时 <code>??</code>，因为后面一些多余空格的缘故，没有像 <em>pt-fingerprint</em> 那样完全模糊化，像这里digest就保留了大小写、去除重复空格、保留 ` 分隔符。但仅有的几种意外情况是可以接受的。</p><p>后面的 query_text 列也有些未知情况，就是末尾会加上一些奇怪的字符，还在排除，但大体不影响需求。</p><p>代码是基于最新 v1.3.6 稳定版修改的，查看变更 <a href="https://github.com/sysown/proxysql/compare/v1.3.6...seanlook:v1.3.7-querysample_digest" target="_blank" rel="noopener">https://github.com/sysown/proxysql/compare/v1.3.6...seanlook:v1.3.7-querysample_digest</a> </p><p>多个 <code>?</code> 合并只涉及到 <em>c_tokenizer.c</em> 文件，分别在flag=4（处理 <code>&#39;abc&#39;,&#39;def&#39;</code> 的情况）和flag=5（处理 <code>1,2, 3</code> 的情况）加入判断：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// wrap two more ? to one ?,</span><br><span class="line">if (*(p_r_t-2) == &apos;?&apos; &amp;&amp; (*(p_r_t-1) ==&apos; &apos; || *(p_r_t-1) == &apos;,&apos; || *(p_r_t-1) == &apos;?&apos;))&#123;</span><br><span class="line">    *(p_r-1) = &apos;,&apos;;</span><br><span class="line">&#125;</span><br><span class="line">else</span><br><span class="line">    *p_r++ = &apos;?&apos;;</span><br></pre></td></tr></table></figure></p><p>然后在 line:450 左右 COPY CHAR 的时候进行一次过滤：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// COPY CHAR</span><br><span class="line">// =================================================</span><br><span class="line">// wrap two more ? to ?,</span><br><span class="line">if ((*s == &apos; &apos; || *s == &apos;,&apos;) &amp;&amp; (*(p_r_t-1) == &apos;?&apos; || *(p_r_t-1) == &apos;,&apos; || *(p_r_t-1) == &apos; &apos;)) &#123;</span><br><span class="line">    if (*(p_r_t-1) == &apos; &apos; &amp;&amp; *(p_r_t-2) == &apos;?&apos;)</span><br><span class="line">        *(p_r-1) = &apos;,&apos;;  // p_r may be changed in line:435:is_digit_string</span><br><span class="line">&#125;</span><br><span class="line">else &#123;</span><br></pre></td></tr></table></figure></p><p>这部分代码调试花了不少功夫，一是理清逻辑，而是意外情况处理。变量的用途注释不清晰，几年没写C，不得不动用 gdb 来跟踪调试，怀念大学时用IDE的日子。</p><a id="more"></a><p>加 query_text 字段，在用 gdb 理清c++函数间调用关系的之后，改起来还是比较容易：</p><ol><li><em>MySQL_Session.cpp:Query_Info::init</em> 里面会将连接会话的sql信息临时存起来</li><li><em>MySQL_Session.cpp:Query_Info::query_parser_init</em> 调用 <em>Qurey_Processor.cpp:Query_Processor::query_parser_init</em>，里面会调用上面 <em>c_tokenizer.c</em> 来处理digest_text并计算得到digest</li><li>继而是 Query_Processor 类骨规则路由函数 <em>process_mysql_query</em>，但这与我们的改动无关</li><li>路由完成后，调用 <em>query_parser_update_counters</em> 函数来更新统计信息，改动从这里开始。从 sess 里拿到原始的sql，把地址传递给 <em>update_query_digest()</em></li><li><em>Query_Processor::update_query_digest</em> 方法会判断当前digest是否已存在 <em>digest_umap.find(qp-&gt;digest_total)</em><ul><li>如果不是第一次出现，则更新 <code>last_seen</code> 时间</li><li>如果是第一次出现，则 <em>new QP_query_digest_stats</em> 对象，就在这个地方把sql传过去。（Query_Processor.cpp:1026,1028）</li></ul></li><li>在 <code>QP_query_digest_stats</code> 加入 <code>query_text</code> 字段并在析构函数里初始化，同时记得free掉<br>这个地方一度出现 qt 的值在赋给 query_text 的时候，被莫名的吃掉，猜想应该是内存分配的时候被擦掉了，请了公司C++大神涛哥一起调试看了下，是传过来长度截取不对。<br>现在是没有这个问题，但是会随机性出现本文开头所说，sql末尾出现意外字符。还需要进一步排查。</li><li>修改操作sqlite的命令<ul><li><em>Query_Processor.cpp</em>：<em>SQLite3_result </em> Query_Processor::get_query_digests()*</li><li><em>ProxySQL_Admin.cpp</em>：修改 <code>stats_mysql_query_digest</code> 表定义，以及插入sql的模板。<br>这个地方参数漏了一个导致proxysql crash，编译的时候建议把 Makefile中的 <code>-O2</code> 改成 <code>-O0</code>，这样gdb调试的时候不会优化输出，容易跟踪。</li></ul></li></ol><p>这些改动对于c++程序员来说，小菜一碟，但对于我一个DBA来说，总算啃下来了。主要是考虑功能急用，提交 issue 等作者renecannao发版也是太慢。<br>现在可以愉快的收集所有sql了，接下来就是新产生的sql进行自动化审核。</p><p>以上两点特性对于升级来讲是无障碍的，因为 <code>stats_mysql_query_stats</code> 在内存里，重启之前字段就加上了，无需改动proxysql.db里面的内容。代码在我fork仓库的 <a href="https://github.com/seanlook/proxysql/tree/v1.3.7-querysample_digest" target="_blank" rel="noopener"><strong>v1.3.7-querysample_digest</strong></a> 分支，我也已提交 <a href="https://github.com/sysown/proxysql/pull/1010" target="_blank" rel="noopener">pull request</a> 给作者合并。等消息中……</p><hr><p>原文连接地址：<a href="http://seanlook.com/2017/04/27/mysql-proxysql-patch-querytext-sample/">http://seanlook.com/2017/04/27/mysql-proxysql-patch-querytext-sample/</a></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近期一直在思考sql上线审核该怎么做，刚好接触到 ProxySQL 这个中间件，内置了一个计算sql指纹的功能，但是没有记录原始的sql语句。当前正有个紧急的拆库项目也希望知道库上所有的查询。于是把ProxySQL的代码下了回来研究了几天，改了把，加入了两个功能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在 &lt;code&gt;stats_mysql_query_digest&lt;/code&gt; 表上增加 &lt;code&gt;query_text&lt;/code&gt; 字段，当第一次出现这个digest_text时，把原始sql记录下来。&lt;/li&gt;
&lt;li&gt;修改计算指纹的模块，对 IN或者 VALUES 后面的多个 &lt;code&gt;?&lt;/code&gt; 合并。这个是目前 &lt;code&gt;c_tokenizer.c&lt;/code&gt; 文件里没有做的，用到底1点上可以避免重复记录。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;效果：&lt;br&gt;&lt;img src=&quot;http://7q5fot.com1.z0.glb.clouddn.com/proxysql-querytext-sample-digest.png&quot; alt=&quot;proxysql-querytext-sample-digest&quot;&gt;&lt;/p&gt;
&lt;p&gt;多个 &lt;code&gt;?&lt;/code&gt; 被折叠成 &lt;code&gt;?,&lt;/code&gt;，有些意外情况时 &lt;code&gt;??&lt;/code&gt;，因为后面一些多余空格的缘故，没有像 &lt;em&gt;pt-fingerprint&lt;/em&gt; 那样完全模糊化，像这里digest就保留了大小写、去除重复空格、保留 ` 分隔符。但仅有的几种意外情况是可以接受的。&lt;/p&gt;
&lt;p&gt;后面的 query_text 列也有些未知情况，就是末尾会加上一些奇怪的字符，还在排除，但大体不影响需求。&lt;/p&gt;
&lt;p&gt;代码是基于最新 v1.3.6 稳定版修改的，查看变更 &lt;a href=&quot;https://github.com/sysown/proxysql/compare/v1.3.6...seanlook:v1.3.7-querysample_digest&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/sysown/proxysql/compare/v1.3.6...seanlook:v1.3.7-querysample_digest&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;多个 &lt;code&gt;?&lt;/code&gt; 合并只涉及到 &lt;em&gt;c_tokenizer.c&lt;/em&gt; 文件，分别在flag=4（处理 &lt;code&gt;&amp;#39;abc&amp;#39;,&amp;#39;def&amp;#39;&lt;/code&gt; 的情况）和flag=5（处理 &lt;code&gt;1,2, 3&lt;/code&gt; 的情况）加入判断：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;// wrap two more ? to one ?,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;if (*(p_r_t-2) == &amp;apos;?&amp;apos; &amp;amp;&amp;amp; (*(p_r_t-1) ==&amp;apos; &amp;apos; || *(p_r_t-1) == &amp;apos;,&amp;apos; || *(p_r_t-1) == &amp;apos;?&amp;apos;))&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    *(p_r-1) = &amp;apos;,&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;else&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    *p_r++ = &amp;apos;?&amp;apos;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;然后在 line:450 左右 COPY CHAR 的时候进行一次过滤：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;// COPY CHAR&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;// =================================================&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;// wrap two more ? to ?,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;if ((*s == &amp;apos; &amp;apos; || *s == &amp;apos;,&amp;apos;) &amp;amp;&amp;amp; (*(p_r_t-1) == &amp;apos;?&amp;apos; || *(p_r_t-1) == &amp;apos;,&amp;apos; || *(p_r_t-1) == &amp;apos; &amp;apos;)) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    if (*(p_r_t-1) == &amp;apos; &amp;apos; &amp;amp;&amp;amp; *(p_r_t-2) == &amp;apos;?&amp;apos;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        *(p_r-1) = &amp;apos;,&amp;apos;;  // p_r may be changed in line:435:is_digit_string&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;else &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;这部分代码调试花了不少功夫，一是理清逻辑，而是意外情况处理。变量的用途注释不清晰，几年没写C，不得不动用 gdb 来跟踪调试，怀念大学时用IDE的日子。&lt;/p&gt;
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="中间件" scheme="http://seanlook.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="proxysql" scheme="http://seanlook.com/tags/proxysql/"/>
    
  </entry>
  
  <entry>
    <title>ProxySQL之性能测试对比</title>
    <link href="http://seanlook.com/2017/04/20/mysql-proxysql-performance-test/"/>
    <id>http://seanlook.com/2017/04/20/mysql-proxysql-performance-test/</id>
    <published>2017-04-20T13:32:49.000Z</published>
    <updated>2017-04-20T13:32:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文会通过sysbench对ProxySQL进行基准测试，并与直连的性能进行对比。与此同时也对 Maxscale 和 Qihu360 Atlas 放在一起参考。<br>提示：压测前确保把query cache完全关掉。</p><h1 id="1-proxysql-vs-直连"><a href="#1-proxysql-vs-直连" class="headerlink" title="1. proxysql vs 直连"></a>1. proxysql vs 直连</h1><h2 id="1-1-select-nontrx"><a href="#1-1-select-nontrx" class="headerlink" title="1.1 select nontrx"></a>1.1 select nontrx</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./bin/sysbench --test=/root/sysbench2/sysbench/tests/db/oltp.lua --mysql-host=10.0.100.36 --mysql-port=6033 --mysql-user=myuser --mysql-password=mypass \</span><br><span class="line">--mysql-db=db15 --oltp-tables-count=20 --oltp-table-size=5000000 --report-interval=20 --oltp-dist-type=uniform --rand-init=on --max-requests=0 --oltp-test-mode=nontrx --oltp-nontrx-mode=select \</span><br><span class="line">--oltp-read-only=on --oltp-skip-trx=on --max-time=120 --num-threads=2 run</span><br><span class="line"></span><br><span class="line">num-threads依次加大 2 5 10 20 50 100 200 400</span><br></pre></td></tr></table></figure><iframe src="http://www.tubiaoxiu.com/p.html?s=106165b0eeca215a&web_mode" width="900" height="700" frameborder="0" allowfullscreen></iframe><!--![QPS Trends for ProxySQL](http://7q5fot.com1.z0.glb.clouddn.com/proxysql-perf-qps.png) --><p><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-perf-rt.png" alt="Response Time Trends for ProxySQL">  </p><p>sysbench线程并发数达到10以下，性能损失在30%以上；达到20，性能损失减少到10%左右。看到proxysql承载的并发数越高，性能损失越少；最好的时候在50线程数，相比直连损失5%。</p><h2 id="1-2-oltp-dml"><a href="#1-2-oltp-dml" class="headerlink" title="1.2 oltp dml"></a>1.2 oltp dml</h2><p>混合读写测试。proxysql结果图应该与上面相差无几，因为是主要好在计算 query digest 和规则匹配，与select无异，可参考下节的图示。</p><p>sysbench 压测命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./bin/sysbench --test=/root/sysbench2/sysbench/tests/db/oltp.lua --mysql-host=10.0.100.34 --mysql-port=3306 --mysql-user=myuser --mysql-password=mypass \</span><br><span class="line">--mysql-db=db15 --oltp-tables-count=20 --oltp-table-size=5000000 --report-interval=20 --oltp-dist-type=uniform --rand-init=on --max-requests=0 --oltp-read-only=off --max-time=120 \</span><br><span class="line">--num-threads=2 run</span><br><span class="line"></span><br><span class="line">num-threads依次加大 2 5 10 16 20 50 100 200 400</span><br><span class="line">分别对PrxoySQL, Maxscale, Atlas, 直连，四种情况做基准测试</span><br></pre></td></tr></table></figure></p><h1 id="2-proxysql-vs-maxscale-vs-atlas"><a href="#2-proxysql-vs-maxscale-vs-atlas" class="headerlink" title="2. proxysql vs maxscale vs atlas"></a>2. proxysql vs maxscale vs atlas</h1><p>作者自己也有指出，在客户端并发数不高的情况下，maxscale表现比proxysql要好。这里我也特意对maxscale和atlas一起做了个对比。配置基本是最小化的，没有很复杂的规则，只是中间转发。</p><ul><li>ProxySQL  (v1.3.5): mysql-threads=4</li><li>Atlas 360 (v2.2.1): event-threads=4</li><li>maxscale  (v1.4.5): threads=4</li></ul><p><strong> 2.1 select nontrx </strong><br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-perf-qps-maxscale-atlas.png" alt="QPS(select) Trends for ProxySQL/Maxscale/atlas"></p><p>oltp混合读写基准测试，没有复杂配置的情况下，ProxySQL与Maxscale神奇般的几乎重合，Qihu360的atlas要弱一些。</p><p><strong> 2.2 oltp dml </strong><br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-perf-qps-oltp-maxscale-atlas.png" alt="QPS(oltp) Trends for ProxySQL/Maxscale/atlas"></p><p>原始数据：<br><img src="http://7q5fot.com1.z0.glb.clouddn.com/proxysql-perf-qps-src-data.png" alt="ProxySQL Performance Test Source Data"></p><h1 id="3-rewrite-vs-non-rewrite"><a href="#3-rewrite-vs-non-rewrite" class="headerlink" title="3. rewrite vs non-rewrite"></a>3. rewrite vs non-rewrite</h1><p>下面来测一下 query rewrite 对性能的影响，考虑到将来如果要分表，可以在ProxySQL这一层做，应用端无需改动表名。<br>为了达到效果，这里rewrite只是为表增加了个别名：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-- proxysql admin cli</span><br><span class="line">update mysql_query_rules set match_pattern=&quot;(.*)(sbtest\d+)(.*)&quot;,replace_pattern=&quot;\1\2 as ttt \3&quot; where rule_id &gt;=61 and rule_id &lt;=92;</span><br><span class="line">load mysql query rules to run;</span><br></pre></td></tr></table></figure></p><p>sysbench num-threads=20 的结果：</p><table><thead><tr><th style="text-align:left">replace?</th><th>qps</th><th>response time avg(ms)</th></tr></thead><tbody><tr><td style="text-align:left">proxysql replace</td><td>15734.49</td><td>17.79</td></tr><tr><td style="text-align:left">proxysql no-replace</td><td>16764.66</td><td>16.70</td></tr><tr><td style="text-align:left">直连</td><td>18778.43</td><td>14.91</td></tr></tbody></table><p>在20个并发线程下，有 rewrite 是 no-rewrite 性能的 93.9% 。测试线程数继续加大到 50，差别更小。</p><h1 id="4-lots-of-rules"><a href="#4-lots-of-rules" class="headerlink" title="4. lots of rules"></a>4. lots of rules</h1><p>测试ProxySQL定义的 query rules 数量（并匹配但不apply），对性能的影响。</p><p>测试的规则时批量插入大量能匹配sysbench查询的规则，但 mysql_query_rules.apply=0 :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">insert into mysql_query_rules(active,schemaname,apply,flagIN) values</span><br><span class="line">  (1,&apos;db15&apos;,0,0),(1,&apos;db15&apos;,0,0),(1,&apos;db15&apos;,0,0),(1,&apos;db15&apos;,0,0),(1,&apos;db15&apos;,0,0), ...</span><br><span class="line"></span><br><span class="line"># 2 100 200 400 800 1200 2000</span><br></pre></td></tr></table></figure></p><p>这里偶然发现一个问题，flagIN=0的规则必须要在 !=0 的规则前面，否则flagOUT找不到下一个新链入口.(经作者回复是参数 <code>mysql-query_processor_iterations</code> 控制的)<br>下面的结果是 sysbench num-threads=20 的几轮数据：（由于结果接近，没作图）</p><table><thead><tr><th>matched rules</th><th>QPS</th><th>RT avg</th><th>CPU%</th></tr></thead><tbody><tr><td>2</td><td>16741.54</td><td>16.69</td><td>151</td></tr><tr><td>100</td><td>16743.54</td><td>16.69</td><td>152</td></tr><tr><td>200</td><td>16749.94</td><td>16.71</td><td>159</td></tr><tr><td>400</td><td>16556.09</td><td>16.91</td><td>176</td></tr><tr><td>800</td><td>16522.02</td><td>16.94</td><td>203</td></tr><tr><td>1200</td><td>16477.70</td><td>16.99</td><td>220</td></tr><tr><td>2000</td><td>16333.59</td><td>17.14</td><td>263</td></tr></tbody></table><p>看到匹配到的规则随着增多，QPS变化不大，只是略微下降；平均响应时间增加在3%以内；倒是ProxySQL对CPU的负载增加比较明显，匹配的规则从 2 个增加到 2000，cpu使用增加了 74% 。 </p><p>参考：</p><ul><li><a href="https://www.percona.com/blog/2017/04/10/proxysql-rules-do-i-have-too-many/#comment-10967989" target="_blank" rel="noopener">https://www.percona.com/blog/2017/04/10/proxysql-rules-do-i-have-too-many/#comment-10967989</a></li></ul><hr><p>原文连接地址：<a href="http://seanlook.com/2017/04/20/mysql-proxysql-performance-test/">http://seanlook.com/2017/04/20/mysql-proxysql-performance-test/</a></p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文会通过sysbench对ProxySQL进行基准测试，并与直连的性能进行对比。与此同时也对 Maxscale 和 Qihu360 Atlas 放在一起参考。&lt;br&gt;提示：压测前确保把query cache完全关掉。&lt;/p&gt;
&lt;h1 id=&quot;1-proxysql-vs-直
      
    
    </summary>
    
      <category term="MySQL" scheme="http://seanlook.com/categories/MySQL/"/>
    
    
      <category term="mysql" scheme="http://seanlook.com/tags/mysql/"/>
    
      <category term="中间件" scheme="http://seanlook.com/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
      <category term="proxysql" scheme="http://seanlook.com/tags/proxysql/"/>
    
  </entry>
  
</feed>
